
library to visualize the pytorch model !!!!!

I am confused on what the accuracy of the unsupervised model is calculated on...

lebesgue_p

So we have a network model: 
what is the input type
What are the layer types
How is the learning implemented
what is the output


ray_search.py : where the parameters are parsed and the main is executed.
    
    run_unsup(): performs unspervised learning and evaluates at the end of every epoch
        train_unsup(): 
            train_hebb(): The criterion can be something like ... ??? criterion seems to be none always, just like measures. 
                            So are they both to be defined??? 


        evaluate_unsup(): 
            evaluate_hebb(): does the unsupervised evaluation ---------------- we can't get in here (return 0.0 error)
                infer_dataset(): 

    run_sup (): runs the supervised learning if the mode is supervised (??? there are instances where the MLP is unsup???)
        train_sup():
            train_sup_hebb(): weigth change vector which is done only the last layer ?????? +  if loss_acc problem
            train_BP():
        evaluate_sup(): 


    run hybrid ()





# Alright so how to organize the slides:
- I would first give a general explanation of what the code does ( so the different types of training, how 
they differ from each other and what they aim to do ), then I would get into the code with the high level 
explanation of the functions implementing the corresponding learning. 
- I would do a very high level discussion of the flow of the functions and the general 
execution of the program. Just include the name of the functions and what they generally do.
Like Input types and output. 

Then do a main discussion on the methods which are used for training and how the update happens. 
So when trainign a model the main thign to consider is what kind of input is used, 
the update rule used ( in our case it would either be hebbian learning without any loss feedback and classical BP)

Ok so the training is mainly done in multi_layer.py while in ray_search we have the search for the optimal hyperparameters. 

-- FIRST READ
We have seen that the soft hebb network is compared with the classical BP fully supervised method. 
From my understanding the hebbian network is trained first in a fully unsupervised manner in order to obtain  a way of clusterizing the points, 
After which we take it and use a classifier to assign the clusters to the classes. 


HebbHardKrotovLinear get_wta needs to be finished commenting.
In the soft implementation we use the activation function, which creates a vector of activations effectively assigning a probability 
distribution to the activations since their value is between 0 and 1. 


What is the concept of activation?? 
So we have a set of neurons on one layer linked to the neurons in the next layer. Let's say we go from neuron i to neuron k, what is the activation of the 
neuron i? It is the pre synaptic value passed in the activation function? Or is the post synaptic?? 

The datasets: 

ImageNette: Imagenette is a subset of 10 easily classified classes from Imagenet (tench, English springer, cassette player, chain saw, church, French horn, garbage truck, gas pump, golf ball, parachute).

STL10: 10 classes: (some similar to cifar10)
- airplane, bird, car, cat, deer, dog, horse, monkey, ship, truck.
- Images are 96x96 pixels, color.
- 500 training images (10 pre-defined folds), 800 test images per class.
- 100000 unlabeled images for unsupervised learning. These examples are extracted from a similar but broader distribution of images. For instance, it contains other types of animals (bears, rabbits, etc.) and vehicles (trains, buses, etc.) in addition to the ones in the labeled set.
- Images were acquired from labeled examples on ImageNet.

CIFAR100: 32x32 color images classified into 100 classes

CIFAR10: 

airplane										
automobile										
bird										
cat										
deer										
dog										
frog										
horse								
		
ship										
truck