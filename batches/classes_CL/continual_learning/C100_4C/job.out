BLOCKS:  {'b0': {'arch': 'CNN', 'preset': 'softkrotov-c96-k5-p2-s1-d1-b0-t1-lr0.08-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 0, 'batch_norm': False, 'pool': {'type': 'max', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 0.7}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5}}, 'b1': {'arch': 'CNN', 'preset': 'softkrotov-c384-k3-p1-s1-d1-b0-t0.65-lr0.005-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 1, 'batch_norm': False, 'pool': {'type': 'max', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 1.4}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3}}, 'b2': {'arch': 'CNN', 'preset': 'softkrotov-c1536-k3-p1-s1-d1-b0-t0.25-lr0.01-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 2, 'batch_norm': False, 'pool': {'type': 'avg', 'kernel_size': 2, 'stride': 2, 'padding': 0}, 'activation': {'function': 'triangle', 'param': 1.0}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3}}, 'b3': {'arch': 'MLP', 'preset': 'BP-c10', 'operation': 'flatten', 'num': 3, 'att_dropout': None, 'dropout': 0.5, 'layer': {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.25, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10}, 'pool': None, 'activation': None}}
CL:  True
{'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 100, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True}
CL:  True
{'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 100, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 50, 'validation': False, 'continual_learning': True}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.11048543456039805, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 4, 'in_channels': 24576, 'old_channels': 1536, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=4, bias=True)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([14, 37, 37, 76, 37, 37, 80, 80, 76, 76, 80, 80, 76, 76, 37, 37, 14, 76,
        14, 14])
[14, 37, 76, 80]
TARGETS AFTER CLEANER:  tensor([0, 1, 1, 2, 1, 1, 3, 3, 2, 2, 3, 3, 2, 2, 1, 1, 0, 2, 0, 0])
400
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 400
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([80, 76, 14, 76, 80, 14, 37, 37, 80, 37, 80, 76, 80, 76, 14, 14, 37, 76,
        76, 14])
[14, 37, 76, 80]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 2, 3, 0, 1, 1, 3, 1, 3, 2, 3, 2, 0, 0, 1, 2, 2, 0])
2000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([80, 76, 14, 76, 80, 14, 37, 37, 80, 37, 80, 76, 80, 76, 14, 14, 37, 76,
        76, 14])
[14, 37, 76, 80]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 2, 3, 0, 1, 1, 3, 1, 3, 2, 3, 2, 0, 0, 1, 2, 2, 0])
2000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  2000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_4C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.78e-01	time: 00:00:21	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:-2.273e-03/SW:7.232e-01/MR:6.091e+00/SR:1.465e+00/MeD:1.162e+00/MaD:4.237e+00/MW:0.430/MAW:0.570
|       0 |       1 |       2 |       3 |       4 |       5 |       6 |       7 |       8 |       9 |      10 |     11 |      12 |      13 |     14 |      15 |       16 |     17 |      18 |      19 |      20 |      21 |      22 |     23 |      24 |      25 |     26 |      27 |      28 |      29 |
|---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+--------+---------+---------+--------+---------+----------+--------+---------+---------+---------+---------+---------+--------+---------+---------+--------+---------+---------+---------|
|   0.152 |   0.214 |   0.199 |   0.195 |   0.145 |   0.164 |   0.178 |   0.214 |   0.151 |   0.239 |   0.171 |   0.17 |   0.179 |   0.195 |   0.18 |   0.198 |   0.0739 |   0.17 |   0.181 |   0.182 |   0.195 |   0.174 |   0.194 |   0.22 |   0.204 |   0.112 |   0.21 |   0.183 |   0.165 |   0.216 |
|   4.59  |   8.13  |   7.18  |   6.95  |   4.28  |   5.2   |   5.95  |   8.13  |   4.57  |   9.91  |   5.58  |   5.51 |   6.03  |   6.96  |   6.07 |   7.12  |   1.85   |   5.54 |   6.11  |   6.16  |   6.94  |   5.74  |   6.87  |   8.54 |   7.48  |   2.95  |   7.92 |   6.23  |   5.27  |   8.32  |
|   0.75  |   0.39  |   0.29  |   0.42  |   1.48  |   2.54  |   0.75  |   0.49  |   1.15  |   0.28  |   1.04  |   0.58 |   0.62  |   0.43  |   1.65 |   0.41  |   2.74   |   0.56 |   0.71  |   1.08  |   0.6   |   1.04  |   0.47  |   0.39 |   0.46  |   2.85  |   0.52 |   0.83  |   0.46  |   0.37  |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan    | nan     | nan      | nan    | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan    | nan     | nan     | nan     |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan    | nan     | nan      | nan    | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan    | nan     | nan     | nan     |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan    | nan     | nan      | nan    | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan    | nan     | nan     | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_4C_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([14, 37, 37, 76, 37, 37, 80, 80, 76, 76, 80, 80, 76, 76, 37, 37, 14, 76,
        14, 14])
[14, 37, 76, 80]
TARGETS AFTER CLEANER:  tensor([0, 1, 1, 2, 1, 1, 3, 3, 2, 2, 3, 3, 2, 2, 1, 1, 0, 2, 0, 0])
400
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 400
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([80, 76, 14, 76, 80, 14, 37, 37, 80, 37, 80, 76, 80, 76, 14, 14, 37, 76,
        76, 14])
[14, 37, 76, 80]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 2, 3, 0, 1, 1, 3, 1, 3, 2, 3, 2, 0, 0, 1, 2, 2, 0])
2000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([80, 76, 14, 76, 80, 14, 37, 37, 80, 37, 80, 76, 80, 76, 14, 14, 37, 76,
        76, 14])
[14, 37, 76, 80]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 2, 3, 0, 1, 1, 3, 1, 3, 2, 3, 2, 0, 0, 1, 2, 2, 0])
2000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  2000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_4C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.78e-01	time: 00:00:33	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:-3.059e-03/SW:7.641e-01/MR:2.231e+01/SR:2.581e+00/MeD:2.082e+00/MaD:8.968e+00/MW:0.758/MAW:0.242
|        0 |        1 |        2 |       3 |        4 |        5 |       6 |        7 |        8 |        9 |       10 |       11 |       12 |       13 |      14 |       15 |       16 |       17 |       18 |       19 |       20 |       21 |       22 |      23 |       24 |       25 |      26 |       27 |       28 |       29 |
|----------+----------+----------+---------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+---------+----------+----------+----------|
|   0.0239 |   0.0244 |   0.0241 |   0.024 |   0.0186 |   0.0228 |   0.024 |   0.0244 |   0.0241 |   0.0232 |   0.0247 |   0.0239 |   0.0245 |   0.0236 |   0.024 |   0.0239 |   0.0231 |   0.0213 |   0.0229 |   0.0231 |   0.0229 |   0.0248 |   0.0228 |   0.023 |   0.0235 |   0.0233 |   0.022 |   0.0235 |   0.0227 |   0.0249 |
|  23.92   |  24.82   |  24.31   |  24.12  |  14.8    |  21.85   |  24.08  |  24.89   |  24.2    |  22.61   |  25.44   |  23.8    |  24.98   |  23.23   |  24.06  |  23.83   |  22.36   |  19.17   |  21.93   |  22.4    |  21.97   |  25.66   |  21.87   |  22.22  |  23.15   |  22.78   |  20.39  |  23.07   |  21.6    |  25.73   |
|   0.14   |   0.03   |   0.02   |   0.02  |   1.55   |   0.28   |   0.08  |   0.11   |   0.05   |   0.18   |   0.02   |   0.06   |   0.07   |   0.18   |   0.05  |   0.09   |   0.15   |   0.59   |   0.19   |   0.24   |   0.16   |   0.02   |   0.41   |   0.34  |   0.16   |   0.18   |   0.45  |   0.1    |   0.25   |   0.05   |
| nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan      | nan      |
| nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan      | nan      |
| nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_4C_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([14, 37, 37, 76, 37, 37, 80, 80, 76, 76, 80, 80, 76, 76, 37, 37, 14, 76,
        14, 14])
[14, 37, 76, 80]
TARGETS AFTER CLEANER:  tensor([0, 1, 1, 2, 1, 1, 3, 3, 2, 2, 3, 3, 2, 2, 1, 1, 0, 2, 0, 0])
400
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 400
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([80, 76, 14, 76, 80, 14, 37, 37, 80, 37, 80, 76, 80, 76, 14, 14, 37, 76,
        76, 14])
[14, 37, 76, 80]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 2, 3, 0, 1, 1, 3, 1, 3, 2, 3, 2, 0, 0, 1, 2, 2, 0])
2000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([80, 76, 14, 76, 80, 14, 37, 37, 80, 37, 80, 76, 80, 76, 14, 14, 37, 76,
        76, 14])
[14, 37, 76, 80]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 2, 3, 0, 1, 1, 3, 1, 3, 2, 3, 2, 0, 0, 1, 2, 2, 0])
2000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  2000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_4C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.79e-02	time: 00:00:44	Acc_train 0.00	Acc_test 0.00	convergence: 2.30e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.293e-04/SW:4.094e-01/MR:2.399e+01/SR:1.990e+00/MeD:1.496e+00/MaD:1.054e+01/MW:0.482/MAW:0.518
|        0 |        1 |        2 |        3 |        4 |        5 |        6 |        7 |        8 |        9 |       10 |       11 |       12 |       13 |       14 |      15 |       16 |       17 |       18 |       19 |       20 |      21 |       22 |     23 |       24 |       25 |       26 |       27 |       28 |       29 |
|----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+---------+----------+--------+----------+----------+----------+----------+----------+----------|
|   0.0494 |   0.0493 |   0.0491 |   0.0469 |   0.0476 |   0.0491 |   0.0496 |   0.0429 |   0.0496 |   0.0492 |   0.0496 |   0.0486 |   0.0471 |   0.0419 |   0.0467 |   0.049 |   0.0441 |   0.0499 |   0.0486 |   0.0491 |   0.0456 |   0.049 |   0.0499 |   0.05 |   0.0481 |   0.0483 |   0.0491 |   0.0468 |   0.0455 |   0.0488 |
|  25.42   |  25.26   |  25.14   |  22.99   |  23.63   |  25.14   |  25.59   |  19.43   |  25.62   |  25.2    |  25.58   |  24.64   |  23.17   |  18.6    |  22.76   |  25     |  20.42   |  25.86   |  24.58   |  25.06   |  21.82   |  25.03  |  25.88   |  26.02 |  24.14   |  24.31   |  25.1    |  22.94   |  21.69   |  24.79   |
|   0      |   0.01   |   0.04   |   0.09   |   0.06   |   0.03   |   0.01   |   0.11   |   0.03   |   0      |   0.02   |   0.09   |   0.09   |   0.16   |   0.15   |   0.03  |   0.26   |   0.01   |   0.06   |   0.01   |   0.17   |   0.04  |   0.22   |   0.02 |   0.02   |   0.05   |   0.02   |   0.08   |   0.13   |   0.01   |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan    | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan    | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan    | nan      | nan      | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_4C_CL/models

 ********** Supervised learning of blocks [3] **********
SAVING FOLDER FOR SUP:  C100_4C_CL
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([14, 37, 37, 76, 37, 37, 80, 80, 76, 76, 80, 80, 76, 76, 37, 37, 14, 76,
        14, 14])
[14, 37, 76, 80]
TARGETS AFTER CLEANER:  tensor([0, 1, 1, 2, 1, 1, 3, 3, 2, 2, 3, 3, 2, 2, 1, 1, 0, 2, 0, 0])
400
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 400
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([80, 76, 14, 76, 80, 14, 37, 37, 80, 37, 80, 76, 80, 76, 14, 14, 37, 76,
        76, 14])
[14, 37, 76, 80]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 2, 3, 0, 1, 1, 3, 1, 3, 2, 3, 2, 0, 0, 1, 2, 2, 0])
2000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([80, 76, 14, 76, 80, 14, 37, 37, 80, 37, 80, 76, 80, 76, 14, 14, 37, 76,
        76, 14])
[14, 37, 76, 80]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 2, 3, 0, 1, 1, 3, 1, 3, 2, 3, 2, 0, 0, 1, 2, 2, 0])
2000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  2000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Epoch: [1/50]	lr: 1.00e-03	time: 00:00:56	Loss_train 0.52170	Acc_train 65.75	/	Loss_test 0.04546	Acc_test 75.25
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_4C_CL/models
Epoch: [10/50]	lr: 1.00e-03	time: 00:00:57	Loss_train 0.08532	Acc_train 88.36	/	Loss_test 0.02399	Acc_test 83.25
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_4C_CL/models
Epoch: [20/50]	lr: 2.50e-04	time: 00:00:58	Loss_train 0.01419	Acc_train 96.84	/	Loss_test 0.01716	Acc_test 85.25
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_4C_CL/models
Epoch: [30/50]	lr: 1.25e-04	time: 00:01:00	Loss_train 0.00483	Acc_train 98.52	/	Loss_test 0.01617	Acc_test 87.25
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_4C_CL/models
Epoch: [40/50]	lr: 3.13e-05	time: 00:01:01	Loss_train 0.00318	Acc_train 98.84	/	Loss_test 0.01627	Acc_test 86.50
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_4C_CL/models
Epoch: [50/50]	lr: 7.81e-06	time: 00:01:02	Loss_train 0.00236	Acc_train 99.08	/	Loss_test 0.01574	Acc_test 87.75
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_4C_CL/models
RESULT:  {'train_loss': 0.0023562991991639137, 'train_acc': 99.08499717712402, 'test_loss': 0.01574360765516758, 'test_acc': 87.75, 'convergence': 22.987783432006836, 'R1': 0, 'dataset_sup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [14, 37, 76, 80]}, 'dataset_unsup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 50, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [14, 37, 76, 80]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}
IN R1:  {'R1': {'train_loss': 0.0023562991991639137, 'train_acc': 99.08499717712402, 'test_loss': 0.01574360765516758, 'test_acc': 87.75, 'convergence': 22.987783432006836, 'R1': 0, 'dataset_sup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [14, 37, 76, 80]}, 'dataset_unsup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 50, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [14, 37, 76, 80]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.11048543456039805, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 4, 'in_channels': 24576, 'old_channels': 1536, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 Model C100_4C_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=4, bias=True)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([43, 73, 73, 43, 67, 67, 43, 43,  1, 73, 73, 67,  1, 67, 67, 43, 43, 67,
        67, 67])
[1, 43, 67, 73]
TARGETS AFTER CLEANER:  tensor([1, 3, 3, 1, 2, 2, 1, 1, 0, 3, 3, 2, 0, 2, 2, 1, 1, 2, 2, 2])
400
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 400
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 1, 73, 43, 73, 67, 43, 67, 73, 43, 43,  1,  1, 67, 43, 73, 43, 73, 67,
        67, 43])
[1, 43, 67, 73]
TARGETS AFTER CLEANER:  tensor([0, 3, 1, 3, 2, 1, 2, 3, 1, 1, 0, 0, 2, 1, 3, 1, 3, 2, 2, 1])
2000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 1, 73, 43, 73, 67, 43, 67, 73, 43, 43,  1,  1, 67, 43, 73, 43, 73, 67,
        67, 43])
[1, 43, 67, 73]
TARGETS AFTER CLEANER:  tensor([0, 3, 1, 3, 2, 1, 2, 3, 1, 1, 0, 0, 2, 1, 3, 1, 3, 2, 2, 1])
2000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  2000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_4C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.72e-01	time: 00:00:11	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.304e-02/SW:7.135e-01/MR:5.924e+00/SR:1.769e+00/MeD:1.300e+00/MaD:4.924e+00/MW:0.545/MAW:0.455
|       0 |       1 |       2 |       3 |       4 |       5 |       6 |       7 |       8 |       9 |       10 |      11 |      12 |      13 |      14 |      15 |         16 |      17 |      18 |      19 |      20 |      21 |      22 |      23 |     24 |         25 |      26 |      27 |      28 |     29 |
|---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+----------+---------+---------+---------+---------+---------+------------+---------+---------+---------+---------+---------+---------+---------+--------+------------+---------+---------+---------+--------|
|   0.163 |   0.212 |   0.185 |   0.191 |   0.152 |   0.178 |   0.186 |   0.218 |   0.169 |   0.223 |   0.0393 |   0.155 |   0.191 |   0.172 |   0.176 |   0.207 |   0.000733 |   0.163 |   0.187 |   0.191 |   0.208 |   0.181 |   0.175 |   0.214 |   0.2  |   0.000616 |   0.208 |   0.164 |   0.172 |   0.21 |
|   5.17  |   8     |   6.33  |   6.71  |   4.62  |   5.97  |   6.41  |   8.41  |   5.49  |   8.78  |   1.24   |   4.74  |   6.73  |   5.61  |   5.85  |   7.7   |   1        |   5.18  |   6.46  |   6.7   |   7.79  |   6.12  |   5.77  |   8.15  |   7.23 |   1        |   7.73  |   5.21  |   5.64  |   7.91 |
|   0.55  |   0.55  |   0.37  |   0.57  |   0.55  |   0.51  |   0.96  |   0.5   |   0.63  |   0.42  |   1.82   |   0.53  |   0.62  |   0.44  |   0.58  |   0.47  |   9.24     |   0.55  |   0.44  |   0.92  |   0.78  |   0.66  |   0.56  |   0.57  |   0.47 |  13.97     |   0.88  |   1.44  |   0.48  |   0.46 |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan      | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan        | nan     | nan     | nan     | nan    |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan      | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan        | nan     | nan     | nan     | nan    |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan      | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan        | nan     | nan     | nan     | nan    |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_4C_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([43, 73, 73, 43, 67, 67, 43, 43,  1, 73, 73, 67,  1, 67, 67, 43, 43, 67,
        67, 67])
[1, 43, 67, 73]
TARGETS AFTER CLEANER:  tensor([1, 3, 3, 1, 2, 2, 1, 1, 0, 3, 3, 2, 0, 2, 2, 1, 1, 2, 2, 2])
400
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 400
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 1, 73, 43, 73, 67, 43, 67, 73, 43, 43,  1,  1, 67, 43, 73, 43, 73, 67,
        67, 43])
[1, 43, 67, 73]
TARGETS AFTER CLEANER:  tensor([0, 3, 1, 3, 2, 1, 2, 3, 1, 1, 0, 0, 2, 1, 3, 1, 3, 2, 2, 1])
2000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 1, 73, 43, 73, 67, 43, 67, 73, 43, 43,  1,  1, 67, 43, 73, 43, 73, 67,
        67, 43])
[1, 43, 67, 73]
TARGETS AFTER CLEANER:  tensor([0, 3, 1, 3, 2, 1, 2, 3, 1, 1, 0, 0, 2, 1, 3, 1, 3, 2, 2, 1])
2000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  2000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_4C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.72e-01	time: 00:00:22	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:-2.501e-03/SW:6.507e-01/MR:1.895e+01/SR:2.608e+00/MeD:2.120e+00/MaD:8.507e+00/MW:0.748/MAW:0.252
|        0 |      1 |        2 |        3 |        4 |        5 |        6 |        7 |       8 |        9 |      10 |       11 |       12 |       13 |       14 |       15 |       16 |       17 |       18 |       19 |       20 |       21 |       22 |       23 |       24 |       25 |       26 |       27 |       28 |      29 |
|----------+--------+----------+----------+----------+----------+----------+----------+---------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------|
|   0.0224 |   0.02 |   0.0216 |   0.0229 |   0.0167 |   0.0206 |   0.0216 |   0.0226 |   0.021 |   0.0218 |   0.022 |   0.0193 |   0.0214 |   0.0208 |   0.0223 |   0.0212 |   0.0215 |   0.0193 |   0.0187 |   0.0207 |   0.0222 |   0.0224 |   0.0192 |   0.0214 |   0.0181 |   0.0214 |   0.0217 |   0.0212 |   0.0181 |   0.023 |
|  21.11   |  17.04 |  19.7    |  21.98   |  12.21   |  17.91   |  19.74   |  21.36   |  18.71  |  19.95   |  20.34  |  15.87   |  19.38   |  18.23   |  20.93   |  19.03   |  19.41   |  15.98   |  15      |  18.08   |  20.69   |  21.15   |  15.71   |  19.32   |  14.13   |  19.4    |  19.88   |  19      |  14.13   |  22.13  |
|   0.19   |   0.48 |   0.35   |   0.13   |   0.61   |   0.21   |   0.29   |   0.19   |   0.32  |   0.17   |   0.25  |   1      |   0.48   |   0.42   |   0.2    |   0.34   |   0.22   |   0.36   |   0.41   |   0.26   |   0.09   |   0.43   |   0.76   |   0.25   |   1.31   |   0.4    |   0.03   |   0.21   |   0.56   |   0.21  |
| nan      | nan    | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     |
| nan      | nan    | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     |
| nan      | nan    | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_4C_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([43, 73, 73, 43, 67, 67, 43, 43,  1, 73, 73, 67,  1, 67, 67, 43, 43, 67,
        67, 67])
[1, 43, 67, 73]
TARGETS AFTER CLEANER:  tensor([1, 3, 3, 1, 2, 2, 1, 1, 0, 3, 3, 2, 0, 2, 2, 1, 1, 2, 2, 2])
400
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 400
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 1, 73, 43, 73, 67, 43, 67, 73, 43, 43,  1,  1, 67, 43, 73, 43, 73, 67,
        67, 43])
[1, 43, 67, 73]
TARGETS AFTER CLEANER:  tensor([0, 3, 1, 3, 2, 1, 2, 3, 1, 1, 0, 0, 2, 1, 3, 1, 3, 2, 2, 1])
2000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 1, 73, 43, 73, 67, 43, 67, 73, 43, 43,  1,  1, 67, 43, 73, 43, 73, 67,
        67, 43])
[1, 43, 67, 73]
TARGETS AFTER CLEANER:  tensor([0, 3, 1, 3, 2, 1, 2, 3, 1, 1, 0, 0, 2, 1, 3, 1, 3, 2, 2, 1])
2000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  2000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_4C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.68e-02	time: 00:00:34	Acc_train 0.00	Acc_test 0.00	convergence: 2.20e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:2.601e-04/SW:3.928e-01/MR:2.296e+01/SR:2.450e+00/MeD:1.972e+00/MaD:9.444e+00/MW:0.482/MAW:0.518
|        0 |       1 |        2 |        3 |        4 |        5 |        6 |        7 |        8 |        9 |       10 |       11 |       12 |       13 |       14 |       15 |       16 |       17 |       18 |       19 |       20 |       21 |       22 |       23 |       24 |       25 |       26 |       27 |       28 |       29 |
|----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------|
|   0.0491 |   0.049 |   0.0484 |   0.0463 |   0.0466 |   0.0468 |   0.0502 |   0.0398 |   0.0496 |   0.0492 |   0.0489 |   0.0476 |   0.0477 |   0.0416 |   0.0478 |   0.0472 |   0.0446 |   0.0511 |   0.0459 |   0.0478 |   0.0461 |   0.0475 |   0.0438 |   0.0458 |   0.0468 |   0.0408 |   0.0464 |   0.0459 |   0.0446 |   0.0468 |
|  25.13   |  24.99  |  24.45   |  22.4    |  22.69   |  22.86   |  26.18   |  16.81   |  25.62   |  25.21   |  24.92   |  23.67   |  23.72   |  18.27   |  23.88   |  23.29   |  20.91   |  27.13   |  22.08   |  23.88   |  22.21   |  23.58   |  20.17   |  21.99   |  22.89   |  17.62   |  22.53   |  22.05   |  20.89   |  22.88   |
|   0.03   |   0.03  |   0.04   |   0.02   |   0.02   |   0.05   |   0.01   |   0.04   |   0.03   |   0.01   |   0.04   |   0.07   |   0.12   |   0.04   |   0.16   |   0.05   |   0.03   |   0.03   |   0.12   |   0.04   |   0.01   |   0.07   |   0.38   |   0.09   |   0.07   |   0.16   |   0.08   |   0.05   |   0.04   |   0.07   |
| nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_4C_CL/models

 ********** Supervised learning of blocks [3] **********
SAVING FOLDER FOR SUP:  C100_4C_CL
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([43, 73, 73, 43, 67, 67, 43, 43,  1, 73, 73, 67,  1, 67, 67, 43, 43, 67,
        67, 67])
[1, 43, 67, 73]
TARGETS AFTER CLEANER:  tensor([1, 3, 3, 1, 2, 2, 1, 1, 0, 3, 3, 2, 0, 2, 2, 1, 1, 2, 2, 2])
400
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 400
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 1, 73, 43, 73, 67, 43, 67, 73, 43, 43,  1,  1, 67, 43, 73, 43, 73, 67,
        67, 43])
[1, 43, 67, 73]
TARGETS AFTER CLEANER:  tensor([0, 3, 1, 3, 2, 1, 2, 3, 1, 1, 0, 0, 2, 1, 3, 1, 3, 2, 2, 1])
2000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 1, 73, 43, 73, 67, 43, 67, 73, 43, 43,  1,  1, 67, 43, 73, 43, 73, 67,
        67, 43])
[1, 43, 67, 73]
TARGETS AFTER CLEANER:  tensor([0, 3, 1, 3, 2, 1, 2, 3, 1, 1, 0, 0, 2, 1, 3, 1, 3, 2, 2, 1])
2000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  2000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Epoch: [1/50]	lr: 1.00e-03	time: 00:00:45	Loss_train 0.82672	Acc_train 59.55	/	Loss_test 0.06313	Acc_test 71.50
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_4C_CL/models
Epoch: [10/50]	lr: 1.00e-03	time: 00:00:46	Loss_train 0.14472	Acc_train 84.41	/	Loss_test 0.03917	Acc_test 79.75
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_4C_CL/models
Epoch: [20/50]	lr: 2.50e-04	time: 00:00:47	Loss_train 0.03960	Acc_train 93.87	/	Loss_test 0.03532	Acc_test 81.00
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_4C_CL/models
Epoch: [30/50]	lr: 1.25e-04	time: 00:00:49	Loss_train 0.01966	Acc_train 96.06	/	Loss_test 0.02854	Acc_test 82.75
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_4C_CL/models
Epoch: [40/50]	lr: 3.13e-05	time: 00:00:50	Loss_train 0.01335	Acc_train 97.03	/	Loss_test 0.02925	Acc_test 81.75
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_4C_CL/models
Epoch: [50/50]	lr: 7.81e-06	time: 00:00:51	Loss_train 0.01209	Acc_train 97.08	/	Loss_test 0.02984	Acc_test 81.50
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_4C_CL/models
RESULT:  {'train_loss': 0.01209018100053072, 'train_acc': 97.079998254776, 'test_loss': 0.029837461188435555, 'test_acc': 81.5, 'convergence': 21.9600887298584, 'R1': 0, 'dataset_sup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [1, 43, 67, 73]}, 'dataset_unsup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 50, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [1, 43, 67, 73]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}
IN R2:  {'R1': {'train_loss': 0.0023562991991639137, 'train_acc': 99.08499717712402, 'test_loss': 0.01574360765516758, 'test_acc': 87.75, 'convergence': 22.987783432006836, 'R1': 0, 'dataset_sup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [14, 37, 76, 80]}, 'dataset_unsup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 50, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [14, 37, 76, 80]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}, 'R2': {'train_loss': 0.01209018100053072, 'train_acc': 97.079998254776, 'test_loss': 0.029837461188435555, 'test_acc': 81.5, 'convergence': 21.9600887298584, 'R1': 0, 'dataset_sup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [1, 43, 67, 73]}, 'dataset_unsup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 50, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [1, 43, 67, 73]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.11048543456039805, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 4, 'in_channels': 24576, 'old_channels': 1536, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 Model C100_4C_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=4, bias=True)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([14, 37, 37, 76, 37, 37, 80, 80, 76, 76, 80, 80, 76, 76, 37, 37, 14, 76,
        14, 14])
[14, 37, 76, 80]
TARGETS AFTER CLEANER:  tensor([0, 1, 1, 2, 1, 1, 3, 3, 2, 2, 3, 3, 2, 2, 1, 1, 0, 2, 0, 0])
400
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 400
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([80, 76, 14, 76, 80, 14, 37, 37, 80, 37, 80, 76, 80, 76, 14, 14, 37, 76,
        76, 14])
[14, 37, 76, 80]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 2, 3, 0, 1, 1, 3, 1, 3, 2, 3, 2, 0, 0, 1, 2, 2, 0])
2000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([80, 76, 14, 76, 80, 14, 37, 37, 80, 37, 80, 76, 80, 76, 14, 14, 37, 76,
        76, 14])
[14, 37, 76, 80]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 2, 3, 0, 1, 1, 3, 1, 3, 2, 3, 2, 0, 0, 1, 2, 2, 0])
2000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  2000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_4C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.54e-01	time: 00:00:11	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.421e-02/SW:6.191e-01/MR:5.047e+00/SR:1.822e+00/MeD:1.468e+00/MaD:4.047e+00/MW:0.553/MAW:0.447
|      0 |       1 |       2 |       3 |       4 |       5 |       6 |       7 |       8 |      9 |       10 |      11 |      12 |      13 |      14 |      15 |         16 |      17 |      18 |      19 |      20 |      21 |      22 |     23 |      24 |         25 |     26 |      27 |      28 |      29 |
|--------+---------+---------+---------+---------+---------+---------+---------+---------+--------+----------+---------+---------+---------+---------+---------+------------+---------+---------+---------+---------+---------+---------+--------+---------+------------+--------+---------+---------+---------|
|   0.11 |   0.172 |   0.174 |   0.182 |   0.122 |   0.146 |   0.182 |   0.187 |   0.145 |   0.21 |   0.0995 |   0.128 |   0.185 |   0.148 |   0.152 |   0.192 |   0.000246 |   0.165 |   0.172 |   0.191 |   0.198 |   0.161 |   0.157 |   0.2  |   0.182 |   0.000229 |   0.21 |   0.141 |   0.127 |   0.208 |
|   2.89 |   5.61  |   5.71  |   6.17  |   3.32  |   4.35  |   6.15  |   6.47  |   4.27  |   7.87 |   2.55   |   3.55  |   6.35  |   4.44  |   4.59  |   6.77  |   1        |   5.23  |   5.64  |   6.68  |   7.1   |   5.04  |   4.85  |   7.26 |   6.18  |   1        |   7.92 |   4.1   |   3.51  |   7.73  |
|   0.73 |   0.68  |   0.57  |   0.66  |   0.55  |   0.54  |   0.59  |   0.54  |   0.6   |   0.57 |   0.88   |   0.57  |   0.75  |   0.53  |   0.52  |   0.58  |  14.89     |   0.62  |   0.55  |   0.55  |   0.69  |   0.58  |   0.62  |   0.55 |   0.54  |  21.47     |   0.66 |   0.84  |   0.64  |   0.65  |
| nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan      | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan        | nan    | nan     | nan     | nan     |
| nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan      | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan        | nan    | nan     | nan     | nan     |
| nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan      | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan        | nan    | nan     | nan     | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_4C_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([14, 37, 37, 76, 37, 37, 80, 80, 76, 76, 80, 80, 76, 76, 37, 37, 14, 76,
        14, 14])
[14, 37, 76, 80]
TARGETS AFTER CLEANER:  tensor([0, 1, 1, 2, 1, 1, 3, 3, 2, 2, 3, 3, 2, 2, 1, 1, 0, 2, 0, 0])
400
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 400
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([80, 76, 14, 76, 80, 14, 37, 37, 80, 37, 80, 76, 80, 76, 14, 14, 37, 76,
        76, 14])
[14, 37, 76, 80]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 2, 3, 0, 1, 1, 3, 1, 3, 2, 3, 2, 0, 0, 1, 2, 2, 0])
2000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([80, 76, 14, 76, 80, 14, 37, 37, 80, 37, 80, 76, 80, 76, 14, 14, 37, 76,
        76, 14])
[14, 37, 76, 80]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 2, 3, 0, 1, 1, 3, 1, 3, 2, 3, 2, 0, 0, 1, 2, 2, 0])
2000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  2000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_4C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.54e-01	time: 00:00:22	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:-1.511e-03/SW:5.120e-01/MR:1.490e+01/SR:2.142e+00/MeD:1.708e+00/MaD:7.042e+00/MW:0.693/MAW:0.307
|        0 |        1 |        2 |        3 |        4 |        5 |       6 |        7 |        8 |        9 |       10 |       11 |       12 |       13 |       14 |       15 |       16 |       17 |       18 |       19 |       20 |       21 |       22 |       23 |       24 |      25 |       26 |       27 |       28 |       29 |
|----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------|
|   0.0194 |   0.0177 |   0.0189 |   0.0188 |   0.0138 |   0.0182 |   0.019 |   0.0192 |   0.0191 |   0.0194 |   0.0184 |   0.0174 |   0.0173 |   0.0188 |   0.0205 |   0.0178 |   0.0194 |   0.0175 |   0.0156 |   0.0177 |   0.0195 |   0.0187 |   0.0172 |   0.0188 |   0.0153 |   0.019 |   0.0194 |   0.0174 |   0.0171 |   0.0192 |
|  16.03   |  13.46   |  15.23   |  15.19   |   8.67   |  14.24   |  15.37  |  15.79   |  15.59   |  16.02   |  14.49   |  13.15   |  12.93   |  15.09   |  17.88   |  13.63   |  15.99   |  13.3    |  10.74   |  13.59   |  16.26   |  14.93   |  12.8    |  15.1    |  10.33   |  15.42  |  16.02   |  13.12   |  12.74   |  15.74   |
|   0.29   |   0.21   |   0.3    |   0.32   |   0.74   |   0.2    |   0.29  |   0.26   |   0.16   |   0.21   |   0.28   |   0.34   |   0.52   |   0.22   |   0.21   |   0.34   |   0.18   |   0.24   |   0.31   |   0.23   |   0.24   |   0.52   |   0.5    |   0.33   |   0.7    |   0.48  |   0.17   |   0.3    |   0.12   |   0.35   |
| nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_4C_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([14, 37, 37, 76, 37, 37, 80, 80, 76, 76, 80, 80, 76, 76, 37, 37, 14, 76,
        14, 14])
[14, 37, 76, 80]
TARGETS AFTER CLEANER:  tensor([0, 1, 1, 2, 1, 1, 3, 3, 2, 2, 3, 3, 2, 2, 1, 1, 0, 2, 0, 0])
400
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 400
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([80, 76, 14, 76, 80, 14, 37, 37, 80, 37, 80, 76, 80, 76, 14, 14, 37, 76,
        76, 14])
[14, 37, 76, 80]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 2, 3, 0, 1, 1, 3, 1, 3, 2, 3, 2, 0, 0, 1, 2, 2, 0])
2000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([80, 76, 14, 76, 80, 14, 37, 37, 80, 37, 80, 76, 80, 76, 14, 14, 37, 76,
        76, 14])
[14, 37, 76, 80]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 2, 3, 0, 1, 1, 3, 1, 3, 2, 3, 2, 0, 0, 1, 2, 2, 0])
2000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  2000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_4C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.58e-02	time: 00:00:34	Acc_train 0.00	Acc_test 0.00	convergence: 2.11e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:4.720e-04/SW:3.779e-01/MR:2.207e+01/SR:2.554e+00/MeD:2.058e+00/MaD:9.384e+00/MW:0.472/MAW:0.528
|        0 |        1 |        2 |        3 |        4 |        5 |        6 |        7 |      8 |        9 |       10 |       11 |       12 |       13 |       14 |       15 |       16 |       17 |       18 |       19 |       20 |       21 |       22 |      23 |       24 |       25 |      26 |       27 |       28 |       29 |
|----------+----------+----------+----------+----------+----------+----------+----------+--------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+---------+----------+----------+----------|
|   0.0482 |   0.0472 |   0.0476 |   0.0465 |   0.0464 |   0.0444 |   0.0502 |   0.0397 |   0.05 |   0.0489 |   0.0456 |   0.0462 |   0.0465 |   0.0403 |   0.0439 |   0.0455 |   0.0452 |   0.0514 |   0.0456 |   0.0471 |   0.0464 |   0.0455 |   0.0342 |   0.046 |   0.0456 |   0.0405 |   0.044 |   0.0454 |   0.0433 |   0.0447 |
|  24.25   |  23.32   |  23.62   |  22.62   |  22.49   |  20.68   |  26.23   |  16.75   |  25.95 |  24.89   |  21.82   |  22.38   |  22.62   |  17.26   |  20.3    |  21.7    |  21.4    |  27.44   |  21.78   |  23.17   |  22.5    |  21.67   |  12.68   |  22.13  |  21.77   |  17.42   |  20.36  |  21.6    |  19.72   |  21.01   |
|   0.04   |   0.05   |   0.07   |   0.01   |   0.02   |   0.06   |   0.07   |   0.03   |   0.03 |   0.02   |   0.1    |   0.09   |   0.16   |   0.1    |   0.18   |   0.04   |   0.01   |   0.06   |   0.14   |   0.04   |   0.01   |   0.06   |   0.41   |   0.04  |   0.07   |   0.05   |   0.07  |   0.04   |   0.06   |   0.05   |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan    | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan    | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan    | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_4C_CL/models
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([14, 37, 37, 76, 37, 37, 80, 80, 76, 76, 80, 80, 76, 76, 37, 37, 14, 76,
        14, 14])
[14, 37, 76, 80]
TARGETS AFTER CLEANER:  tensor([0, 1, 1, 2, 1, 1, 3, 3, 2, 2, 3, 3, 2, 2, 1, 1, 0, 2, 0, 0])
400
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 400
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([80, 76, 14, 76, 80, 14, 37, 37, 80, 37, 80, 76, 80, 76, 14, 14, 37, 76,
        76, 14])
[14, 37, 76, 80]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 2, 3, 0, 1, 1, 3, 1, 3, 2, 3, 2, 0, 0, 1, 2, 2, 0])
2000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([80, 76, 14, 76, 80, 14, 37, 37, 80, 37, 80, 76, 80, 76, 14, 14, 37, 76,
        76, 14])
[14, 37, 76, 80]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 2, 3, 0, 1, 1, 3, 1, 3, 2, 3, 2, 0, 0, 1, 2, 2, 0])
2000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  2000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Accuracy of the network on the 1st dataset: 41.750 %
Test loss on the 1st dataset: 0.147

