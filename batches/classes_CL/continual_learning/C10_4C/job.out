BLOCKS:  {'b0': {'arch': 'CNN', 'preset': 'softkrotov-c96-k5-p2-s1-d1-b0-t1-lr0.08-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 0, 'batch_norm': False, 'pool': {'type': 'max', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 0.7}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5}}, 'b1': {'arch': 'CNN', 'preset': 'softkrotov-c384-k3-p1-s1-d1-b0-t0.65-lr0.005-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 1, 'batch_norm': False, 'pool': {'type': 'max', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 1.4}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3}}, 'b2': {'arch': 'CNN', 'preset': 'softkrotov-c1536-k3-p1-s1-d1-b0-t0.25-lr0.01-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 2, 'batch_norm': False, 'pool': {'type': 'avg', 'kernel_size': 2, 'stride': 2, 'padding': 0}, 'activation': {'function': 'triangle', 'param': 1.0}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3}}, 'b3': {'arch': 'MLP', 'preset': 'BP-c10', 'operation': 'flatten', 'num': 3, 'att_dropout': None, 'dropout': 0.5, 'layer': {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.25, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10}, 'pool': None, 'activation': None}}
CL:  True
{'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True}
CL:  True
{'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.11048543456039805, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 4, 'in_channels': 24576, 'old_channels': 1536, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=4, bias=True)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 6, 1, 6, 1, 6, 4, 2, 4, 6, 6, 4, 2, 4, 1, 4, 6, 6, 6, 4])
[1, 2, 4, 6]
TARGETS AFTER CLEANER:  tensor([3, 3, 0, 3, 0, 3, 2, 1, 2, 3, 3, 2, 1, 2, 0, 2, 3, 3, 3, 2])
4000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 4000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 4, 1, 1, 2, 4, 2, 2, 6, 4, 6, 6, 2, 6, 4, 1, 4, 2, 2, 1])
[1, 2, 4, 6]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 0, 1, 2, 1, 1, 3, 2, 3, 3, 1, 3, 2, 0, 2, 1, 1, 0])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 4, 1, 1, 2, 4, 2, 2, 6, 4, 6, 6, 2, 6, 4, 1, 4, 2, 2, 1])
[1, 2, 4, 6]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 0, 1, 2, 1, 1, 3, 2, 3, 3, 1, 3, 2, 0, 2, 1, 1, 0])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  20000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_4C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.37e-01	time: 00:00:42	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.121e-02/SW:5.156e-01/MR:4.223e+00/SR:1.462e+00/MeD:1.141e+00/MaD:3.538e+00/MW:0.576/MAW:0.424
|       0 |       1 |       2 |       3 |       4 |       5 |       6 |       7 |       8 |       9 |       10 |      11 |      12 |      13 |      14 |      15 |         16 |     17 |      18 |      19 |      20 |     21 |      22 |      23 |      24 |      25 |      26 |      27 |       28 |      29 |
|---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+----------+---------+---------+---------+---------+---------+------------+--------+---------+---------+---------+--------+---------+---------+---------+---------+---------+---------+----------+---------|
|   0.109 |   0.129 |   0.129 |   0.145 |   0.135 |   0.114 |   0.158 |   0.155 |   0.141 |   0.158 |   0.0013 |   0.125 |   0.159 |   0.145 |   0.139 |   0.162 |   4.78e-05 |   0.15 |   0.158 |   0.172 |   0.202 |   0.17 |   0.129 |   0.181 |   0.169 |   8e-07 |   0.188 |   0.132 |   0.0818 |   0.183 |
|   2.87  |   3.61  |   3.6   |   4.28  |   3.86  |   3.04  |   4.89  |   4.74  |   4.1   |   4.88  |   1      |   3.43  |   4.93  |   4.29  |   4.04  |   5.12  |   1        |   4.53 |   4.89  |   5.64  |   7.35  |   5.54 |   3.61  |   6.12  |   5.47  |   1     |   6.54  |   3.73  |   2.05   |   6.22  |
|   0.6   |   0.51  |   0.54  |   0.62  |   0.61  |   0.71  |   0.53  |   0.54  |   0.64  |   0.51  |   3.59   |   0.53  |   0.56  |   0.51  |   0.61  |   0.5   |  15.12     |   0.6  |   0.55  |   0.63  |   0.63  |   0.66 |   0.58  |   0.58  |   0.57  |  21.66  |   0.46  |   1.12  |   0.56   |   0.6   |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan      | nan     | nan     | nan     | nan     | nan     | nan        | nan    | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan      | nan     |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan      | nan     | nan     | nan     | nan     | nan     | nan        | nan    | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan      | nan     |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan      | nan     | nan     | nan     | nan     | nan     | nan        | nan    | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan      | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 6, 1, 6, 1, 6, 4, 2, 4, 6, 6, 4, 2, 4, 1, 4, 6, 6, 6, 4])
[1, 2, 4, 6]
TARGETS AFTER CLEANER:  tensor([3, 3, 0, 3, 0, 3, 2, 1, 2, 3, 3, 2, 1, 2, 0, 2, 3, 3, 3, 2])
4000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 4000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 4, 1, 1, 2, 4, 2, 2, 6, 4, 6, 6, 2, 6, 4, 1, 4, 2, 2, 1])
[1, 2, 4, 6]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 0, 1, 2, 1, 1, 3, 2, 3, 3, 1, 3, 2, 0, 2, 1, 1, 0])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 4, 1, 1, 2, 4, 2, 2, 6, 4, 6, 6, 2, 6, 4, 1, 4, 2, 2, 1])
[1, 2, 4, 6]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 0, 1, 2, 1, 1, 3, 2, 3, 3, 1, 3, 2, 0, 2, 1, 1, 0])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  20000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_4C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.37e-01	time: 00:01:23	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:5.450e-03/SW:1.874e-01/MR:5.365e+00/SR:1.262e+00/MeD:9.852e-01/MaD:4.365e+00/MW:0.536/MAW:0.464
|         0 |         1 |        2 |         3 |        4 |        5 |        6 |         7 |        8 |      9 |        10 |       11 |        12 |       13 |       14 |       15 |        16 |     17 |        18 |        19 |       20 |       21 |       22 |       23 |         24 |       25 |       26 |        27 |      28 |        29 |
|-----------+-----------+----------+-----------+----------+----------+----------+-----------+----------+--------+-----------+----------+-----------+----------+----------+----------+-----------+--------+-----------+-----------+----------+----------+----------+----------+------------+----------+----------+-----------+---------+-----------|
|   0.00993 |   0.00897 |   0.0095 |   0.00792 |   0.0072 |   0.0106 |   0.0102 |   0.00922 |   0.0109 |   0.01 |   0.00903 |   0.0109 |   0.00654 |   0.0128 |   0.0107 |   0.0107 |   0.00897 |   0.01 |   0.00712 |   0.00943 |   0.0118 |   0.0123 |   0.0115 |   0.0129 |   7.88e-05 |   0.0117 |   0.0106 |   0.00913 |   0.011 |   0.00782 |
|   4.94    |   4.22    |   4.61   |   3.51    |   3.07   |   5.47   |   5.12   |   4.4     |   5.79   |   5.02 |   4.26    |   5.74   |   2.71    |   7.51   |   5.54   |   5.55   |   4.22    |   5.03 |   3.03    |   4.56    |   6.6    |   7      |   6.26   |   7.62   |   1        |   6.51   |   5.46   |   4.34    |   5.83  |   3.44    |
|   0.23    |   0.16    |   0.19   |   0.23    |   0.72   |   0.23   |   0.21   |   0.26    |   0.22   |   0.21 |   0.27    |   0.29   |   0.29    |   0.21   |   0.2    |   0.21   |   0.16    |   0.29 |   0.27    |   0.23    |   0.18   |   0.31   |   0.43   |   0.27   |   4.38     |   0.48   |   0.2    |   0.2     |   0.17  |   0.28    |
| nan       | nan       | nan      | nan       | nan      | nan      | nan      | nan       | nan      | nan    | nan       | nan      | nan       | nan      | nan      | nan      | nan       | nan    | nan       | nan       | nan      | nan      | nan      | nan      | nan        | nan      | nan      | nan       | nan     | nan       |
| nan       | nan       | nan      | nan       | nan      | nan      | nan      | nan       | nan      | nan    | nan       | nan      | nan       | nan      | nan      | nan      | nan       | nan    | nan       | nan       | nan      | nan      | nan      | nan      | nan        | nan      | nan      | nan       | nan     | nan       |
| nan       | nan       | nan      | nan       | nan      | nan      | nan      | nan       | nan      | nan    | nan       | nan      | nan       | nan      | nan      | nan      | nan       | nan    | nan       | nan       | nan      | nan      | nan      | nan      | nan        | nan      | nan      | nan       | nan     | nan       |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 6, 1, 6, 1, 6, 4, 2, 4, 6, 6, 4, 2, 4, 1, 4, 6, 6, 6, 4])
[1, 2, 4, 6]
TARGETS AFTER CLEANER:  tensor([3, 3, 0, 3, 0, 3, 2, 1, 2, 3, 3, 2, 1, 2, 0, 2, 3, 3, 3, 2])
4000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 4000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 4, 1, 1, 2, 4, 2, 2, 6, 4, 6, 6, 2, 6, 4, 1, 4, 2, 2, 1])
[1, 2, 4, 6]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 0, 1, 2, 1, 1, 3, 2, 3, 3, 1, 3, 2, 0, 2, 1, 1, 0])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 4, 1, 1, 2, 4, 2, 2, 6, 4, 6, 6, 2, 6, 4, 1, 4, 2, 2, 1])
[1, 2, 4, 6]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 0, 1, 2, 1, 1, 3, 2, 3, 3, 1, 3, 2, 0, 2, 1, 1, 0])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  20000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_4C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.23e-02	time: 00:02:06	Acc_train 0.00	Acc_test 0.00	convergence: 1.80e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:3.674e-03/SW:3.260e-01/MR:1.899e+01/SR:2.612e+00/MeD:2.068e+00/MaD:1.797e+01/MW:0.408/MAW:0.592
|        0 |        1 |        2 |        3 |       4 |        5 |        6 |        7 |        8 |        9 |       10 |       11 |       12 |       13 |       14 |       15 |       16 |       17 |       18 |       19 |       20 |       21 |       22 |       23 |       24 |       25 |       26 |      27 |       28 |       29 |
|----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------|
|   0.0449 |   0.0453 |   0.0452 |   0.0406 |   0.042 |   0.0431 |   0.0467 |   0.0365 |   0.0431 |   0.0473 |   0.0432 |   0.0408 |   0.0439 |   0.0386 |   0.0422 |   0.0426 |   0.0434 |   0.0465 |   0.0416 |   0.0447 |   0.0409 |   0.0386 |   0.0356 |   0.0448 |   0.0401 |   0.0334 |   0.0408 |   0.043 |   0.0374 |   0.0414 |
|  21.19   |  21.55   |  21.46   |  17.45   |  18.67  |  19.56   |  22.79   |  14.29   |  19.57   |  23.39   |  19.64   |  17.61   |  20.3    |  15.9    |  18.82   |  19.17   |  19.84   |  22.64   |  18.28   |  20.95   |  17.71   |  15.87   |  13.64   |  21.08   |  17.07   |  12.17   |  17.69   |  19.52  |  14.95   |  18.16   |
|   0.05   |   0.03   |   0.05   |   0.05   |   0.03  |   0.04   |   0.06   |   0.04   |   0.07   |   0.06   |   0.09   |   0.07   |   0.16   |   0.05   |   0.15   |   0.03   |   0.04   |   0.09   |   0.07   |   0.03   |   0.1    |   0.07   |   0.23   |   0.05   |   0.07   |   0.07   |   0.07   |   0.06  |   0.05   |   0.03   |
| nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      |
| nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      |
| nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models

 ********** Supervised learning of blocks [3] **********
SAVING FOLDER FOR SUP:  C10_4C_CL
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 6, 1, 6, 1, 6, 4, 2, 4, 6, 6, 4, 2, 4, 1, 4, 6, 6, 6, 4])
[1, 2, 4, 6]
TARGETS AFTER CLEANER:  tensor([3, 3, 0, 3, 0, 3, 2, 1, 2, 3, 3, 2, 1, 2, 0, 2, 3, 3, 3, 2])
4000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 4000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 4, 1, 1, 2, 4, 2, 2, 6, 4, 6, 6, 2, 6, 4, 1, 4, 2, 2, 1])
[1, 2, 4, 6]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 0, 1, 2, 1, 1, 3, 2, 3, 3, 1, 3, 2, 0, 2, 1, 1, 0])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 4, 1, 1, 2, 4, 2, 2, 6, 4, 6, 6, 2, 6, 4, 1, 4, 2, 2, 1])
[1, 2, 4, 6]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 0, 1, 2, 1, 1, 3, 2, 3, 3, 1, 3, 2, 0, 2, 1, 1, 0])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  20000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Epoch: [1/50]	lr: 1.00e-03	time: 00:02:43	Loss_train 0.18003	Acc_train 74.95	/	Loss_test 0.00589	Acc_test 84.68
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
Epoch: [10/50]	lr: 1.00e-03	time: 00:02:55	Loss_train 0.14731	Acc_train 85.36	/	Loss_test 0.00959	Acc_test 88.88
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
Epoch: [20/50]	lr: 2.50e-04	time: 00:03:09	Loss_train 0.10249	Acc_train 90.15	/	Loss_test 0.00759	Acc_test 89.97
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
Epoch: [30/50]	lr: 1.25e-04	time: 00:03:23	Loss_train 0.07341	Acc_train 91.66	/	Loss_test 0.00737	Acc_test 90.25
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
Epoch: [40/50]	lr: 3.13e-05	time: 00:03:37	Loss_train 0.05956	Acc_train 92.60	/	Loss_test 0.00697	Acc_test 90.28
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
Epoch: [50/50]	lr: 7.81e-06	time: 00:03:50	Loss_train 0.05612	Acc_train 92.81	/	Loss_test 0.00663	Acc_test 90.65
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
RESULT:  {'train_loss': 0.05612042918801308, 'train_acc': 92.80850291252136, 'test_loss': 0.006625505164265633, 'test_acc': 90.6500015258789, 'convergence': 17.988773345947266, 'R1': 0, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [1, 2, 4, 6]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [1, 2, 4, 6]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}
IN R1:  {'R1': {'train_loss': 0.05612042918801308, 'train_acc': 92.80850291252136, 'test_loss': 0.006625505164265633, 'test_acc': 90.6500015258789, 'convergence': 17.988773345947266, 'R1': 0, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [1, 2, 4, 6]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [1, 2, 4, 6]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.11048543456039805, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 4, 'in_channels': 24576, 'old_channels': 1536, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 Model C10_4C_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=4, bias=True)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([3, 8, 8, 3, 9, 5, 9, 8, 5, 8, 9, 5, 9, 5, 5, 9, 9, 5, 5, 9])
[3, 5, 8, 9]
TARGETS AFTER CLEANER:  tensor([0, 2, 2, 0, 3, 1, 3, 2, 1, 2, 3, 1, 3, 1, 1, 3, 3, 1, 1, 3])
4000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 4000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 8, 3, 9, 9, 9, 3, 3, 3, 5, 9, 3, 3, 3, 3, 5, 9, 5, 9])
[3, 5, 8, 9]
TARGETS AFTER CLEANER:  tensor([3, 3, 2, 0, 3, 3, 3, 0, 0, 0, 1, 3, 0, 0, 0, 0, 1, 3, 1, 3])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 8, 3, 9, 9, 9, 3, 3, 3, 5, 9, 3, 3, 3, 3, 5, 9, 5, 9])
[3, 5, 8, 9]
TARGETS AFTER CLEANER:  tensor([3, 3, 2, 0, 3, 3, 3, 0, 0, 0, 1, 3, 0, 0, 0, 0, 1, 3, 1, 3])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  20000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_4C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.47e-01	time: 00:00:40	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.015e-02/SW:5.901e-01/MR:4.806e+00/SR:1.746e+00/MeD:1.312e+00/MaD:4.951e+00/MW:0.615/MAW:0.385
|       0 |       1 |       2 |       3 |       4 |       5 |       6 |       7 |       8 |      9 |         10 |     11 |      12 |      13 |      14 |      15 |         16 |      17 |      18 |      19 |      20 |      21 |      22 |      23 |      24 |         25 |      26 |      27 |      28 |      29 |
|---------+---------+---------+---------+---------+---------+---------+---------+---------+--------+------------+--------+---------+---------+---------+---------+------------+---------+---------+---------+---------+---------+---------+---------+---------+------------+---------+---------+---------+---------|
|   0.123 |   0.132 |   0.125 |   0.155 |   0.175 |   0.118 |   0.167 |   0.161 |   0.182 |   0.17 |   0.000946 |   0.18 |   0.141 |   0.151 |   0.139 |   0.171 |   5.52e-05 |   0.215 |   0.168 |   0.175 |   0.155 |   0.166 |   0.162 |   0.198 |   0.195 |   4.78e-05 |   0.213 |   0.107 |   0.146 |   0.183 |
|   3.35  |   3.7   |   3.45  |   4.73  |   5.78  |   3.16  |   5.37  |   5.04  |   6.16  |   5.52 |   1        |   6.08 |   4.11  |   4.55  |   4.02  |   5.56  |   1        |   8.2   |   5.43  |   5.8   |   4.75  |   5.3   |   5.1   |   7.13  |   6.93  |   1        |   8.06  |   2.79  |   4.34  |   6.22  |
|   0.57  |   0.5   |   0.53  |   0.55  |   0.5   |   0.51  |   0.35  |   0.48  |   0.53  |   0.46 |   2.03     |   0.54 |   0.32  |   0.45  |   0.46  |   0.44  |  21.71     |   0.52  |   0.46  |   0.46  |   0.35  |   0.49  |   0.48  |   0.56  |   0.53  |  26.17     |   0.31  |   0.56  |   0.6   |   0.38  |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan        | nan    | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan        | nan    | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan        | nan    | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([3, 8, 8, 3, 9, 5, 9, 8, 5, 8, 9, 5, 9, 5, 5, 9, 9, 5, 5, 9])
[3, 5, 8, 9]
TARGETS AFTER CLEANER:  tensor([0, 2, 2, 0, 3, 1, 3, 2, 1, 2, 3, 1, 3, 1, 1, 3, 3, 1, 1, 3])
4000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 4000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 8, 3, 9, 9, 9, 3, 3, 3, 5, 9, 3, 3, 3, 3, 5, 9, 5, 9])
[3, 5, 8, 9]
TARGETS AFTER CLEANER:  tensor([3, 3, 2, 0, 3, 3, 3, 0, 0, 0, 1, 3, 0, 0, 0, 0, 1, 3, 1, 3])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 8, 3, 9, 9, 9, 3, 3, 3, 5, 9, 3, 3, 3, 3, 5, 9, 5, 9])
[3, 5, 8, 9]
TARGETS AFTER CLEANER:  tensor([3, 3, 2, 0, 3, 3, 3, 0, 0, 0, 1, 3, 0, 0, 0, 0, 1, 3, 1, 3])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  20000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_4C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.47e-01	time: 00:01:21	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:5.346e-03/SW:1.761e-01/MR:4.950e+00/SR:1.524e+00/MeD:1.199e+00/MaD:3.950e+00/MW:0.590/MAW:0.410
|         0 |       1 |         2 |         3 |         4 |      5 |         6 |         7 |        8 |        9 |       10 |        11 |        12 |       13 |        14 |        15 |       16 |        17 |       18 |       19 |       20 |       21 |       22 |       23 |         24 |       25 |        26 |        27 |       28 |       29 |
|-----------+---------+-----------+-----------+-----------+--------+-----------+-----------+----------+----------+----------+-----------+-----------+----------+-----------+-----------+----------+-----------+----------+----------+----------+----------+----------+----------+------------+----------+-----------+-----------+----------+----------|
|   0.00436 |   0.011 |   0.00784 |   0.00142 |   0.00135 |   0.01 |   0.00975 |   0.00883 |   0.0107 |   0.0104 |   0.0102 |   0.00925 |   0.00152 |   0.0115 |   0.00946 |   0.00916 |   0.0097 |   0.00828 |   0.0114 |   0.0116 |   0.0113 |   0.0119 |   0.0111 |   0.0124 |   2.28e-05 |   0.0113 |   0.00693 |   0.00972 |   0.0123 |   0.0072 |
|   1.76    |   5.82  |   3.46    |   1.08    |   1.07    |   5.03 |   4.81    |   4.12    |   5.61   |   5.31   |   5.16   |   4.42    |   1.09    |   6.29   |   4.58    |   4.36    |   4.77   |   3.74    |   6.18   |   6.42   |   6.09   |   6.66   |   5.93   |   7.13   |   1        |   6.11   |   2.92    |   4.78    |   7      |   3.07   |
|   0.2     |   0.11  |   0.16    |   0.39    |   0.45    |   0.16 |   0.16    |   0.15    |   0.18   |   0.17   |   0.16   |   0.16    |   0.34    |   0.21   |   0.16    |   0.15    |   0.15   |   0.15    |   0.1    |   0.13   |   0.22   |   0.14   |   0.2    |   0.23   |  11.44     |   0.21   |   0.09    |   0.13    |   0.16   |   0.12   |
| nan       | nan     | nan       | nan       | nan       | nan    | nan       | nan       | nan      | nan      | nan      | nan       | nan       | nan      | nan       | nan       | nan      | nan       | nan      | nan      | nan      | nan      | nan      | nan      | nan        | nan      | nan       | nan       | nan      | nan      |
| nan       | nan     | nan       | nan       | nan       | nan    | nan       | nan       | nan      | nan      | nan      | nan       | nan       | nan      | nan       | nan       | nan      | nan       | nan      | nan      | nan      | nan      | nan      | nan      | nan        | nan      | nan       | nan       | nan      | nan      |
| nan       | nan     | nan       | nan       | nan       | nan    | nan       | nan       | nan      | nan      | nan      | nan       | nan       | nan      | nan       | nan       | nan      | nan       | nan      | nan      | nan      | nan      | nan      | nan      | nan        | nan      | nan       | nan       | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([3, 8, 8, 3, 9, 5, 9, 8, 5, 8, 9, 5, 9, 5, 5, 9, 9, 5, 5, 9])
[3, 5, 8, 9]
TARGETS AFTER CLEANER:  tensor([0, 2, 2, 0, 3, 1, 3, 2, 1, 2, 3, 1, 3, 1, 1, 3, 3, 1, 1, 3])
4000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 4000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 8, 3, 9, 9, 9, 3, 3, 3, 5, 9, 3, 3, 3, 3, 5, 9, 5, 9])
[3, 5, 8, 9]
TARGETS AFTER CLEANER:  tensor([3, 3, 2, 0, 3, 3, 3, 0, 0, 0, 1, 3, 0, 0, 0, 0, 1, 3, 1, 3])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 8, 3, 9, 9, 9, 3, 3, 3, 5, 9, 3, 3, 3, 3, 5, 9, 5, 9])
[3, 5, 8, 9]
TARGETS AFTER CLEANER:  tensor([3, 3, 2, 0, 3, 3, 3, 0, 0, 0, 1, 3, 0, 0, 0, 0, 1, 3, 1, 3])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  20000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_4C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.08e-02	time: 00:02:04	Acc_train 0.00	Acc_test 0.00	convergence: 1.67e+01	R1: 1	Info MB:0.000e+00/SB:0.000e+00/MW:8.034e-03/SW:3.035e-01/MR:1.774e+01/SR:1.986e+00/MeD:1.552e+00/MaD:1.674e+01/MW:0.430/MAW:0.570
|        0 |        1 |        2 |        3 |        4 |        5 |        6 |        7 |        8 |        9 |       10 |       11 |       12 |      13 |      14 |       15 |       16 |       17 |       18 |       19 |       20 |      21 |       22 |       23 |       24 |       25 |       26 |       27 |       28 |       29 |
|----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------+---------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------|
|   0.0404 |   0.0434 |   0.0441 |   0.0392 |   0.0418 |   0.0424 |   0.0399 |   0.0394 |   0.0384 |   0.0439 |   0.0434 |   0.0391 |   0.0416 |   0.039 |   0.041 |   0.0384 |   0.0422 |   0.0407 |   0.0414 |   0.0431 |   0.0418 |   0.039 |   0.0385 |   0.0409 |   0.0382 |   0.0361 |   0.0419 |   0.0401 |   0.0393 |   0.0408 |
|  17.31   |  19.8    |  20.49   |  16.34   |  18.51   |  19.01   |  16.9    |  16.49   |  15.73   |  20.25   |  19.81   |  16.28   |  18.27   |  16.25  |  17.79  |  15.74   |  18.85   |  17.6    |  18.15   |  19.54   |  18.46   |  16.22  |  15.8    |  17.74   |  15.62   |  14.03   |  18.55   |  17.05   |  16.43   |  17.66   |
|   0.06   |   0.04   |   0.04   |   0.08   |   0.05   |   0.05   |   0.05   |   0.03   |   0.06   |   0.09   |   0.06   |   0.06   |   0.08   |   0.04  |   0.08  |   0.04   |   0.06   |   0.08   |   0.06   |   0.05   |   0.05   |   0.06  |   0.03   |   0.06   |   0.09   |   0.06   |   0.06   |   0.08   |   0.04   |   0.04   |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models

 ********** Supervised learning of blocks [3] **********
SAVING FOLDER FOR SUP:  C10_4C_CL
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([3, 8, 8, 3, 9, 5, 9, 8, 5, 8, 9, 5, 9, 5, 5, 9, 9, 5, 5, 9])
[3, 5, 8, 9]
TARGETS AFTER CLEANER:  tensor([0, 2, 2, 0, 3, 1, 3, 2, 1, 2, 3, 1, 3, 1, 1, 3, 3, 1, 1, 3])
4000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 4000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 8, 3, 9, 9, 9, 3, 3, 3, 5, 9, 3, 3, 3, 3, 5, 9, 5, 9])
[3, 5, 8, 9]
TARGETS AFTER CLEANER:  tensor([3, 3, 2, 0, 3, 3, 3, 0, 0, 0, 1, 3, 0, 0, 0, 0, 1, 3, 1, 3])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 8, 3, 9, 9, 9, 3, 3, 3, 5, 9, 3, 3, 3, 3, 5, 9, 5, 9])
[3, 5, 8, 9]
TARGETS AFTER CLEANER:  tensor([3, 3, 2, 0, 3, 3, 3, 0, 0, 0, 1, 3, 0, 0, 0, 0, 1, 3, 1, 3])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  20000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Epoch: [1/50]	lr: 1.00e-03	time: 00:02:41	Loss_train 0.67293	Acc_train 66.98	/	Loss_test 0.02366	Acc_test 75.97
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
Epoch: [10/50]	lr: 1.00e-03	time: 00:02:53	Loss_train 0.25362	Acc_train 82.07	/	Loss_test 0.01555	Acc_test 84.07
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
Epoch: [20/50]	lr: 2.50e-04	time: 00:03:07	Loss_train 0.14252	Acc_train 87.51	/	Loss_test 0.01104	Acc_test 85.65
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
Epoch: [30/50]	lr: 1.25e-04	time: 00:03:20	Loss_train 0.10167	Acc_train 89.28	/	Loss_test 0.01051	Acc_test 86.00
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
Epoch: [40/50]	lr: 3.13e-05	time: 00:03:34	Loss_train 0.08376	Acc_train 90.15	/	Loss_test 0.00929	Acc_test 86.38
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
Epoch: [50/50]	lr: 7.81e-06	time: 00:03:48	Loss_train 0.07819	Acc_train 90.42	/	Loss_test 0.00918	Acc_test 86.20
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
RESULT:  {'train_loss': 0.07818624377250671, 'train_acc': 90.41849970817566, 'test_loss': 0.009179115295410156, 'test_acc': 86.19999694824219, 'convergence': 16.739124298095703, 'R1': 1, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [3, 5, 8, 9]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [3, 5, 8, 9]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}
IN R2:  {'R1': {'train_loss': 0.05612042918801308, 'train_acc': 92.80850291252136, 'test_loss': 0.006625505164265633, 'test_acc': 90.6500015258789, 'convergence': 17.988773345947266, 'R1': 0, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [1, 2, 4, 6]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [1, 2, 4, 6]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}, 'R2': {'train_loss': 0.07818624377250671, 'train_acc': 90.41849970817566, 'test_loss': 0.009179115295410156, 'test_acc': 86.19999694824219, 'convergence': 16.739124298095703, 'R1': 1, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [3, 5, 8, 9]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [3, 5, 8, 9]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.11048543456039805, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 4, 'in_channels': 24576, 'old_channels': 1536, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 Model C10_4C_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=4, bias=True)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 6, 1, 6, 1, 6, 4, 2, 4, 6, 6, 4, 2, 4, 1, 4, 6, 6, 6, 4])
[1, 2, 4, 6]
TARGETS AFTER CLEANER:  tensor([3, 3, 0, 3, 0, 3, 2, 1, 2, 3, 3, 2, 1, 2, 0, 2, 3, 3, 3, 2])
4000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 4000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 4, 1, 1, 2, 4, 2, 2, 6, 4, 6, 6, 2, 6, 4, 1, 4, 2, 2, 1])
[1, 2, 4, 6]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 0, 1, 2, 1, 1, 3, 2, 3, 3, 1, 3, 2, 0, 2, 1, 1, 0])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 4, 1, 1, 2, 4, 2, 2, 6, 4, 6, 6, 2, 6, 4, 1, 4, 2, 2, 1])
[1, 2, 4, 6]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 0, 1, 2, 1, 1, 3, 2, 3, 3, 1, 3, 2, 0, 2, 1, 1, 0])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  20000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_4C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.39e-01	time: 00:00:40	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.132e-02/SW:5.435e-01/MR:4.430e+00/SR:1.599e+00/MeD:1.238e+00/MaD:3.847e+00/MW:0.578/MAW:0.422
|       0 |       1 |       2 |       3 |       4 |       5 |       6 |       7 |      8 |       9 |        10 |      11 |      12 |      13 |      14 |      15 |         16 |      17 |      18 |      19 |     20 |      21 |      22 |      23 |      24 |         25 |      26 |      27 |      28 |      29 |
|---------+---------+---------+---------+---------+---------+---------+---------+--------+---------+-----------+---------+---------+---------+---------+---------+------------+---------+---------+---------+--------+---------+---------+---------+---------+------------+---------+---------+---------+---------|
|   0.207 |   0.158 |   0.119 |   0.124 |   0.152 |   0.101 |   0.145 |   0.152 |   0.17 |   0.175 |   0.00154 |   0.157 |   0.129 |   0.136 |   0.133 |   0.167 |   0.000172 |   0.167 |   0.156 |   0.174 |   0.17 |   0.171 |   0.138 |   0.153 |   0.185 |   0.000135 |   0.183 |   0.062 |   0.159 |   0.187 |
|   7.68  |   4.88  |   3.2   |   3.4   |   4.63  |   2.59  |   4.3   |   4.63  |   5.52 |   5.77  |   1       |   4.85  |   3.6   |   3.89  |   3.78  |   5.38  |   1        |   5.33  |   4.8   |   5.74  |   5.49 |   5.56  |   3.97  |   4.66  |   6.37  |   1        |   6.24  |   1.6   |   4.94  |   6.48  |
|   0.58  |   0.54  |   0.6   |   0.59  |   0.51  |   0.59  |   0.34  |   0.53  |   0.53 |   0.55  |   3.7     |   0.53  |   0.34  |   0.49  |   0.51  |   0.49  |  18.93     |   0.43  |   0.53  |   0.5   |   0.4  |   0.55  |   0.51  |   0.55  |   0.54  |  26.04     |   0.33  |   0.48  |   0.53  |   0.42  |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan       | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan       | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan       | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 6, 1, 6, 1, 6, 4, 2, 4, 6, 6, 4, 2, 4, 1, 4, 6, 6, 6, 4])
[1, 2, 4, 6]
TARGETS AFTER CLEANER:  tensor([3, 3, 0, 3, 0, 3, 2, 1, 2, 3, 3, 2, 1, 2, 0, 2, 3, 3, 3, 2])
4000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 4000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 4, 1, 1, 2, 4, 2, 2, 6, 4, 6, 6, 2, 6, 4, 1, 4, 2, 2, 1])
[1, 2, 4, 6]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 0, 1, 2, 1, 1, 3, 2, 3, 3, 1, 3, 2, 0, 2, 1, 1, 0])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 4, 1, 1, 2, 4, 2, 2, 6, 4, 6, 6, 2, 6, 4, 1, 4, 2, 2, 1])
[1, 2, 4, 6]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 0, 1, 2, 1, 1, 3, 2, 3, 3, 1, 3, 2, 0, 2, 1, 1, 0])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  20000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_4C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.39e-01	time: 00:01:21	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:5.854e-03/SW:1.566e-01/MR:4.364e+00/SR:1.478e+00/MeD:1.170e+00/MaD:3.688e+00/MW:0.576/MAW:0.424
|         0 |         1 |         2 |          3 |          4 |         5 |         6 |        7 |         8 |        9 |        10 |        11 |         12 |       13 |        14 |        15 |        16 |        17 |        18 |        19 |       20 |       21 |       22 |       23 |         24 |       25 |        26 |       27 |       28 |       29 |
|-----------+-----------+-----------+------------+------------+-----------+-----------+----------+-----------+----------+-----------+-----------+------------+----------+-----------+-----------+-----------+-----------+-----------+-----------+----------+----------+----------+----------+------------+----------+-----------+----------+----------+----------|
|   0.00189 |   0.00871 |   0.00744 |   0.000183 |   0.000864 |   0.00915 |   0.00847 |   0.0111 |   0.00979 |   0.0102 |   0.00941 |   0.00378 |   0.000794 |   0.0114 |   0.00911 |   0.00836 |   0.00968 |   0.00998 |   0.00976 |   0.00947 |   0.0105 |   0.0101 |   0.0115 |   0.0118 |   2.82e-05 |   0.0103 |   0.00554 |   0.0101 |   0.0108 |   0.0088 |
|   1.14    |   4.04    |   3.21    |   1        |   1.03     |   4.35    |   3.87    |   5.95   |   4.83    |   5.14   |   4.54    |   1.57    |   1.03     |   6.15   |   4.32    |   3.79    |   4.75    |   4.99    |   4.81    |   4.59    |   5.42   |   5.07   |   6.31   |   6.54   |   1        |   5.22   |   2.23    |   5.08   |   5.7    |   4.1    |
|   0.27    |   0.16    |   0.11    |   1.46     |   0.44     |   0.16    |   0.1     |   0.1    |   0.19    |   0.19   |   0.14    |   0.21    |   0.43     |   0.18   |   0.15    |   0.17    |   0.14    |   0.11    |   0.19    |   0.17    |   0.2    |   0.16   |   0.21   |   0.22   |  10.92     |   0.2    |   0.07    |   0.15   |   0.22   |   0.07   |
| nan       | nan       | nan       | nan        | nan        | nan       | nan       | nan      | nan       | nan      | nan       | nan       | nan        | nan      | nan       | nan       | nan       | nan       | nan       | nan       | nan      | nan      | nan      | nan      | nan        | nan      | nan       | nan      | nan      | nan      |
| nan       | nan       | nan       | nan        | nan        | nan       | nan       | nan      | nan       | nan      | nan       | nan       | nan        | nan      | nan       | nan       | nan       | nan       | nan       | nan       | nan      | nan      | nan      | nan      | nan        | nan      | nan       | nan      | nan      | nan      |
| nan       | nan       | nan       | nan        | nan        | nan       | nan       | nan      | nan       | nan      | nan       | nan       | nan        | nan      | nan       | nan       | nan       | nan       | nan       | nan       | nan      | nan      | nan      | nan      | nan        | nan      | nan       | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 6, 1, 6, 1, 6, 4, 2, 4, 6, 6, 4, 2, 4, 1, 4, 6, 6, 6, 4])
[1, 2, 4, 6]
TARGETS AFTER CLEANER:  tensor([3, 3, 0, 3, 0, 3, 2, 1, 2, 3, 3, 2, 1, 2, 0, 2, 3, 3, 3, 2])
4000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 4000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 4, 1, 1, 2, 4, 2, 2, 6, 4, 6, 6, 2, 6, 4, 1, 4, 2, 2, 1])
[1, 2, 4, 6]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 0, 1, 2, 1, 1, 3, 2, 3, 3, 1, 3, 2, 0, 2, 1, 1, 0])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 4, 1, 1, 2, 4, 2, 2, 6, 4, 6, 6, 2, 6, 4, 1, 4, 2, 2, 1])
[1, 2, 4, 6]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 0, 1, 2, 1, 1, 3, 2, 3, 3, 1, 3, 2, 0, 2, 1, 1, 0])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  20000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_4C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 3.99e-02	time: 00:02:04	Acc_train 0.00	Acc_test 0.00	convergence: 1.60e+01	R1: 1	Info MB:0.000e+00/SB:0.000e+00/MW:1.209e-02/SW:2.900e-01/MR:1.695e+01/SR:1.961e+00/MeD:1.515e+00/MaD:1.595e+01/MW:0.428/MAW:0.572
|        0 |        1 |        2 |       3 |        4 |        5 |        6 |        7 |        8 |        9 |       10 |       11 |       12 |      13 |       14 |       15 |       16 |      17 |       18 |      19 |     20 |       21 |       22 |       23 |       24 |       25 |     26 |      27 |       28 |       29 |
|----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+---------+----------+---------+--------+----------+----------+----------+----------+----------+--------+---------+----------+----------|
|   0.0368 |   0.0427 |   0.0419 |   0.036 |   0.0402 |   0.0444 |   0.0388 |   0.0397 |   0.0391 |   0.0434 |   0.0404 |   0.0391 |   0.0405 |   0.038 |   0.0409 |   0.0378 |   0.0403 |   0.041 |   0.0408 |   0.042 |   0.04 |   0.0375 |   0.0314 |   0.0384 |   0.0377 |   0.0383 |   0.04 |   0.039 |   0.0387 |   0.0381 |
|  14.56   |  19.19   |  18.53   |  13.94  |  17.15   |  20.74   |  16.08   |  16.79   |  16.27   |  19.82   |  17.34   |  16.27   |  17.37   |  15.41  |  17.69   |  15.32   |  17.22   |  17.78  |  17.66   |  18.65  |  17.03 |  15.03   |  10.85   |  15.72   |  15.2    |  15.68   |  17    |  16.24  |  15.99   |  15.5    |
|   0.05   |   0.05   |   0.06   |   0.06  |   0.05   |   0.05   |   0.04   |   0.03   |   0.04   |   0.07   |   0.09   |   0.04   |   0.09   |   0.05  |   0.06   |   0.04   |   0.05   |   0.08  |   0.05   |   0.06  |   0.05 |   0.06   |   0.04   |   0.05   |   0.07   |   0.05   |   0.04 |   0.08  |   0.05   |   0.05   |
| nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan     | nan      | nan     | nan    | nan      | nan      | nan      | nan      | nan      | nan    | nan     | nan      | nan      |
| nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan     | nan      | nan     | nan    | nan      | nan      | nan      | nan      | nan      | nan    | nan     | nan      | nan      |
| nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan     | nan      | nan     | nan    | nan      | nan      | nan      | nan      | nan      | nan    | nan     | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 6, 1, 6, 1, 6, 4, 2, 4, 6, 6, 4, 2, 4, 1, 4, 6, 6, 6, 4])
[1, 2, 4, 6]
TARGETS AFTER CLEANER:  tensor([3, 3, 0, 3, 0, 3, 2, 1, 2, 3, 3, 2, 1, 2, 0, 2, 3, 3, 3, 2])
4000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 4000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 4, 1, 1, 2, 4, 2, 2, 6, 4, 6, 6, 2, 6, 4, 1, 4, 2, 2, 1])
[1, 2, 4, 6]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 0, 1, 2, 1, 1, 3, 2, 3, 3, 1, 3, 2, 0, 2, 1, 1, 0])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 4, 1, 1, 2, 4, 2, 2, 6, 4, 6, 6, 2, 6, 4, 1, 4, 2, 2, 1])
[1, 2, 4, 6]
TARGETS AFTER CLEANER:  tensor([3, 2, 0, 0, 1, 2, 1, 1, 3, 2, 3, 3, 1, 3, 2, 0, 2, 1, 1, 0])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  20000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Accuracy of the network on the 1st dataset: 15.225 %
Test loss on the 1st dataset: 0.207

