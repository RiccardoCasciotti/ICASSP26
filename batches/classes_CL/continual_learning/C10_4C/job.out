--------------- /leonardo/prod/opt/modulefiles/deeplrn/libraries ---------------
cineca-ai/3.0.0  cineca-ai/4.0.0  cineca-ai/4.1.1(default)  
cineca-ai/3.0.1  cineca-ai/4.1.0  cineca-ai/4.3.0           

Key:
(symbolic-version)  
The device used will be: 
True
cuda:0
BLOCKS:  {'b0': {'arch': 'CNN', 'preset': 'softkrotov-c96-k5-p2-s1-d1-b0-t1-lr0.08-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 0, 'batch_norm': False, 'pool': {'type': 'max', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 0.7}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5}}, 'b1': {'arch': 'CNN', 'preset': 'softkrotov-c384-k3-p1-s1-d1-b0-t0.65-lr0.005-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 1, 'batch_norm': False, 'pool': {'type': 'max', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 1.4}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3}}, 'b2': {'arch': 'CNN', 'preset': 'softkrotov-c1536-k3-p1-s1-d1-b0-t0.25-lr0.01-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 2, 'batch_norm': False, 'pool': {'type': 'avg', 'kernel_size': 2, 'stride': 2, 'padding': 0}, 'activation': {'function': 'triangle', 'param': 1.0}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3}}, 'b3': {'arch': 'MLP', 'preset': 'BP-c10', 'operation': 'flatten', 'num': 3, 'att_dropout': None, 'dropout': 0.5, 'layer': {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.25, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10}, 'pool': None, 'activation': None}}
CL:  True
{'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True}
CL:  True
{'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}

 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=4, bias=True)
[Sequential(
  (0): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=0.7)
  )
  (1): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=1.4)
  )
  (2): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (activation): Triangle(power=1.0)
  )
  (3): BasicBlock(
    (operations): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
    )
    (layer): Linear(in_features=24576, out_features=4, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
)]
LAYER NAME:  Sequential(
  (0): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=0.7)
  )
  (1): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=1.4)
  )
  (2): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (activation): Triangle(power=1.0)
  )
  (3): BasicBlock(
    (operations): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
    )
    (layer): Linear(in_features=24576, out_features=4, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
)
LAYER CHILDREN:  [BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
  (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
  (activation): Triangle(power=0.7)
), BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
  (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
  (activation): Triangle(power=1.4)
), BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (activation): Triangle(power=1.0)
), BasicBlock(
  (operations): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
  )
  (layer): Linear(in_features=24576, out_features=4, bias=True)
  (dropout): Dropout(p=0.5, inplace=False)
)]
subsubl NAME:  Sequential(
  (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
subsubl NAME:  Triangle(power=0.7)
subsubl NAME:  Sequential(
  (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
subsubl NAME:  Triangle(power=1.4)
subsubl NAME:  Sequential(
  (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  AvgPool2d(kernel_size=2, stride=2, padding=0)
subsubl NAME:  Triangle(power=1.0)
subsubl NAME:  Sequential(
  (0): Flatten(start_dim=1, end_dim=-1)
)
subsubl NAME:  Linear(in_features=24576, out_features=4, bias=True)
subsubl NAME:  Dropout(p=0.5, inplace=False)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([3, 0, 1, 3, 1, 0, 5, 5, 0, 5, 0, 5, 5, 1, 5, 5, 0, 3, 0, 3])
[0, 1, 3, 5]
TARGETS AFTER CLEANER:  tensor([2, 0, 1, 2, 1, 0, 3, 3, 0, 3, 0, 3, 3, 1, 3, 3, 0, 2, 0, 2])
4000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 4000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([1, 1, 3, 3, 3, 3, 5, 0, 0, 1, 3, 0, 3, 3, 3, 5, 1, 1, 1, 0])
[0, 1, 3, 5]
TARGETS AFTER CLEANER:  tensor([1, 1, 2, 2, 2, 2, 3, 0, 0, 1, 2, 0, 2, 2, 2, 3, 1, 1, 1, 0])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([1, 1, 3, 3, 3, 3, 5, 0, 0, 1, 3, 0, 3, 3, 3, 5, 1, 1, 1, 0])
[0, 1, 3, 5]
TARGETS AFTER CLEANER:  tensor([1, 1, 2, 2, 2, 2, 3, 0, 0, 1, 2, 0, 2, 2, 2, 3, 1, 1, 1, 0])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  20000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_4C_CL
DEPTH:  3
WTA IN delta_weight:  tensor([[[-4.0133e-39, -5.1473e-39, -5.0215e-39,  ..., -6.9709e-39,
          -4.3569e-39, -3.5405e-39],
         [-9.1174e-39, -5.6200e-39, -6.0194e-39,  ..., -6.0002e-39,
          -9.5777e-39, -1.0962e-38],
         [-4.9599e-39, -5.3155e-39, -6.8733e-39,  ..., -7.8070e-39,
          -9.1331e-39, -4.4961e-39],
         ...,
         [-5.9605e-29, -2.0636e-29, -1.0944e-31,  ..., -1.3069e-38,
          -1.1308e-38, -1.1999e-38],
         [-4.6457e-29, -1.5156e-29, -2.6839e-30,  ..., -9.0992e-39,
          -4.6818e-39, -9.5786e-39],
         [-4.3805e-29, -7.3134e-29, -1.3862e-28,  ..., -6.6457e-39,
          -4.9611e-39, -8.2450e-39]],

        [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         ...,
         [-6.0256e-44, -7.0065e-44, -4.2039e-45,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         [-6.3058e-44, -7.2868e-44, -7.0065e-45,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         [-7.5670e-44, -6.7262e-44, -1.1210e-44,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00]],

        [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         ...,
         [-2.5181e-42, -3.9110e-41, -9.7008e-41,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         [-1.9576e-42, -8.6923e-42, -4.6341e-42,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         [-3.6378e-42, -3.9362e-42, -6.6281e-43,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00]],

        ...,

        [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         ...,
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00]],

        [[-4.2039e-45, -4.2039e-45, -2.8026e-45,  ..., -2.8026e-45,
          -2.8026e-45, -2.8026e-45],
         [-9.8091e-45, -7.0065e-45, -7.0065e-45,  ..., -4.2039e-45,
          -1.1210e-44, -9.8091e-45],
         [-4.2039e-45, -4.2039e-45, -4.2039e-45,  ..., -4.2039e-45,
          -4.2039e-45, -2.8026e-45],
         ...,
         [-1.5383e-33, -9.6375e-33, -4.0851e-34,  ..., -4.2039e-45,
          -5.6052e-45, -1.1210e-44],
         [-1.2105e-33, -1.7138e-33, -1.0778e-34,  ..., -4.2039e-45,
          -2.8026e-45, -9.8091e-45],
         [-8.1272e-34, -4.0080e-33, -3.6720e-34,  ..., -4.2039e-45,
          -4.2039e-45, -7.0065e-45]],

        [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         ...,
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00]]], device='cuda:0')
LAYER_NUM:  0
FINAL_SUM:  [43, 77, 26, 11, 91, 46, 87, 34, 84, 35]
acts len:  3
acts keys:  ['conv0', 'conv1', 'conv2']
acts:  {'conv0': [43, 77, 26, 11, 91, 46, 87, 34, 84, 35, 30, 55, 4, 15, 42, 67, 37, 66, 39, 92, 40], 'conv1': [98, 19, 61, 330, 260, 300, 317, 324, 158, 204, 110, 63, 180, 59, 65, 254, 67, 49, 214, 225, 359], 'conv2': [660, 1065, 1132, 537, 1471, 1284, 1149, 1285, 1016, 870, 117, 1174, 605, 903, 832, 1113, 1222, 525, 557, 130, 1409]}
final_sum len:  96
delta_weights INFO: 
NUM OF TRACKED COV LAYERS:  1
NUM OF TRACKED WEIGHTS CHANGES PER LAYER:  20
avg_deltas INFO:  <class 'dict'>
avg_deltas keys:  ['blocks.0.layer.weight', 'blocks.1.layer.weight', 'blocks.2.layer.weight']
avg_deltas size:  3
num of averages for 0 layer:  torch.Size([96])
################################################
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.41e-01	time: 00:00:42	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:3.116e-03/SW:5.600e-01/MR:4.530e+00/SR:1.738e+00/MeD:1.368e+00/MaD:4.240e+00/MW:0.587/MAW:0.413
|       0 |       1 |       2 |       3 |        4 |       5 |       6 |       7 |       8 |       9 |        10 |       11 |      12 |      13 |     14 |      15 |     16 |      17 |      18 |      19 |      20 |      21 |      22 |      23 |      24 |     25 |      26 |     27 |       28 |      29 |
|---------+---------+---------+---------+----------+---------+---------+---------+---------+---------+-----------+----------+---------+---------+--------+---------+--------+---------+---------+---------+---------+---------+---------+---------+---------+--------+---------+--------+----------+---------|
|   0.102 |   0.105 |   0.137 |   0.169 |   0.0599 |   8e-07 |   0.137 |   0.186 |   0.146 |   0.203 |   0.00366 |   0.0124 |   0.158 |   0.147 |   0.14 |   0.169 |   0.14 |   0.168 |   0.165 |   0.175 |   0.178 |   0.157 |   0.173 |   0.186 |   0.176 |   0.16 |   0.174 |   0.19 |   0.0259 |   0.138 |
|   2.64  |   2.71  |   3.94  |   5.44  |   1.56   |   1     |   3.93  |   6.42  |   4.35  |   7.43  |   1       |   1.02   |   4.88  |   4.36  |   4.07 |   5.46  |   4.06 |   5.4   |   5.27  |   5.8   |   5.93  |   4.85  |   5.66  |   6.43  |   5.83  |   5    |   5.73  |   6.64 |   1.11   |   3.97  |
|   0.55  |   0.43  |   0.44  |   0.5   |   2.15   |  15.53  |   0.49  |   0.42  |   0.65  |   0.42  |   1.19    |   1.43   |   0.55  |   0.43  |   0.58 |   0.39  |   1.16 |   0.51  |   0.49  |   0.62  |   0.55  |   0.58  |   0.51  |   0.44  |   0.48  |   1.01 |   0.41  |   0.64 |   1.06   |   0.83  |
| nan     | nan     | nan     | nan     | nan      | nan     | nan     | nan     | nan     | nan     | nan       | nan      | nan     | nan     | nan    | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan    | nan      | nan     |
| nan     | nan     | nan     | nan     | nan      | nan     | nan     | nan     | nan     | nan     | nan       | nan      | nan     | nan     | nan    | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan    | nan      | nan     |
| nan     | nan     | nan     | nan     | nan      | nan     | nan     | nan     | nan     | nan     | nan       | nan      | nan     | nan     | nan    | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan    | nan      | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([3, 0, 1, 3, 1, 0, 5, 5, 0, 5, 0, 5, 5, 1, 5, 5, 0, 3, 0, 3])
[0, 1, 3, 5]
TARGETS AFTER CLEANER:  tensor([2, 0, 1, 2, 1, 0, 3, 3, 0, 3, 0, 3, 3, 1, 3, 3, 0, 2, 0, 2])
4000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 4000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([1, 1, 3, 3, 3, 3, 5, 0, 0, 1, 3, 0, 3, 3, 3, 5, 1, 1, 1, 0])
[0, 1, 3, 5]
TARGETS AFTER CLEANER:  tensor([1, 1, 2, 2, 2, 2, 3, 0, 0, 1, 2, 0, 2, 2, 2, 3, 1, 1, 1, 0])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([1, 1, 3, 3, 3, 3, 5, 0, 0, 1, 3, 0, 3, 3, 3, 5, 1, 1, 1, 0])
[0, 1, 3, 5]
TARGETS AFTER CLEANER:  tensor([1, 1, 2, 2, 2, 2, 3, 0, 0, 1, 2, 0, 2, 2, 2, 3, 1, 1, 1, 0])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  20000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_4C_CL
DEPTH:  3
ACTIVATIONS SHAPE:  tensor([[-1.1204e+01,  3.0415e+01, -5.4820e+01, -1.0391e+02, -5.4150e+01,
         -5.5702e+01, -4.5655e+01, -9.0866e+01, -1.3368e+02, -1.4407e+02,
         -1.0211e+02, -7.1757e+01, -8.3704e+01, -7.5037e+01, -5.9341e+01,
         -1.4364e+01],
        [ 2.9226e+01,  3.8474e+01,  2.3799e+01, -2.5551e+01, -5.6717e+01,
         -6.2479e+01, -5.8192e+01, -1.0588e+02, -1.4060e+02, -1.8039e+02,
         -9.2952e+01, -1.0278e+02, -9.5748e+01, -8.5056e+01, -4.8110e+01,
         -8.6167e+00],
        [-8.1265e+00, -5.6984e+01, -4.4167e+01, -1.8643e+01,  1.0016e+00,
         -4.9975e+01, -7.3441e+01, -6.6612e+01, -1.2550e+02, -1.9101e+02,
         -1.5878e+02, -1.2399e+02, -1.3539e+02, -9.1883e+01, -7.6590e+01,
         -5.8076e+00],
        [-4.6993e+01, -1.1261e+02, -1.0594e+02, -5.9478e+01, -4.0170e+01,
         -7.9142e+01, -1.3667e+02, -1.4358e+02, -1.4587e+02, -2.1917e+02,
         -1.7478e+02, -1.4622e+02, -1.8490e+02, -1.5471e+02, -1.0136e+02,
         -2.2339e+01],
        [ 6.0428e+00, -1.9964e+01, -5.0472e+01, -1.0273e+02, -7.8775e+01,
         -7.3971e+01, -1.7476e+02, -2.1283e+02, -1.9523e+02, -1.6361e+02,
         -9.1783e+01, -1.0832e+02, -1.7092e+02, -1.9466e+02, -1.4489e+02,
         -3.1480e+01],
        [ 2.9870e+01,  6.2976e+01,  2.7415e+01, -8.7755e+01, -1.6994e+02,
         -1.6647e+02, -1.9058e+02, -1.7342e+02, -1.5085e+02, -1.2058e+02,
         -5.0282e+01, -8.3928e+01, -2.2116e+02, -2.3738e+02, -1.7218e+02,
         -3.6270e+01],
        [-1.1294e+01, -1.4869e+01,  3.2152e+01, -3.3681e+01, -2.0213e+02,
         -1.7136e+02, -1.9462e+02, -1.9501e+02, -2.4351e+02, -1.9987e+02,
         -8.3798e+01, -1.1847e+02, -1.8573e+02, -2.0192e+02, -1.3591e+02,
         -6.0917e+01],
        [-2.5132e+01, -1.0436e+01, -3.0373e+01, -1.1365e+02, -1.3858e+02,
         -1.3758e+02, -1.3990e+02, -1.6642e+02, -2.2954e+02, -1.5230e+02,
         -2.0355e+02, -1.4315e+02, -6.8570e+01, -8.0748e+01, -1.3440e+02,
         -4.8486e+01],
        [-2.6298e+01,  5.3541e+01, -4.8963e+01, -1.7209e+02, -1.1596e+02,
          4.3360e+01,  1.1495e+01, -2.9901e+01, -1.0462e+02, -1.0927e+02,
         -1.3505e+02, -1.1926e+02, -7.3744e+01, -4.5342e+01, -3.3726e+01,
          6.5671e+01],
        [ 1.2614e+01,  5.1735e+01, -2.9014e+01, -1.0627e+02, -5.5196e+01,
          8.0016e+01, -2.1678e+01, -8.3237e+01, -1.1259e+02, -8.3696e+01,
         -1.4169e+02, -1.5800e+02, -1.5242e+02, -1.1431e+02, -7.7921e+00,
          1.2875e+02],
        [ 3.2379e+01,  2.8895e+00, -5.7107e+01, -1.3783e+02, -9.1977e+01,
         -3.0293e+01, -6.2828e+01, -1.4896e+02, -1.1840e+02, -1.3274e+02,
         -9.9704e+01, -1.7103e+02, -1.8508e+02, -1.8601e+02, -5.8820e+01,
          3.5138e+01],
        [-2.6991e+01, -3.8952e+01, -8.1555e+01, -1.1594e+02, -6.9800e+01,
         -1.0170e+02, -1.5217e+02, -1.8825e+02, -1.9609e+02, -1.6738e+02,
         -1.7854e+02, -1.6841e+02, -1.4167e+02, -8.7763e+01, -6.3381e+00,
          8.8036e+01],
        [-1.9202e+01,  8.4427e+00,  3.1181e+01, -3.4191e+01, -3.7361e-02,
         -3.8886e+01, -8.6088e+01, -1.8965e+02, -1.7578e+02, -1.5300e+02,
         -1.6737e+02, -1.6588e+02, -1.4096e+02, -2.9616e+01,  2.8569e+01,
          3.3593e+01],
        [-1.1564e+01,  4.5408e+00, -4.3504e+00, -3.6373e+01, -6.6839e+01,
         -1.0178e+02, -1.3212e+02, -1.5361e+02, -1.2037e+02, -1.0692e+02,
         -8.9270e+01, -1.2033e+02, -1.2147e+02, -7.0983e+01, -7.4666e+01,
         -1.6604e+01],
        [ 1.1903e+01,  3.6182e+01, -9.0740e+00, -8.2123e+01, -1.2524e+02,
         -1.6044e+02, -1.6582e+02, -1.2634e+02, -1.0909e+02, -8.4296e+01,
         -5.6018e+01, -2.2495e+01, -3.1780e+01, -5.1301e+01, -1.0263e+02,
         -1.7623e+01],
        [-2.5397e+01, -1.3152e+01, -4.1056e+01, -1.2348e+02, -1.2846e+02,
         -1.5562e+02, -1.5189e+02, -1.3263e+02, -1.2322e+02, -1.3105e+02,
         -9.7455e+01, -8.7643e+01, -1.0167e+02, -1.0847e+02, -9.4725e+01,
         -6.4003e+01]], device='cuda:0')
LAYER_NUM:  1
FINAL_SUM:  [78, 204, 61, 300, 77, 260, 92, 359, 32, 151]
acts len:  3
acts keys:  ['conv0', 'conv1', 'conv2']
acts:  {'conv0': [43, 77, 26, 11, 91, 46, 87, 34, 84, 35, 30, 55, 4, 15, 42, 67, 37, 66, 39, 92, 40], 'conv1': [78, 204, 61, 300, 77, 260, 92, 359, 32, 151, 210, 63, 349, 243, 332, 49, 116, 112, 53, 330, 19], 'conv2': [660, 1065, 1132, 537, 1471, 1284, 1149, 1285, 1016, 870, 117, 1174, 605, 903, 832, 1113, 1222, 525, 557, 130, 1409]}
final_sum len:  384
delta_weights INFO: 
NUM OF TRACKED COV LAYERS:  1
NUM OF TRACKED WEIGHTS CHANGES PER LAYER:  20
avg_deltas INFO:  <class 'dict'>
avg_deltas keys:  ['blocks.0.layer.weight', 'blocks.1.layer.weight', 'blocks.2.layer.weight']
avg_deltas size:  3
num of averages for 1 layer:  torch.Size([96])
################################################
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.41e-01	time: 00:01:30	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:4.348e-03/SW:1.935e-01/MR:5.511e+00/SR:1.420e+00/MeD:1.099e+00/MaD:4.510e+00/MW:0.544/MAW:0.456
|        0 |        1 |         2 |         3 |         4 |         5 |        6 |         7 |        8 |        9 |       10 |       11 |      12 |       13 |       14 |       15 |        16 |       17 |        18 |       19 |       20 |       21 |       22 |       23 |       24 |       25 |       26 |        27 |       28 |        29 |
|----------+----------+-----------+-----------+-----------+-----------+----------+-----------+----------+----------+----------+----------+---------+----------+----------+----------+-----------+----------+-----------+----------+----------+----------+----------+----------+----------+----------+----------+-----------+----------+-----------|
|   0.0111 |   0.0094 |   0.00956 |   0.00519 |   0.00875 |   0.00737 |   0.0115 |   0.00784 |   0.0117 |   0.0108 |   0.0112 |   0.0114 |   0.011 |   0.0108 |   0.0109 |   0.0106 |   0.00887 |   0.0112 |   0.00531 |   0.0124 |   0.0138 |   0.0122 |   0.0117 |   0.0124 |   0.0119 |   0.0128 |   0.0113 |   0.00985 |   0.0113 |   0.00814 |
|   5.97   |   4.53   |   4.66    |   2.08    |   4.06    |   3.18    |   6.31   |   3.46    |   6.5    |   5.69   |   6.03   |   6.23   |   5.8   |   5.7    |   5.72   |   5.5    |   4.14    |   6.05   |   2.13    |   7.11   |   8.6    |   6.96   |   6.46   |   7.14   |   6.68   |   7.59   |   6.1    |   4.88    |   6.15   |   3.65    |
|   0.17   |   0.18   |   0.27    |   0.23    |   0.62    |   0.16    |   0.2    |   0.21    |   0.18   |   0.16   |   0.18   |   0.23   |   0.28  |   0.22   |   0.2    |   0.17   |   0.16    |   0.25   |   0.24    |   0.42   |   0.14   |   0.2    |   0.38   |   0.2    |   0.44   |   0.34   |   0.13   |   0.18    |   0.24   |   0.28    |
| nan      | nan      | nan       | nan       | nan       | nan       | nan      | nan       | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan       | nan      | nan       | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan       |
| nan      | nan      | nan       | nan       | nan       | nan       | nan      | nan       | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan       | nan      | nan       | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan       |
| nan      | nan      | nan       | nan       | nan       | nan       | nan      | nan       | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan       | nan      | nan       | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan       |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([3, 0, 1, 3, 1, 0, 5, 5, 0, 5, 0, 5, 5, 1, 5, 5, 0, 3, 0, 3])
[0, 1, 3, 5]
TARGETS AFTER CLEANER:  tensor([2, 0, 1, 2, 1, 0, 3, 3, 0, 3, 0, 3, 3, 1, 3, 3, 0, 2, 0, 2])
4000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 4000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([1, 1, 3, 3, 3, 3, 5, 0, 0, 1, 3, 0, 3, 3, 3, 5, 1, 1, 1, 0])
[0, 1, 3, 5]
TARGETS AFTER CLEANER:  tensor([1, 1, 2, 2, 2, 2, 3, 0, 0, 1, 2, 0, 2, 2, 2, 3, 1, 1, 1, 0])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([1, 1, 3, 3, 3, 3, 5, 0, 0, 1, 3, 0, 3, 3, 3, 5, 1, 1, 1, 0])
[0, 1, 3, 5]
TARGETS AFTER CLEANER:  tensor([1, 1, 2, 2, 2, 2, 3, 0, 0, 1, 2, 0, 2, 2, 2, 3, 1, 1, 1, 0])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  20000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_4C_CL
DEPTH:  3
ACTIVATIONS SHAPE:  tensor([[-3.8709e+00,  3.6953e+00, -1.3395e+01, -2.2961e+01, -8.3311e+00,
         -8.5525e+00, -1.1843e+01, -2.3191e+01, -3.4527e+01, -3.6851e+01,
         -3.0402e+01, -2.6275e+01, -2.7381e+01, -2.6588e+01, -2.7454e+01,
         -1.4442e+01],
        [ 8.1385e+00,  9.6748e+00,  8.4037e+00, -1.2478e+00, -7.7349e+00,
         -7.9184e+00, -1.0780e+01, -2.1560e+01, -3.1234e+01, -4.2935e+01,
         -2.5338e+01, -3.0935e+01, -2.9263e+01, -2.6217e+01, -2.1889e+01,
         -1.1416e+01],
        [ 3.3443e+00, -1.0531e+01, -8.7337e-01,  8.9934e+00,  1.4823e+01,
          3.4514e+00, -4.8730e+00, -2.1891e+00, -1.5601e+01, -3.3911e+01,
         -3.1538e+01, -3.2771e+01, -3.3893e+01, -2.4033e+01, -2.2472e+01,
         -4.8370e+00],
        [-1.3703e-01, -1.6052e+01, -8.7443e+00,  4.5184e+00,  9.9847e+00,
          3.1529e+00, -1.0926e+01, -9.8386e+00, -7.9147e+00, -2.6630e+01,
         -2.6226e+01, -3.1814e+01, -4.0936e+01, -3.2469e+01, -2.1580e+01,
          1.9306e-01],
        [ 2.4173e+01,  1.7845e+01,  1.0775e+01, -3.9981e-02,  9.8433e+00,
          1.2823e+01, -1.1439e+01, -1.8061e+01, -1.0378e+01, -5.8115e+00,
          2.1704e+00, -1.2918e+01, -3.1036e+01, -3.6911e+01, -2.6880e+01,
          3.5669e+00],
        [ 3.8221e+01,  4.6493e+01,  3.7474e+01,  7.2657e+00, -5.7381e+00,
         -1.5085e+00, -9.0197e+00, -6.4536e+00, -4.5903e-01,  5.7922e+00,
          1.7745e+01,  2.2234e+00, -3.5686e+01, -4.1985e+01, -2.8912e+01,
          6.3128e+00],
        [ 3.4136e+01,  2.9079e+01,  4.4127e+01,  2.4046e+01, -7.3235e+00,
          5.9195e-01, -5.3653e+00, -6.9741e+00, -1.9326e+01, -1.0451e+01,
          1.3813e+01,  1.5117e+00, -1.9168e+01, -2.5886e+01, -1.5176e+01,
          5.1026e+00],
        [ 2.9781e+01,  3.0019e+01,  2.9096e+01,  1.0330e+01,  1.1300e+01,
          1.3930e+01,  1.3261e+01,  4.6467e+00, -1.2091e+01,  2.2798e+00,
         -1.2265e+01,  2.2748e+00,  1.6201e+01,  1.0082e+01, -8.3579e+00,
          1.4138e+01],
        [ 2.8856e+01,  4.4069e+01,  2.1986e+01, -4.4586e+00,  1.9266e+01,
          5.9383e+01,  5.3023e+01,  4.1565e+01,  2.0221e+01,  1.4463e+01,
          5.0197e+00,  1.1618e+01,  2.0819e+01,  2.5736e+01,  2.5346e+01,
          5.0549e+01],
        [ 3.4784e+01,  4.1403e+01,  2.2859e+01,  7.9783e+00,  3.2769e+01,
          6.5846e+01,  4.1109e+01,  2.3226e+01,  1.7788e+01,  2.0812e+01,
          2.8648e+00, -2.3406e+00, -3.5926e+00,  7.2140e+00,  3.0845e+01,
          6.6458e+01],
        [ 3.6119e+01,  2.4875e+01,  1.2888e+01, -2.0661e+00,  1.7527e+01,
          3.5200e+01,  2.3285e+01,  2.7288e+00,  1.0631e+01,  4.2497e+00,
          9.2171e+00, -1.1968e+01, -1.4549e+01, -1.2874e+01,  1.2945e+01,
          4.0796e+01],
        [ 1.6120e+01,  1.0996e+01,  2.9674e+00, -1.7516e+00,  1.5414e+01,
          1.0754e+01, -1.7041e+00, -1.2016e+01, -1.0921e+01, -1.1091e+01,
         -1.9512e+01, -2.0369e+01, -1.5397e+01, -2.8647e-02,  1.5015e+01,
          4.5349e+01],
        [ 9.6562e+00,  1.6061e+01,  2.3708e+01,  9.8222e+00,  2.3644e+01,
          1.6535e+01,  6.4359e+00, -1.4601e+01, -1.3444e+01, -1.9336e+01,
         -3.1244e+01, -3.2754e+01, -2.7695e+01,  2.2342e+00,  1.4061e+01,
          2.3643e+01],
        [ 7.3018e+00,  9.2334e+00,  6.7842e+00, -1.0739e+00, -5.4461e+00,
         -1.2315e+01, -1.6484e+01, -1.9380e+01, -1.1911e+01, -1.5390e+01,
         -2.1400e+01, -3.0615e+01, -3.0934e+01, -1.6759e+01, -1.7063e+01,
          5.1379e+00],
        [ 8.8505e+00,  1.3211e+01, -1.1244e+00, -2.0423e+01, -2.8999e+01,
         -3.6265e+01, -3.4014e+01, -1.9994e+01, -1.7082e+01, -1.6064e+01,
         -1.4507e+01, -1.0220e+01, -1.0789e+01, -1.3305e+01, -2.6326e+01,
          3.3359e+00],
        [-1.1778e+00, -5.8689e-03, -1.2129e+01, -3.2901e+01, -3.2408e+01,
         -3.9427e+01, -3.4068e+01, -2.6474e+01, -2.5636e+01, -2.9965e+01,
         -2.6224e+01, -2.3498e+01, -2.5465e+01, -2.6386e+01, -2.2455e+01,
         -8.0101e+00]], device='cuda:0')
LAYER_NUM:  2
FINAL_SUM:  [268, 1458, 350, 205, 1113, 660, 1284, 1490, 1005, 1383]
acts len:  3
acts keys:  ['conv0', 'conv1', 'conv2']
acts:  {'conv0': [43, 77, 26, 11, 91, 46, 87, 34, 84, 35, 30, 55, 4, 15, 42, 67, 37, 66, 39, 92, 40], 'conv1': [78, 204, 61, 300, 77, 260, 92, 359, 32, 151, 210, 63, 349, 243, 332, 49, 116, 112, 53, 330, 19], 'conv2': [268, 1458, 350, 205, 1113, 660, 1284, 1490, 1005, 1383, 1323, 689, 1030, 1359, 537, 75, 61, 557, 964, 301, 924]}
final_sum len:  1536
delta_weights INFO: 
NUM OF TRACKED COV LAYERS:  1
NUM OF TRACKED WEIGHTS CHANGES PER LAYER:  20
avg_deltas INFO:  <class 'dict'>
avg_deltas keys:  ['blocks.0.layer.weight', 'blocks.1.layer.weight', 'blocks.2.layer.weight']
avg_deltas size:  3
num of averages for 2 layer:  torch.Size([96])
################################################
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.15e-02	time: 00:02:59	Acc_train 0.00	Acc_test 0.00	convergence: 1.74e+01	R1: 2	Info MB:0.000e+00/SB:0.000e+00/MW:4.669e-03/SW:3.152e-01/MR:1.837e+01/SR:2.497e+00/MeD:1.951e+00/MaD:1.736e+01/MW:0.425/MAW:0.575
|        0 |        1 |        2 |        3 |        4 |        5 |        6 |        7 |        8 |        9 |       10 |       11 |       12 |       13 |       14 |       15 |       16 |       17 |       18 |       19 |       20 |       21 |       22 |      23 |       24 |       25 |       26 |       27 |       28 |       29 |
|----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------|
|   0.0471 |   0.0474 |   0.0417 |   0.0386 |   0.0402 |   0.0394 |   0.0414 |   0.0365 |   0.0413 |   0.0461 |   0.0408 |   0.0371 |   0.0437 |   0.0376 |   0.0434 |   0.0379 |   0.0434 |   0.0467 |   0.0416 |   0.0436 |   0.0445 |   0.0422 |   0.0393 |   0.043 |   0.0403 |   0.0367 |   0.0425 |   0.0435 |   0.0431 |   0.0455 |
|  23.16   |  23.43   |  18.41   |  15.93   |  17.18   |  16.54   |  18.17   |  14.35   |  18.1    |  22.23   |  17.67   |  14.74   |  20.13   |  15.12   |  19.87   |  15.37   |  19.84   |  22.81   |  18.27   |  20.01   |  20.81   |  18.84   |  16.46   |  19.52  |  17.26   |  14.5    |  19.05   |  19.88   |  19.54   |  21.69   |
|   0.05   |   0.04   |   0.07   |   0.07   |   0.04   |   0.05   |   0.05   |   0.03   |   0.05   |   0.05   |   0.05   |   0.07   |   0.14   |   0.05   |   0.15   |   0.05   |   0.05   |   0.09   |   0.08   |   0.04   |   0.06   |   0.08   |   0.13   |   0.04  |   0.04   |   0.08   |   0.08   |   0.04   |   0.05   |   0.04   |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models

 ********** Supervised learning of blocks [3] **********
SAVING FOLDER FOR SUP:  C10_4C_CL
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([3, 0, 1, 3, 1, 0, 5, 5, 0, 5, 0, 5, 5, 1, 5, 5, 0, 3, 0, 3])
[0, 1, 3, 5]
TARGETS AFTER CLEANER:  tensor([2, 0, 1, 2, 1, 0, 3, 3, 0, 3, 0, 3, 3, 1, 3, 3, 0, 2, 0, 2])
4000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 4000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([1, 1, 3, 3, 3, 3, 5, 0, 0, 1, 3, 0, 3, 3, 3, 5, 1, 1, 1, 0])
[0, 1, 3, 5]
TARGETS AFTER CLEANER:  tensor([1, 1, 2, 2, 2, 2, 3, 0, 0, 1, 2, 0, 2, 2, 2, 3, 1, 1, 1, 0])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([1, 1, 3, 3, 3, 3, 5, 0, 0, 1, 3, 0, 3, 3, 3, 5, 1, 1, 1, 0])
[0, 1, 3, 5]
TARGETS AFTER CLEANER:  tensor([1, 1, 2, 2, 2, 2, 3, 0, 0, 1, 2, 0, 2, 2, 2, 3, 1, 1, 1, 0])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  20000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Epoch: [1/50]	lr: 1.00e-03	time: 00:03:30	Loss_train 0.20127	Acc_train 71.45	/	Loss_test 0.01067	Acc_test 74.43
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
Epoch: [10/50]	lr: 1.00e-03	time: 00:03:39	Loss_train 0.18096	Acc_train 81.47	/	Loss_test 0.01485	Acc_test 82.05
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
Epoch: [20/50]	lr: 2.50e-04	time: 00:03:48	Loss_train 0.13482	Acc_train 86.28	/	Loss_test 0.01111	Acc_test 83.80
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
Epoch: [30/50]	lr: 1.25e-04	time: 00:03:57	Loss_train 0.09502	Acc_train 88.29	/	Loss_test 0.00912	Acc_test 85.68
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
Epoch: [40/50]	lr: 3.13e-05	time: 00:04:07	Loss_train 0.07595	Acc_train 89.35	/	Loss_test 0.00863	Acc_test 85.75
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
Epoch: [50/50]	lr: 7.81e-06	time: 00:04:16	Loss_train 0.07102	Acc_train 89.54	/	Loss_test 0.00850	Acc_test 85.53
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
RESULT:  {'train_loss': 0.0710216760635376, 'train_acc': 89.54049944877625, 'test_loss': 0.00850343331694603, 'test_acc': 85.5250015258789, 'convergence': 17.365699768066406, 'R1': 2, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [0, 1, 3, 5]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [0, 1, 3, 5]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}
IN R1:  {'R1': {'train_loss': 0.0710216760635376, 'train_acc': 89.54049944877625, 'test_loss': 0.00850343331694603, 'test_acc': 85.5250015258789, 'convergence': 17.365699768066406, 'R1': 2, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [0, 1, 3, 5]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [0, 1, 3, 5]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}

 Model C10_4C_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=4, bias=True)
[Sequential(
  (0): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=0.7)
  )
  (1): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=1.4)
  )
  (2): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (activation): Triangle(power=1.0)
  )
  (3): BasicBlock(
    (operations): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
    )
    (layer): Linear(in_features=24576, out_features=4, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
)]
LAYER NAME:  Sequential(
  (0): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=0.7)
  )
  (1): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=1.4)
  )
  (2): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (activation): Triangle(power=1.0)
  )
  (3): BasicBlock(
    (operations): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
    )
    (layer): Linear(in_features=24576, out_features=4, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
)
LAYER CHILDREN:  [BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
  (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
  (activation): Triangle(power=0.7)
), BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
  (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
  (activation): Triangle(power=1.4)
), BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (activation): Triangle(power=1.0)
), BasicBlock(
  (operations): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
  )
  (layer): Linear(in_features=24576, out_features=4, bias=True)
  (dropout): Dropout(p=0.5, inplace=False)
)]
subsubl NAME:  Sequential(
  (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
subsubl NAME:  Triangle(power=0.7)
subsubl NAME:  Sequential(
  (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
subsubl NAME:  Triangle(power=1.4)
subsubl NAME:  Sequential(
  (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  AvgPool2d(kernel_size=2, stride=2, padding=0)
subsubl NAME:  Triangle(power=1.0)
subsubl NAME:  Sequential(
  (0): Flatten(start_dim=1, end_dim=-1)
)
subsubl NAME:  Linear(in_features=24576, out_features=4, bias=True)
subsubl NAME:  Dropout(p=0.5, inplace=False)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([8, 8, 7, 8, 7, 8, 7, 4, 2, 4, 4, 2, 4, 4, 7, 8, 8, 8, 7, 7])
[2, 4, 7, 8]
TARGETS AFTER CLEANER:  tensor([3, 3, 2, 3, 2, 3, 2, 1, 0, 1, 1, 0, 1, 1, 2, 3, 3, 3, 2, 2])
4000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 4000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([4, 2, 7, 8, 4, 7, 7, 2, 2, 4, 2, 4, 4, 7, 2, 2, 7, 2, 2, 7])
[2, 4, 7, 8]
TARGETS AFTER CLEANER:  tensor([1, 0, 2, 3, 1, 2, 2, 0, 0, 1, 0, 1, 1, 2, 0, 0, 2, 0, 0, 2])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([4, 2, 7, 8, 4, 7, 7, 2, 2, 4, 2, 4, 4, 7, 2, 2, 7, 2, 2, 7])
[2, 4, 7, 8]
TARGETS AFTER CLEANER:  tensor([1, 0, 2, 3, 1, 2, 2, 0, 0, 1, 0, 1, 1, 2, 0, 0, 2, 0, 0, 2])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  20000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_4C_CL
DEPTH:  3
ACTIVATIONS SHAPE:  tensor([[-1252.5422, -1114.0719, -1216.8542, -1613.7346, -1772.9581, -1691.4126,
         -1615.0886, -1730.3971, -1632.5461, -1547.0502, -1589.9624, -1701.8499,
         -1593.9683, -1444.8374, -1611.8663,  -805.5060],
        [ -700.7136,  -464.3539,  -641.7415, -1060.1317, -1172.7645, -1177.4304,
         -1401.2239, -1522.5448, -1447.5962, -1237.1392, -1115.1014, -1070.5334,
         -1180.1849, -1044.5400, -1183.6963,  -200.6184],
        [  -83.6455,   102.2141,   -19.6103,  -283.8561,  -198.8747,  -416.6885,
          -634.5435,  -810.5859,  -810.6105,  -606.5812,  -451.9031,  -350.8431,
          -437.3825,  -397.6679,  -713.0145,   349.5848],
        [  297.0688,   445.8916,   448.8998,   258.5482,   470.4557,   241.0672,
           -26.1982,  -147.4547,  -223.3916,   -60.8628,    11.8025,   128.0485,
            65.1938,   -37.6083,  -255.6852,   881.5087],
        [  922.6302,   947.9895,  1055.6765,   741.2384,   905.8611,   840.5479,
           569.8871,   341.7343,   449.0399,   524.5929,   464.1322,   448.0332,
           387.7919,   389.2984,   330.6702,  1419.4426],
        [ 1161.5664,  1096.8472,  1245.9292,  1004.6204,  1104.8557,  1283.3562,
          1237.3064,   962.3929,  1085.8572,  1126.3998,  1144.0764,  1089.8727,
           975.3225,   800.5052,   586.3286,  1838.6541],
        [ 1241.7111,  1110.6556,  1419.1875,  1323.0239,  1517.2883,  1686.8519,
          1606.9088,  1485.8997,  1541.4124,  1486.3549,  1582.9135,  1505.3186,
          1408.5471,  1224.8185,   734.0156,  2253.2681],
        [ 1486.9766,  1553.5034,  1745.6846,  1613.9714,  1865.8323,  2047.4592,
          1937.6643,  1926.2771,  1749.3666,  1902.1637,  1919.7390,  1584.1737,
          1438.0402,  1428.5769,  1046.3279,  2601.1956],
        [ 1825.0857,  1832.1001,  2049.3276,  1971.1007,  2219.8643,  2067.6050,
          2160.6292,  2122.9685,  1944.1604,  2089.2332,  1983.1030,  1490.0809,
          1242.2705,  1239.7441,  1048.1289,  2670.6533],
        [ 1899.2703,  1565.7024,  1901.0439,  1725.0089,  1924.0869,  1994.6362,
          1909.9673,  1960.4952,  1880.1340,  1965.1921,  2016.4482,  1491.4646,
          1084.8428,   985.0170,   651.1775,  2424.1616],
        [ 1685.4812,  1239.3652,  1452.6493,  1299.3604,  1381.7665,  1499.6045,
          1527.5077,  1633.1028,  1625.7913,  1652.4648,  1484.6130,  1114.1678,
           746.8271,   595.6072,   315.3344,  1939.3280],
        [ 1199.5562,   781.2133,   997.4069,   789.6849,   906.0925,  1063.9807,
          1141.3723,  1272.5934,  1275.2764,  1179.7751,   946.1163,   720.2423,
           375.5370,    68.2636,  -380.3354,  1365.4148],
        [  430.9988,   113.1496,   337.6744,   216.1447,   384.6217,   536.2785,
           825.8735,   877.1475,   690.5493,   612.0423,   274.3482,   -38.9668,
          -374.5398,  -545.5101,  -973.0604,   629.9648],
        [ -267.6308,  -494.3438,  -382.9619,  -601.7649,  -499.2878,  -132.4496,
            67.2670,  -106.8083,  -202.5843,  -423.2368,  -590.3674,  -921.5200,
         -1169.6582, -1194.0850, -1483.5205,  -156.2258],
        [ -804.6486,  -946.4237,  -935.1526, -1174.9425, -1003.8143,  -748.1273,
          -617.3235,  -606.1292,  -739.8413,  -938.9896, -1135.6229, -1284.8882,
         -1437.9747, -1495.4340, -1730.4724,  -493.8803],
        [-2278.3381, -2183.7659, -2495.2344, -2928.8225, -2924.2510, -2650.7239,
         -2488.4219, -2501.1753, -2584.8147, -2771.7991, -2783.4043, -2819.4565,
         -2898.0220, -3011.2261, -3156.9663, -1947.2341]], device='cuda:0')
LAYER_NUM:  0
FINAL_SUM:  [11, 43, 67, 26, 42, 58, 84, 10, 55, 46]
acts len:  3
acts keys:  ['conv0', 'conv1', 'conv2']
acts:  {'conv0': [11, 43, 67, 26, 42, 58, 84, 10, 55, 46, 91, 74, 75, 28, 87, 5, 37, 4, 92, 77, 15], 'conv1': [78, 204, 61, 300, 77, 260, 92, 359, 32, 151, 210, 63, 349, 243, 332, 49, 116, 112, 53, 330, 19], 'conv2': [268, 1458, 350, 205, 1113, 660, 1284, 1490, 1005, 1383, 1323, 689, 1030, 1359, 537, 75, 61, 557, 964, 301, 924]}
final_sum len:  96
delta_weights INFO: 
NUM OF TRACKED COV LAYERS:  1
NUM OF TRACKED WEIGHTS CHANGES PER LAYER:  20
avg_deltas INFO:  <class 'dict'>
avg_deltas keys:  ['blocks.0.layer.weight', 'blocks.1.layer.weight', 'blocks.2.layer.weight']
avg_deltas size:  3
num of averages for 0 layer:  torch.Size([96])
################################################
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.40e-01	time: 00:00:35	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:9.157e-03/SW:5.694e-01/MR:4.523e+00/SR:1.975e+00/MeD:1.390e+00/MaD:8.122e+00/MW:0.576/MAW:0.424
|       0 |       1 |       2 |       3 |        4 |          5 |      6 |       7 |       8 |       9 |        10 |         11 |      12 |      13 |      14 |      15 |      16 |     17 |      18 |      19 |      20 |      21 |      22 |      23 |      24 |      25 |      26 |     27 |         28 |      29 |
|---------+---------+---------+---------+----------+------------+--------+---------+---------+---------+-----------+------------+---------+---------+---------+---------+---------+--------+---------+---------+---------+---------+---------+---------+---------+---------+---------+--------+------------+---------|
|   0.113 |   0.141 |   0.129 |   0.164 |   0.0242 |   0.000308 |   0.15 |   0.156 |   0.153 |   0.207 |   0.00201 |   0.000308 |   0.142 |   0.123 |   0.125 |   0.163 |   0.132 |   0.18 |   0.155 |   0.172 |   0.168 |   0.161 |   0.164 |   0.153 |   0.174 |   0.164 |   0.179 |   0.21 |   0.000496 |   0.118 |
|   3     |   4.12  |   3.6   |   5.18  |   1.09   |   1        |   4.53 |   4.8   |   4.66  |   7.66  |   1       |   1        |   4.16  |   3.37  |   3.43  |   5.17  |   3.74  |   6.06 |   4.75  |   5.6   |   5.39  |   5.06  |   5.21  |   4.64  |   5.71  |   5.19  |   6     |   7.91 |   1        |   3.19  |
|   0.49  |   0.46  |   0.54  |   0.52  |   1.27   |  20.67     |   0.36 |   0.46  |   0.48  |   0.5   |   3.58    |   2.37     |   0.5   |   0.42  |   0.42  |   0.39  |   0.46  |   0.48 |   0.49  |   0.48  |   0.45  |   0.49  |   0.51  |   0.52  |   0.49  |   0.37  |   0.42  |   0.52 |   1.17     |   0.61  |
| nan     | nan     | nan     | nan     | nan      | nan        | nan    | nan     | nan     | nan     | nan       | nan        | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan        | nan     |
| nan     | nan     | nan     | nan     | nan      | nan        | nan    | nan     | nan     | nan     | nan       | nan        | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan        | nan     |
| nan     | nan     | nan     | nan     | nan      | nan        | nan    | nan     | nan     | nan     | nan       | nan        | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan        | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([8, 8, 7, 8, 7, 8, 7, 4, 2, 4, 4, 2, 4, 4, 7, 8, 8, 8, 7, 7])
[2, 4, 7, 8]
TARGETS AFTER CLEANER:  tensor([3, 3, 2, 3, 2, 3, 2, 1, 0, 1, 1, 0, 1, 1, 2, 3, 3, 3, 2, 2])
4000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 4000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([4, 2, 7, 8, 4, 7, 7, 2, 2, 4, 2, 4, 4, 7, 2, 2, 7, 2, 2, 7])
[2, 4, 7, 8]
TARGETS AFTER CLEANER:  tensor([1, 0, 2, 3, 1, 2, 2, 0, 0, 1, 0, 1, 1, 2, 0, 0, 2, 0, 0, 2])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([4, 2, 7, 8, 4, 7, 7, 2, 2, 4, 2, 4, 4, 7, 2, 2, 7, 2, 2, 7])
[2, 4, 7, 8]
TARGETS AFTER CLEANER:  tensor([1, 0, 2, 3, 1, 2, 2, 0, 0, 1, 0, 1, 1, 2, 0, 0, 2, 0, 0, 2])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  20000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_4C_CL
DEPTH:  3
ACTIVATIONS SHAPE:  tensor([[ -3.8787, -10.6636,   2.5874,  10.5185,  -3.9050, -18.7102, -29.1963,
         -17.9314, -12.8406,  -8.6729, -11.3178, -27.9819, -24.4532,  -6.1952,
          -1.9288,   4.7156],
        [-10.3326, -17.6567,  -1.4745,  14.5679,  -0.3989, -18.6683, -29.4075,
         -18.0448, -10.3938, -15.7281, -24.6553, -31.2603, -14.4815,  -4.6863,
          -7.5281,   8.5905],
        [ -8.1933, -22.2677,   2.5979,   4.9943,   6.8161,   3.7439,   3.9617,
          -5.7337, -21.3461, -23.4900, -33.8762, -33.5002, -23.3547,  -8.0400,
          -2.7137,  12.6869],
        [  7.6559, -11.6041,  -7.3241, -17.2044,  -1.8511,  21.6772,  22.7355,
          17.4371, -21.2125, -28.6655, -32.2709, -22.0486, -11.6534, -10.7781,
         -23.7726,  12.2658],
        [  3.9302, -13.3081,   5.6890,   5.7519,  15.6844,  29.6435,   6.7492,
          -1.6206, -16.6527,  -7.8484,  -9.5090,  -5.4803, -10.2754, -17.5800,
         -19.7962,   4.5524],
        [ -4.6586, -10.0114,   3.0840,  15.0618,  32.0320,  43.5998,  21.5964,
          13.1472,   2.2887,   6.0461,  12.5043,  17.9508,   1.6877, -10.2156,
         -13.2466,  13.9926],
        [ -2.7404,  -3.8712,  -1.2670,   5.3303,  19.9770,  33.7556,   4.5730,
          16.5990,  22.2414,  17.7672,  22.1036,  15.7894,  19.0288,  12.5039,
          11.4682,  25.3757],
        [  4.2584, -10.9071,  -7.9068,   4.6450,  -0.8733,  13.3755,  14.8166,
          22.5254,  23.5662,  19.1241,   4.1592,   4.3582,  18.6648,  22.1289,
           6.4091,  41.4800],
        [ 12.3833,  -3.4105,   5.4205,   8.6800,   1.8109,   5.6912,  -1.4870,
          13.5049,  34.1631,  10.0276, -12.1248,   1.7554,  28.1030,  20.3164,
          10.5773,  51.8410],
        [ 18.4444,  -0.4750,  17.4151,   5.7748,   6.9361, -10.5492,  -7.4914,
          23.2077,  43.9839,  -8.0664, -30.1533,  -4.8214,  37.7464,  33.9372,
          31.4005,  60.3160],
        [ 10.3442,   0.2016,  21.1304,  20.9178,  32.5223,  23.1959,  26.0795,
          38.3705,  32.7010,  -6.9248, -12.0553,  23.1545,  38.2806,  40.6087,
          44.3433,  76.8211],
        [  2.9265,  -8.2999,  10.5204,  18.0977,  37.1481,  22.8833,  30.6856,
          35.6379,  31.6691,  10.4016,   1.7029,  15.5633,   9.2205,  24.2997,
          36.1381,  58.0949],
        [ -4.1180,  -5.3240,   6.2059,   4.1109,  20.8905,  29.4200,  22.2082,
          22.5992,   6.3303, -11.6024,   0.7742,  13.8043,   8.4050,  29.3827,
          34.7441,  71.4634],
        [-10.1516, -12.8489,  -1.3250,  -0.4956,  17.6341,  18.5889,  12.5930,
          -2.6850,  -0.6012, -18.9815, -17.3755,  -9.9075,  -8.8462,  19.3581,
          24.4888,  55.3968],
        [ -1.3061,  -9.6058,  -4.4841,  -3.8424,  -6.7314,  -1.2937,  -4.8932,
          -4.2905,   5.3869, -13.9604, -10.7941, -11.0193, -11.3179,  16.2263,
          18.6288,  56.6469],
        [-19.8203, -24.8342, -21.1542, -23.9087, -22.8807, -14.5310, -24.4266,
         -13.1369,  -4.7779, -20.0159, -25.0175, -28.0338, -23.1604,   3.3743,
           6.5757,  45.6895]], device='cuda:0')
LAYER_NUM:  1
FINAL_SUM:  [349, 63, 61, 78, 300, 77, 330, 19, 53, 158]
acts len:  3
acts keys:  ['conv0', 'conv1', 'conv2']
acts:  {'conv0': [11, 43, 67, 26, 42, 58, 84, 10, 55, 46, 91, 74, 75, 28, 87, 5, 37, 4, 92, 77, 15], 'conv1': [349, 63, 61, 78, 300, 77, 330, 19, 53, 158, 49, 191, 204, 92, 324, 247, 67, 116, 243, 294, 10], 'conv2': [268, 1458, 350, 205, 1113, 660, 1284, 1490, 1005, 1383, 1323, 689, 1030, 1359, 537, 75, 61, 557, 964, 301, 924]}
final_sum len:  384
delta_weights INFO: 
NUM OF TRACKED COV LAYERS:  1
NUM OF TRACKED WEIGHTS CHANGES PER LAYER:  20
avg_deltas INFO:  <class 'dict'>
avg_deltas keys:  ['blocks.0.layer.weight', 'blocks.1.layer.weight', 'blocks.2.layer.weight']
avg_deltas size:  3
num of averages for 1 layer:  torch.Size([96])
################################################
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.40e-01	time: 00:01:19	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:5.697e-03/SW:1.646e-01/MR:4.565e+00/SR:1.616e+00/MeD:1.305e+00/MaD:3.565e+00/MW:0.577/MAW:0.423
|        0 |         1 |         2 |         3 |         4 |         5 |         6 |         7 |         8 |         9 |       10 |        11 |        12 |        13 |        14 |        15 |        16 |        17 |        18 |       19 |       20 |       21 |      22 |       23 |        24 |       25 |       26 |       27 |       28 |        29 |
|----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+----------+----------+----------+---------+----------+-----------+----------+----------+----------+----------+-----------|
|   0.0101 |   0.00771 |   0.00776 |   0.00672 |   0.00539 |   0.00897 |   0.00612 |   0.00314 |   0.00776 |   0.00648 |   0.0116 |   0.00874 |   0.00923 |   0.00746 |   0.00752 |   0.00843 |   0.00929 |   0.00958 |   0.00171 |   0.0117 |   0.0133 |   0.0122 |   0.012 |   0.0104 |   0.00688 |   0.0123 |   0.0126 |   0.0105 |   0.0101 |   0.00756 |
|   5.04   |   3.38    |   3.41    |   2.81    |   2.16    |   4.22    |   2.5     |   1.4     |   3.41    |   2.68    |   6.41   |   4.06    |   4.41    |   3.23    |   3.26    |   3.85    |   4.45    |   4.67    |   1.12    |   6.43   |   8.13   |   6.99   |   6.76  |   5.31   |   2.89    |   7.07   |   7.37   |   5.44   |   5.1    |   3.28    |
|   0.16   |   0.12    |   0.14    |   0.11    |   0.19    |   0.09    |   0.12    |   0.09    |   0.2     |   0.16    |   0.18   |   0.18    |   0.19    |   0.08    |   0.14    |   0.14    |   0.12    |   0.18    |   0.12    |   0.29   |   0.18   |   0.16   |   0.22  |   0.23   |   0.13    |   0.26   |   0.13   |   0.12   |   0.17   |   0.09    |
| nan      | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan      | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan      | nan      | nan      | nan     | nan      | nan       | nan      | nan      | nan      | nan      | nan       |
| nan      | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan      | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan      | nan      | nan      | nan     | nan      | nan       | nan      | nan      | nan      | nan      | nan       |
| nan      | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan      | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan      | nan      | nan      | nan     | nan      | nan       | nan      | nan      | nan      | nan      | nan       |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([8, 8, 7, 8, 7, 8, 7, 4, 2, 4, 4, 2, 4, 4, 7, 8, 8, 8, 7, 7])
[2, 4, 7, 8]
TARGETS AFTER CLEANER:  tensor([3, 3, 2, 3, 2, 3, 2, 1, 0, 1, 1, 0, 1, 1, 2, 3, 3, 3, 2, 2])
4000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 4000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([4, 2, 7, 8, 4, 7, 7, 2, 2, 4, 2, 4, 4, 7, 2, 2, 7, 2, 2, 7])
[2, 4, 7, 8]
TARGETS AFTER CLEANER:  tensor([1, 0, 2, 3, 1, 2, 2, 0, 0, 1, 0, 1, 1, 2, 0, 0, 2, 0, 0, 2])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([4, 2, 7, 8, 4, 7, 7, 2, 2, 4, 2, 4, 4, 7, 2, 2, 7, 2, 2, 7])
[2, 4, 7, 8]
TARGETS AFTER CLEANER:  tensor([1, 0, 2, 3, 1, 2, 2, 0, 0, 1, 0, 1, 1, 2, 0, 0, 2, 0, 0, 2])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  20000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_4C_CL
DEPTH:  3
ACTIVATIONS SHAPE:  tensor([[ 1.1840e+00, -5.4988e+00,  4.5153e+00,  1.2130e+01,  6.3099e-01,
         -1.4415e+01, -2.3270e+01, -1.5836e+01, -1.1093e+01, -3.1710e+00,
         -3.3798e+00, -1.8083e+01, -1.6111e+01, -3.3973e+00, -2.4505e+00,
          5.4259e+00],
        [-1.8068e+00, -9.5663e+00,  2.2796e+00,  1.5863e+01,  3.6521e+00,
         -1.3053e+01, -2.0741e+01, -1.5555e+01, -7.8056e+00, -6.3379e+00,
         -1.6628e+01, -2.1929e+01, -6.9392e+00, -3.7997e-02, -7.2749e+00,
          7.9095e+00],
        [-8.1228e-01, -1.5060e+01,  4.5228e+00,  3.6930e+00,  2.9385e+00,
         -2.3911e+00,  4.3772e+00, -5.8747e+00, -1.7750e+01, -1.5106e+01,
         -2.5897e+01, -2.5727e+01, -1.7503e+01, -7.9568e+00, -8.5251e+00,
          7.7779e+00],
        [ 1.1330e+01, -4.9792e+00, -3.2322e+00, -1.6740e+01, -7.0805e+00,
          1.1163e+01,  1.5710e+01,  9.5270e+00, -2.1296e+01, -1.9956e+01,
         -2.8083e+01, -2.2767e+01, -1.1567e+01, -1.6674e+01, -2.9340e+01,
          4.5708e+00],
        [ 7.3888e+00, -3.9203e+00,  6.8670e+00, -1.1094e+00,  1.8594e+00,
          1.2947e+01, -4.5390e+00, -1.0239e+01, -2.0752e+01, -8.0118e+00,
         -1.0548e+01, -9.2685e+00, -1.2493e+01, -2.0587e+01, -2.4151e+01,
          1.4556e+00],
        [-5.4849e-01, -2.8558e+00,  3.9269e+00,  4.4519e+00,  1.4807e+01,
          2.2373e+01,  2.0680e+00, -5.3957e+00, -9.0067e+00, -7.6637e-01,
          4.3219e+00,  8.3952e+00, -2.7059e+00, -1.7095e+01, -1.9416e+01,
          6.6857e+00],
        [ 1.8872e-01,  1.2371e+00, -2.4193e+00, -5.6039e-01,  8.0477e+00,
          1.8608e+01, -1.1370e+01, -6.1970e+00,  4.3099e+00,  7.4856e+00,
          1.0422e+01,  5.8814e+00,  8.6656e+00, -8.4145e-02,  1.0194e+00,
          1.4460e+01],
        [ 4.1350e+00, -5.4882e+00, -6.7828e+00,  2.2241e+00, -4.1808e+00,
          7.1432e+00,  2.3924e+00,  4.9802e+00,  9.6552e+00,  1.0058e+01,
         -1.5687e+00, -1.4122e+00,  8.8583e+00,  7.2804e+00, -4.3613e+00,
          2.6324e+01],
        [ 5.9199e+00, -4.6645e+00,  2.9468e+00,  6.4166e+00,  2.3100e+00,
          4.8592e+00, -8.3164e+00,  8.6020e-01,  2.0020e+01,  1.2922e+00,
         -1.4318e+01, -8.7263e-01,  1.8819e+01,  5.0823e+00, -1.4932e+00,
          3.4709e+01],
        [ 6.7053e+00, -6.9839e+00,  6.5881e+00, -3.2337e+00,  1.2775e+00,
         -1.1747e+01, -1.6597e+01,  8.7157e+00,  2.4756e+01, -1.4992e+01,
         -2.8680e+01, -9.0339e+00,  2.5482e+01,  1.3235e+01,  9.5279e+00,
          3.7966e+01],
        [-9.2030e-01, -3.0824e+00,  5.8423e+00, -2.3823e+00,  1.4389e+01,
          5.1795e+00,  6.1008e+00,  1.9198e+01,  1.5349e+01, -1.5043e+01,
         -1.4817e+01,  1.4569e+01,  1.9651e+01,  1.3343e+01,  1.3629e+01,
          4.5500e+01],
        [-3.2417e+00, -6.2488e+00, -4.0629e+00, -8.6325e+00,  1.2637e+01,
          3.9470e+00,  7.7751e+00,  1.4857e+01,  1.0917e+01, -6.3961e-01,
         -5.4206e+00,  6.3235e+00, -5.5695e+00, -8.6953e-01,  3.8594e+00,
          2.5302e+01],
        [-8.5484e+00,  1.2772e+00, -6.0104e+00, -2.1003e+01, -2.6627e+00,
          1.0609e+01,  6.0062e+00,  8.9038e+00, -4.4163e+00, -1.8415e+01,
         -4.1904e+00,  5.0357e+00, -7.2562e+00,  4.4584e+00,  5.0090e+00,
          3.8833e+01],
        [-1.2372e+01, -5.1836e+00, -5.5982e+00, -1.8450e+01, -2.0880e+00,
          5.8423e+00,  6.1875e+00, -2.4583e+00, -1.6827e+00, -1.8799e+01,
         -1.5038e+01, -1.2679e+01, -2.1295e+01, -1.8598e+00, -9.5930e-01,
          2.7969e+01],
        [-1.7710e+00, -9.5533e-01, -1.6811e+00, -1.0135e+01, -1.3294e+01,
         -5.5719e+00, -5.6811e+00, -1.7387e+00,  5.0081e+00, -1.0755e+01,
         -6.5221e+00, -1.0522e+01, -2.2163e+01, -2.2858e+00, -1.9675e-01,
          3.4356e+01],
        [-1.6117e+01, -1.4470e+01, -1.5393e+01, -2.3974e+01, -2.3544e+01,
         -1.2969e+01, -1.7887e+01, -6.3610e+00, -7.2066e-01, -1.5276e+01,
         -1.7048e+01, -2.4549e+01, -2.6307e+01, -8.7676e+00, -5.1018e+00,
          2.9316e+01]], device='cuda:0')
LAYER_NUM:  2
FINAL_SUM:  [315, 866, 924, 61, 1359, 1483, 168, 1284, 525, 660]
acts len:  3
acts keys:  ['conv0', 'conv1', 'conv2']
acts:  {'conv0': [11, 43, 67, 26, 42, 58, 84, 10, 55, 46, 91, 74, 75, 28, 87, 5, 37, 4, 92, 77, 15], 'conv1': [349, 63, 61, 78, 300, 77, 330, 19, 53, 158, 49, 191, 204, 92, 324, 247, 67, 116, 243, 294, 10], 'conv2': [315, 866, 924, 61, 1359, 1483, 168, 1284, 525, 660, 1065, 914, 1312, 1015, 540, 985, 1141, 618, 205, 1195, 1156]}
final_sum len:  1536
delta_weights INFO: 
NUM OF TRACKED COV LAYERS:  1
NUM OF TRACKED WEIGHTS CHANGES PER LAYER:  20
avg_deltas INFO:  <class 'dict'>
avg_deltas keys:  ['blocks.0.layer.weight', 'blocks.1.layer.weight', 'blocks.2.layer.weight']
avg_deltas size:  3
num of averages for 2 layer:  torch.Size([96])
################################################
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 3.97e-02	time: 00:02:45	Acc_train 0.00	Acc_test 0.00	convergence: 1.59e+01	R1: 2	Info MB:0.000e+00/SB:0.000e+00/MW:1.069e-02/SW:2.891e-01/MR:1.688e+01/SR:2.099e+00/MeD:1.613e+00/MaD:1.588e+01/MW:0.440/MAW:0.560
|       0 |       1 |        2 |        3 |        4 |        5 |        6 |        7 |        8 |        9 |       10 |       11 |       12 |       13 |       14 |       15 |       16 |       17 |       18 |       19 |       20 |       21 |       22 |       23 |       24 |       25 |       26 |       27 |       28 |       29 |
|---------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------|
|   0.044 |   0.043 |   0.0375 |   0.0342 |   0.0369 |   0.0411 |   0.0387 |   0.0394 |   0.0356 |   0.0423 |   0.0418 |   0.0365 |   0.0405 |   0.0398 |   0.0405 |   0.0405 |   0.0453 |   0.0413 |   0.0417 |   0.0428 |   0.0382 |   0.0379 |   0.0376 |   0.0404 |   0.0377 |   0.0409 |   0.0408 |   0.0386 |   0.0401 |   0.0454 |
|  20.35  |  19.49  |  15.09   |  12.68   |  14.62   |  17.9    |  15.98   |  16.51   |  13.68   |  18.86   |  18.47   |  14.32   |  17.37   |  16.82   |  17.42   |  17.42   |  21.53   |  18.03   |  18.37   |  19.28   |  15.6    |  15.4    |  15.14   |  17.32   |  15.18   |  17.72   |  17.62   |  15.91   |  17.05   |  21.58   |
|   0.05  |   0.06  |   0.07   |   0.06   |   0.04   |   0.05   |   0.06   |   0.02   |   0.04   |   0.06   |   0.08   |   0.03   |   0.07   |   0.04   |   0.05   |   0.05   |   0.05   |   0.07   |   0.05   |   0.04   |   0.05   |   0.07   |   0.05   |   0.07   |   0.06   |   0.05   |   0.07   |   0.06   |   0.07   |   0.05   |
| nan     | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan     | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan     | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models

 ********** Supervised learning of blocks [3] **********
SAVING FOLDER FOR SUP:  C10_4C_CL
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([8, 8, 7, 8, 7, 8, 7, 4, 2, 4, 4, 2, 4, 4, 7, 8, 8, 8, 7, 7])
[2, 4, 7, 8]
TARGETS AFTER CLEANER:  tensor([3, 3, 2, 3, 2, 3, 2, 1, 0, 1, 1, 0, 1, 1, 2, 3, 3, 3, 2, 2])
4000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 4000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([4, 2, 7, 8, 4, 7, 7, 2, 2, 4, 2, 4, 4, 7, 2, 2, 7, 2, 2, 7])
[2, 4, 7, 8]
TARGETS AFTER CLEANER:  tensor([1, 0, 2, 3, 1, 2, 2, 0, 0, 1, 0, 1, 1, 2, 0, 0, 2, 0, 0, 2])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([4, 2, 7, 8, 4, 7, 7, 2, 2, 4, 2, 4, 4, 7, 2, 2, 7, 2, 2, 7])
[2, 4, 7, 8]
TARGETS AFTER CLEANER:  tensor([1, 0, 2, 3, 1, 2, 2, 0, 0, 1, 0, 1, 1, 2, 0, 0, 2, 0, 0, 2])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  20000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Epoch: [1/50]	lr: 1.00e-03	time: 00:03:12	Loss_train 0.50414	Acc_train 69.27	/	Loss_test 0.01284	Acc_test 81.97
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
Epoch: [10/50]	lr: 1.00e-03	time: 00:03:21	Loss_train 0.19636	Acc_train 84.48	/	Loss_test 0.01097	Acc_test 88.07
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
Epoch: [20/50]	lr: 2.50e-04	time: 00:03:30	Loss_train 0.10387	Acc_train 90.10	/	Loss_test 0.00943	Acc_test 88.65
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
Epoch: [30/50]	lr: 1.25e-04	time: 00:03:39	Loss_train 0.07629	Acc_train 91.58	/	Loss_test 0.00845	Acc_test 89.25
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
Epoch: [40/50]	lr: 3.13e-05	time: 00:03:49	Loss_train 0.06308	Acc_train 92.42	/	Loss_test 0.00806	Acc_test 89.50
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
Epoch: [50/50]	lr: 7.81e-06	time: 00:03:58	Loss_train 0.05986	Acc_train 92.55	/	Loss_test 0.00795	Acc_test 89.62
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
RESULT:  {'train_loss': 0.05986209958791733, 'train_acc': 92.55099892616272, 'test_loss': 0.007949482649564743, 'test_acc': 89.625, 'convergence': 15.878185272216797, 'R1': 2, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [2, 4, 7, 8]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [2, 4, 7, 8]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}
IN R2:  {'R1': {'train_loss': 0.0710216760635376, 'train_acc': 89.54049944877625, 'test_loss': 0.00850343331694603, 'test_acc': 85.5250015258789, 'convergence': 17.365699768066406, 'R1': 2, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [0, 1, 3, 5]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [0, 1, 3, 5]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}, 'R2': {'train_loss': 0.05986209958791733, 'train_acc': 92.55099892616272, 'test_loss': 0.007949482649564743, 'test_acc': 89.625, 'convergence': 15.878185272216797, 'R1': 2, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [2, 4, 7, 8]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [2, 4, 7, 8]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}

 Model C10_4C_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=4, bias=True)
[Sequential(
  (0): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=0.7)
  )
  (1): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=1.4)
  )
  (2): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (activation): Triangle(power=1.0)
  )
  (3): BasicBlock(
    (operations): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
    )
    (layer): Linear(in_features=24576, out_features=4, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
)]
LAYER NAME:  Sequential(
  (0): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=0.7)
  )
  (1): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=1.4)
  )
  (2): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (activation): Triangle(power=1.0)
  )
  (3): BasicBlock(
    (operations): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
    )
    (layer): Linear(in_features=24576, out_features=4, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
)
LAYER CHILDREN:  [BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
  (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
  (activation): Triangle(power=0.7)
), BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
  (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
  (activation): Triangle(power=1.4)
), BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (activation): Triangle(power=1.0)
), BasicBlock(
  (operations): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
  )
  (layer): Linear(in_features=24576, out_features=4, bias=True)
  (dropout): Dropout(p=0.5, inplace=False)
)]
subsubl NAME:  Sequential(
  (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
subsubl NAME:  Triangle(power=0.7)
subsubl NAME:  Sequential(
  (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
subsubl NAME:  Triangle(power=1.4)
subsubl NAME:  Sequential(
  (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  AvgPool2d(kernel_size=2, stride=2, padding=0)
subsubl NAME:  Triangle(power=1.0)
subsubl NAME:  Sequential(
  (0): Flatten(start_dim=1, end_dim=-1)
)
subsubl NAME:  Linear(in_features=24576, out_features=4, bias=True)
subsubl NAME:  Dropout(p=0.5, inplace=False)
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([3, 0, 1, 3, 1, 0, 5, 5, 0, 5, 0, 5, 5, 1, 5, 5, 0, 3, 0, 3])
[0, 1, 3, 5]
TARGETS AFTER CLEANER:  tensor([2, 0, 1, 2, 1, 0, 3, 3, 0, 3, 0, 3, 3, 1, 3, 3, 0, 2, 0, 2])
4000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 4000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([1, 1, 3, 3, 3, 3, 5, 0, 0, 1, 3, 0, 3, 3, 3, 5, 1, 1, 1, 0])
[0, 1, 3, 5]
TARGETS AFTER CLEANER:  tensor([1, 1, 2, 2, 2, 2, 3, 0, 0, 1, 2, 0, 2, 2, 2, 3, 1, 1, 1, 0])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([1, 1, 3, 3, 3, 3, 5, 0, 0, 1, 3, 0, 3, 3, 3, 5, 1, 1, 1, 0])
[0, 1, 3, 5]
TARGETS AFTER CLEANER:  tensor([1, 1, 2, 2, 2, 2, 3, 0, 0, 1, 2, 0, 2, 2, 2, 3, 1, 1, 1, 0])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  20000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Accuracy of the network on the 1st dataset: 16.350 %
Test loss on the 1st dataset: 0.224

The device used will be: 
True
cuda:0
BLOCKS:  {'b0': {'arch': 'CNN', 'preset': 'softkrotov-c96-k5-p2-s1-d1-b0-t1-lr0.08-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 0, 'batch_norm': False, 'pool': {'type': 'max', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 0.7}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5}}, 'b1': {'arch': 'CNN', 'preset': 'softkrotov-c384-k3-p1-s1-d1-b0-t0.65-lr0.005-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 1, 'batch_norm': False, 'pool': {'type': 'max', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 1.4}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3}}, 'b2': {'arch': 'CNN', 'preset': 'softkrotov-c1536-k3-p1-s1-d1-b0-t0.25-lr0.01-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 2, 'batch_norm': False, 'pool': {'type': 'avg', 'kernel_size': 2, 'stride': 2, 'padding': 0}, 'activation': {'function': 'triangle', 'param': 1.0}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3}}, 'b3': {'arch': 'MLP', 'preset': 'BP-c10', 'operation': 'flatten', 'num': 3, 'att_dropout': None, 'dropout': 0.5, 'layer': {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.25, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10}, 'pool': None, 'activation': None}}
CL:  True
{'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True}
CL:  True
{'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}

 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=4, bias=True)
[Sequential(
  (0): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=0.7)
  )
  (1): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=1.4)
  )
  (2): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (activation): Triangle(power=1.0)
  )
  (3): BasicBlock(
    (operations): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
    )
    (layer): Linear(in_features=24576, out_features=4, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
)]
LAYER NAME:  Sequential(
  (0): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=0.7)
  )
  (1): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=1.4)
  )
  (2): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (activation): Triangle(power=1.0)
  )
  (3): BasicBlock(
    (operations): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
    )
    (layer): Linear(in_features=24576, out_features=4, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
)
LAYER CHILDREN:  [BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
  (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
  (activation): Triangle(power=0.7)
), BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
  (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
  (activation): Triangle(power=1.4)
), BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (activation): Triangle(power=1.0)
), BasicBlock(
  (operations): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
  )
  (layer): Linear(in_features=24576, out_features=4, bias=True)
  (dropout): Dropout(p=0.5, inplace=False)
)]
subsubl NAME:  Sequential(
  (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
subsubl NAME:  Triangle(power=0.7)
subsubl NAME:  Sequential(
  (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
subsubl NAME:  Triangle(power=1.4)
subsubl NAME:  Sequential(
  (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  AvgPool2d(kernel_size=2, stride=2, padding=0)
subsubl NAME:  Triangle(power=1.0)
subsubl NAME:  Sequential(
  (0): Flatten(start_dim=1, end_dim=-1)
)
subsubl NAME:  Linear(in_features=24576, out_features=4, bias=True)
subsubl NAME:  Dropout(p=0.5, inplace=False)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([3, 3, 9, 5, 9, 5, 9, 5, 2, 9, 5, 5, 9, 2, 9, 5, 5, 9, 3, 9])
[2, 3, 5, 9]
TARGETS AFTER CLEANER:  tensor([1, 1, 3, 2, 3, 2, 3, 2, 0, 3, 2, 2, 3, 0, 3, 2, 2, 3, 1, 3])
4000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 4000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 2, 3, 2, 9, 9, 9, 3, 2, 3, 2, 3, 5, 9, 3, 3, 3, 3, 5])
[2, 3, 5, 9]
TARGETS AFTER CLEANER:  tensor([3, 3, 0, 1, 0, 3, 3, 3, 1, 0, 1, 0, 1, 2, 3, 1, 1, 1, 1, 2])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 2, 3, 2, 9, 9, 9, 3, 2, 3, 2, 3, 5, 9, 3, 3, 3, 3, 5])
[2, 3, 5, 9]
TARGETS AFTER CLEANER:  tensor([3, 3, 0, 1, 0, 3, 3, 3, 1, 0, 1, 0, 1, 2, 3, 1, 1, 1, 1, 2])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  20000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_4C_CL
DEPTH:  3
WTA IN delta_weight:  tensor([[[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -1.9480e-17,
          -4.3463e-17, -1.1564e-13],
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -2.5430e-14,
          -1.5013e-15, -4.5290e-14],
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -6.4478e-14,
          -7.5683e-16, -2.4900e-14],
         ...,
         [-2.2070e-30, -4.9994e-23, -1.8331e-17,  ..., -2.0651e-26,
          -1.1550e-30, -4.9091e-36],
         [-1.9317e-29, -2.5168e-29, -2.2607e-20,  ..., -2.1720e-26,
          -9.8973e-31, -2.2662e-38],
         [-1.4205e-28, -1.9332e-26, -1.5077e-20,  ..., -5.1846e-25,
          -1.4191e-30, -1.2184e-37]],

        [[-0.0000e+00, -0.0000e+00, -4.0638e-44,  ..., -9.0379e-14,
          -8.0809e-14, -1.1086e-10],
         [-0.0000e+00, -0.0000e+00, -1.3873e-43,  ..., -1.4133e-12,
          -1.9347e-13, -4.4250e-13],
         [-4.2039e-45, -2.3822e-44, -9.4924e-42,  ..., -1.8504e-12,
          -1.7147e-14, -1.9585e-14],
         ...,
         [-2.3582e-24, -1.4053e-19, -2.0903e-25,  ..., -9.9952e-27,
          -8.1833e-23, -5.2862e-27],
         [-6.3008e-21, -6.0084e-22, -1.0659e-22,  ..., -1.3918e-25,
          -1.0088e-21, -1.6136e-28],
         [-2.3513e-20, -3.2388e-20, -2.1016e-23,  ..., -2.5488e-25,
          -1.1249e-21, -2.5849e-29]],

        [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -1.8519e-13,
          -3.8937e-15, -8.2107e-13],
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -1.3531e-11,
          -1.4295e-14, -3.8245e-14],
         [-0.0000e+00, -0.0000e+00, -1.6816e-44,  ..., -8.0060e-09,
          -1.4594e-11, -4.0565e-13],
         ...,
         [-3.6033e-24, -7.3154e-21, -1.9495e-21,  ..., -4.9285e-25,
          -4.5365e-24, -9.4046e-26],
         [-3.7395e-22, -7.3229e-26, -4.8674e-25,  ..., -3.7685e-24,
          -3.7286e-23, -7.5093e-28],
         [-8.7235e-24, -1.1811e-23, -4.8302e-26,  ..., -6.0145e-28,
          -1.2164e-24, -5.1921e-29]],

        ...,

        [[-7.5978e-12, -8.5891e-13, -1.5428e-11,  ..., -9.2989e-07,
          -2.0057e-05, -8.8701e-02],
         [-5.8518e-14, -3.7817e-13, -6.3512e-12,  ..., -2.0973e-06,
          -9.8191e-06, -3.9435e-04],
         [-1.9651e-13, -7.8782e-12, -1.8618e-11,  ..., -2.7456e-05,
          -1.0583e-04, -1.0190e-03],
         ...,
         [-2.2482e-08, -4.8270e-07, -5.9671e-06,  ..., -4.9390e-05,
          -1.3114e-06, -4.6042e-15],
         [-2.7094e-07, -9.5118e-10, -5.8772e-08,  ..., -1.0420e-04,
          -2.7998e-06, -2.5227e-15],
         [-6.0984e-09, -1.7601e-06, -1.1965e-06,  ..., -1.1223e-04,
          -5.4583e-07, -1.6726e-14]],

        [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -2.8994e-16,
          -3.5634e-17, -4.7822e-16],
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -1.6138e-15,
          -7.3866e-17, -5.2484e-18],
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -9.8858e-16,
          -1.0844e-16, -1.8357e-17],
         ...,
         [-1.6701e-33, -2.9369e-31, -1.1261e-30,  ..., -3.3215e-34,
          -7.5138e-30, -1.8626e-30],
         [-7.0794e-33, -8.8025e-33, -6.2800e-31,  ..., -1.8981e-33,
          -2.1671e-28, -9.3097e-31],
         [-1.2220e-31, -1.8046e-30, -3.9530e-31,  ..., -6.0005e-33,
          -8.4929e-30, -5.2851e-31]],

        [[-1.6392e-37, -1.8572e-38, -7.2813e-38,  ..., -3.2974e-08,
          -1.0181e-09, -3.4081e-08],
         [-5.8016e-39, -9.4364e-39, -2.0365e-38,  ..., -4.3040e-10,
          -6.6663e-10, -6.0680e-10],
         [-1.8579e-38, -5.1144e-37, -3.2135e-38,  ..., -1.0047e-10,
          -1.9445e-12, -3.2608e-11],
         ...,
         [-3.0168e-20, -6.2511e-22, -8.8174e-15,  ..., -6.4281e-21,
          -5.9634e-22, -1.1610e-25],
         [-5.5343e-18, -1.8972e-23, -1.2235e-13,  ..., -1.3529e-20,
          -1.6956e-20, -1.2318e-25],
         [-2.7893e-17, -1.6842e-20, -7.4511e-13,  ..., -1.2856e-17,
          -2.6449e-20, -1.8944e-24]]], device='cuda:0')
LAYER_NUM:  0
FINAL_SUM:  [77, 11, 26, 43, 46, 34, 91, 87, 4, 53]
acts len:  3
acts keys:  ['conv0', 'conv1', 'conv2']
acts:  {'conv0': [77, 11, 26, 43, 46, 34, 91, 87, 4, 53, 84, 66, 55, 30, 35, 92, 42, 95, 15, 39, 40], 'conv1': [98, 19, 61, 330, 260, 300, 317, 324, 158, 204, 110, 63, 180, 59, 65, 254, 67, 49, 214, 225, 359], 'conv2': [660, 1065, 1132, 537, 1471, 1284, 1149, 1285, 1016, 870, 117, 1174, 605, 903, 832, 1113, 1222, 525, 557, 130, 1409]}
final_sum len:  96
delta_weights INFO: 
NUM OF TRACKED COV LAYERS:  1
NUM OF TRACKED WEIGHTS CHANGES PER LAYER:  20
avg_deltas INFO:  <class 'dict'>
avg_deltas keys:  ['blocks.0.layer.weight', 'blocks.1.layer.weight', 'blocks.2.layer.weight']
avg_deltas size:  3
num of averages for 0 layer:  torch.Size([96])
################################################
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.42e-01	time: 00:00:42	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.088e-02/SW:5.677e-01/MR:4.599e+00/SR:1.750e+00/MeD:1.309e+00/MaD:4.716e+00/MW:0.602/MAW:0.398
|        0 |       1 |       2 |       3 |       4 |          5 |       6 |       7 |       8 |       9 |       10 |       11 |      12 |      13 |      14 |      15 |      16 |      17 |      18 |     19 |      20 |      21 |      22 |      23 |      24 |      25 |      26 |      27 |      28 |      29 |
|----------+---------+---------+---------+---------+------------+---------+---------+---------+---------+----------+----------+---------+---------+---------+---------+---------+---------+---------+--------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------|
|   0.0968 |   0.124 |   0.141 |   0.157 |   0.118 |   0.000259 |   0.159 |   0.164 |   0.157 |   0.188 |   0.0021 |   0.0158 |   0.175 |   0.151 |   0.154 |   0.177 |   0.158 |   0.169 |   0.176 |   0.18 |   0.184 |   0.152 |   0.135 |   0.192 |   0.167 |   0.151 |   0.189 |   0.197 |   0.012 |   0.155 |
|   2.46   |   3.42  |   4.1   |   4.86  |   3.18  |   1        |   4.96  |   5.19  |   4.85  |   6.53  |   1      |   1.04   |   5.81  |   4.54  |   4.69  |   5.92  |   4.92  |   5.44  |   5.82  |   6.09 |   6.27  |   4.62  |   3.85  |   6.74  |   5.35  |   4.58  |   6.58  |   7.06  |   1.02  |   4.76  |
|   0.57   |   0.44  |   0.44  |   0.51  |   1.5   |  14.99     |   0.5   |   0.45  |   0.66  |   0.41  |   1.61   |   1.34   |   0.57  |   0.43  |   0.59  |   0.4   |   1.11  |   0.54  |   0.52  |   0.66 |   0.53  |   0.52  |   0.48  |   0.5   |   0.49  |   1     |   0.43  |   0.63  |   1.19  |   0.81  |
| nan      | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan      | nan      | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     |
| nan      | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan      | nan      | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     |
| nan      | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan      | nan      | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([3, 3, 9, 5, 9, 5, 9, 5, 2, 9, 5, 5, 9, 2, 9, 5, 5, 9, 3, 9])
[2, 3, 5, 9]
TARGETS AFTER CLEANER:  tensor([1, 1, 3, 2, 3, 2, 3, 2, 0, 3, 2, 2, 3, 0, 3, 2, 2, 3, 1, 3])
4000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 4000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 2, 3, 2, 9, 9, 9, 3, 2, 3, 2, 3, 5, 9, 3, 3, 3, 3, 5])
[2, 3, 5, 9]
TARGETS AFTER CLEANER:  tensor([3, 3, 0, 1, 0, 3, 3, 3, 1, 0, 1, 0, 1, 2, 3, 1, 1, 1, 1, 2])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 2, 3, 2, 9, 9, 9, 3, 2, 3, 2, 3, 5, 9, 3, 3, 3, 3, 5])
[2, 3, 5, 9]
TARGETS AFTER CLEANER:  tensor([3, 3, 0, 1, 0, 3, 3, 3, 1, 0, 1, 0, 1, 2, 3, 1, 1, 1, 1, 2])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  20000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_4C_CL
DEPTH:  3
ACTIVATIONS SHAPE:  tensor([[ -58.4200,  -33.0361,  -68.8344, -111.5682, -113.1252, -170.9623,
         -216.2747, -129.0733, -175.6693, -202.2807, -144.0569, -214.8741,
         -207.2437, -240.8690, -179.0584, -149.8362],
        [ -17.3544,  -47.1411,  -41.4560,  -52.2549,  -90.1140, -119.0853,
         -169.8992, -133.7091, -165.2836, -203.9386, -158.7175, -189.9853,
         -213.9556, -258.9799, -198.9796, -163.1075],
        [  23.0072,  -22.1864,  -27.9938,  -54.4494, -103.2637, -113.9550,
         -217.2252, -117.7361, -183.6213, -196.4677, -149.6042, -131.6701,
         -156.5706, -144.7557,  -99.5529, -116.1819],
        [   2.1866,  -28.1744,  -30.1996,  -74.3242, -115.2099,  -92.9928,
         -166.8375,  -76.2861, -170.1383, -179.5930,  -94.7482,  -54.6127,
          -78.2279,  -64.1254,  -25.3289,  -48.6943],
        [ -31.1163,  -31.0852,  -19.7356,  -48.2638, -101.3061,  -79.5190,
         -186.2484, -149.5440, -145.5619, -148.1380,  -92.2322,  -85.0956,
          -64.1253,  -56.8637,  -49.6225,  -17.0361],
        [ -82.1281,  -59.4566,  -53.1067,  -57.1572, -117.4792,  -73.6241,
         -190.9664, -214.3316, -186.3758, -197.0010, -197.1106, -146.5394,
          -58.9348,  -66.7547,  -68.9235,   -0.4051],
        [ -50.9286,  -30.5993,  -74.7767, -131.4659, -180.9001, -194.5480,
         -227.2495, -173.0562, -175.3857, -154.1954, -178.0813, -152.6295,
          -69.9473,  -51.2874,  -55.1202,  -21.0974],
        [  -1.8298,  -26.1305,  -30.8091, -154.4013, -275.6704, -229.5140,
         -181.5863, -168.0865, -131.7772, -204.5631, -229.2024, -178.1171,
          -74.7489,  -14.3216,  -39.3117,   -8.0443],
        [  -3.0634,  -27.1172,   -4.2182, -141.9149, -288.6544, -199.3445,
         -123.0627,  -98.5168,  -58.1381, -200.7950, -234.6330, -128.2224,
          -43.1864,  -76.1114, -141.0143,  -21.8110],
        [ -33.6697, -103.2345,  -34.7220, -128.0774, -175.1077,  -92.9203,
          -63.1837,  -73.7747,  -36.3501, -202.9185, -208.0804, -130.0663,
          -17.6067,  -76.5275, -208.7493,  -35.4588],
        [ -62.0759, -121.9292,  -38.9261, -145.4297, -168.3916, -100.6859,
         -115.5926, -126.2259, -105.0706, -188.1035, -162.4111, -158.0759,
         -116.3641, -107.2394, -186.2107,  -35.7835],
        [-124.6772, -194.0370,  -92.5227, -140.1217, -148.2946, -104.2830,
         -151.3096, -156.4975, -113.6785, -168.3299, -177.1789, -160.5911,
         -187.2260, -153.4626, -123.3828,   -8.1485],
        [-123.6626, -160.1856, -135.1755, -146.2782, -138.7932,  -98.2929,
         -153.9428, -140.2277,  -93.9409, -108.4632, -122.6971, -151.1594,
         -201.5368, -148.5946, -111.4399,   -8.4640],
        [-131.8439, -182.1240, -140.3718, -154.0998, -134.9017, -122.2631,
         -179.3545, -137.9259,  -79.8630, -119.8398, -125.0458, -115.3856,
         -162.5590, -140.4022, -122.8504,  -70.9470],
        [ -66.8273, -116.2989,  -84.7864, -108.7201, -140.8031,  -93.8942,
          -93.6826, -107.5204,  -42.3199,  -70.8487, -167.9884, -139.1535,
         -189.6827, -145.2468, -159.8361,  -94.7235],
        [ -93.4013, -165.4757, -125.6079, -119.2703, -121.9913, -140.8133,
         -181.5208, -124.7463, -106.7708, -102.3894, -220.3808, -186.6165,
         -229.4500, -210.2384, -216.6006, -163.8833]], device='cuda:0')
LAYER_NUM:  1
FINAL_SUM:  [61, 204, 78, 260, 359, 49, 63, 291, 19, 77]
acts len:  3
acts keys:  ['conv0', 'conv1', 'conv2']
acts:  {'conv0': [43, 77, 26, 11, 91, 46, 87, 34, 84, 35, 30, 55, 4, 15, 42, 67, 37, 66, 39, 92, 40], 'conv1': [61, 204, 78, 260, 359, 49, 63, 291, 19, 77, 300, 174, 324, 180, 151, 8, 349, 112, 210, 157, 53], 'conv2': [660, 1065, 1132, 537, 1471, 1284, 1149, 1285, 1016, 870, 117, 1174, 605, 903, 832, 1113, 1222, 525, 557, 130, 1409]}
final_sum len:  384
delta_weights INFO: 
NUM OF TRACKED COV LAYERS:  1
NUM OF TRACKED WEIGHTS CHANGES PER LAYER:  20
avg_deltas INFO:  <class 'dict'>
avg_deltas keys:  ['blocks.0.layer.weight', 'blocks.1.layer.weight', 'blocks.2.layer.weight']
avg_deltas size:  3
num of averages for 1 layer:  torch.Size([96])
################################################
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.42e-01	time: 00:01:26	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:5.454e-03/SW:1.871e-01/MR:5.345e+00/SR:1.312e+00/MeD:1.010e+00/MaD:4.344e+00/MW:0.555/MAW:0.445
|         0 |         1 |        2 |         3 |         4 |         5 |        6 |         7 |        8 |        9 |        10 |       11 |       12 |       13 |        14 |        15 |        16 |       17 |        18 |       19 |       20 |      21 |       22 |       23 |      24 |       25 |      26 |       27 |        28 |       29 |
|-----------+-----------+----------+-----------+-----------+-----------+----------+-----------+----------+----------+-----------+----------+----------+----------+-----------+-----------+-----------+----------+-----------+----------+----------+---------+----------+----------+---------+----------+---------+----------+-----------+----------|
|   0.00981 |   0.00699 |   0.0102 |   0.00523 |   0.00506 |   0.00662 |   0.0102 |   0.00917 |   0.0105 |   0.0117 |   0.00762 |   0.0105 |   0.0117 |   0.0109 |   0.00988 |   0.00926 |   0.00906 |   0.0105 |   0.00577 |   0.0116 |   0.0122 |   0.013 |   0.0108 |   0.0115 |   0.009 |   0.0118 |   0.013 |   0.0103 |   0.00978 |   0.0094 |
|   4.85    |   2.96    |   5.13   |   2.09    |   2.02    |   2.75    |   5.19   |   4.36    |   5.45   |   6.45   |   3.32    |   5.45   |   6.44   |   5.79   |   4.9     |   4.43    |   4.29    |   5.4    |   2.33    |   6.42   |   6.94   |   7.77  |   5.64   |   6.34   |   4.24  |   6.6    |   7.74  |   5.28   |   4.83    |   4.53   |
|   0.16    |   0.18    |   0.2    |   0.2     |   0.6     |   0.18    |   0.18   |   0.23    |   0.15   |   0.17   |   0.18    |   0.26   |   0.21   |   0.22   |   0.2     |   0.17    |   0.18    |   0.25   |   0.2     |   0.43   |   0.16   |   0.21  |   0.42   |   0.2    |   0.47  |   0.39   |   0.16  |   0.17   |   0.23    |   0.29   |
| nan       | nan       | nan      | nan       | nan       | nan       | nan      | nan       | nan      | nan      | nan       | nan      | nan      | nan      | nan       | nan       | nan       | nan      | nan       | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan     | nan      | nan       | nan      |
| nan       | nan       | nan      | nan       | nan       | nan       | nan      | nan       | nan      | nan      | nan       | nan      | nan      | nan      | nan       | nan       | nan       | nan      | nan       | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan     | nan      | nan       | nan      |
| nan       | nan       | nan      | nan       | nan       | nan       | nan      | nan       | nan      | nan      | nan       | nan      | nan      | nan      | nan       | nan       | nan       | nan      | nan       | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan     | nan      | nan       | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([3, 3, 9, 5, 9, 5, 9, 5, 2, 9, 5, 5, 9, 2, 9, 5, 5, 9, 3, 9])
[2, 3, 5, 9]
TARGETS AFTER CLEANER:  tensor([1, 1, 3, 2, 3, 2, 3, 2, 0, 3, 2, 2, 3, 0, 3, 2, 2, 3, 1, 3])
4000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 4000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 2, 3, 2, 9, 9, 9, 3, 2, 3, 2, 3, 5, 9, 3, 3, 3, 3, 5])
[2, 3, 5, 9]
TARGETS AFTER CLEANER:  tensor([3, 3, 0, 1, 0, 3, 3, 3, 1, 0, 1, 0, 1, 2, 3, 1, 1, 1, 1, 2])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 2, 3, 2, 9, 9, 9, 3, 2, 3, 2, 3, 5, 9, 3, 3, 3, 3, 5])
[2, 3, 5, 9]
TARGETS AFTER CLEANER:  tensor([3, 3, 0, 1, 0, 3, 3, 3, 1, 0, 1, 0, 1, 2, 3, 1, 1, 1, 1, 2])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  20000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_4C_CL
DEPTH:  3
ACTIVATIONS SHAPE:  tensor([[-12.8791,  -7.8530, -11.5267, -18.4314, -21.0844, -27.5280, -26.5336,
          -5.2789, -10.7344, -19.9474, -21.7261, -40.9676, -37.3232, -39.9608,
         -25.3266, -28.8855],
        [ -4.8750, -10.0967,  -7.1571,  -6.6408, -14.4228, -14.0164, -16.5656,
          -2.7434,  -3.6850, -16.5793, -17.8743, -29.8573, -31.8884, -39.6314,
         -25.4024, -24.2160],
        [  6.9219,  -2.8999,  -3.9724,  -6.7927, -13.7605,  -6.7372, -16.6862,
          11.0771,  -0.7644,  -9.1354,  -5.3210,  -4.6178,  -8.7786,  -4.4108,
           5.5568,  -1.3055],
        [  4.9991,  -2.0298,  -0.9408,  -9.1411, -10.6757,   3.2187,  -0.6048,
          24.9746,   4.9632,  -0.7210,  12.4971,  22.2320,  18.6283,  20.1346,
          27.0213,  23.6154],
        [  1.6567,   2.8617,   6.1724,  -0.4425,  -1.4817,   9.9677,  -2.7788,
          12.1300,  11.3889,   5.3994,  14.3014,  19.0252,  30.7244,  29.7758,
          27.8808,  37.1458],
        [ -6.3863,   0.6612,  -0.9585,  -0.5677,  -2.4177,  14.8533,  -3.0234,
          -1.7961,   2.9299,  -4.5512,  -4.0043,  11.4928,  35.5638,  32.1467,
          25.7906,  41.6694],
        [  1.4872,   9.4737,  -3.4841, -13.8380, -11.4480,  -5.6647,  -9.1733,
           7.2659,   4.2981,   2.7809,   1.1441,  15.6527,  37.1897,  38.5373,
          29.2830,  38.7393],
        [ 17.4547,  12.9324,  11.5546, -12.7093, -29.4042, -14.5579,  -1.5017,
           9.7531,  12.2108, -10.0383, -11.9725,   6.2605,  33.7803,  40.2946,
          26.1208,  39.1872],
        [ 26.4297,  20.1344,  27.1415,  -1.2362, -26.6143,  -5.4912,  10.1644,
          19.5563,  22.6091, -14.8411, -19.6945,   9.3864,  31.1396,  19.6549,
          -0.7397,  35.4471],
        [ 22.7735,   7.9125,  25.6754,   4.1295,  -4.5414,  16.4424,  24.3246,
          22.6782,  20.2077, -21.1650, -18.2620,  -0.5122,  25.2894,  12.6375,
         -17.1667,  32.3800],
        [ 12.7074,   2.3390,  20.5299,  -2.9618,  -2.9226,  13.3956,  10.8237,
           5.8130,  -1.1002, -20.6704, -10.3893,  -7.2529,   2.2115,   1.8167,
          -9.9181,  32.2397],
        [ -8.1818, -20.8102,   2.8163,  -6.1731,  -2.2351,   7.7464,  -0.4673,
          -4.2528,  -3.9276, -16.6306, -13.4781,  -8.0604, -14.5606,  -9.7697,
           0.8256,  35.5559],
        [-12.6304, -19.1519,  -9.9259,  -9.2380,  -0.5361,   5.4770,  -4.1162,
          -3.1796,   0.5867,  -3.6948,  -1.9052,  -6.7844, -19.7553, -11.6646,
          -0.1442,  26.5515],
        [-19.3516, -28.0392, -12.2787, -12.6381,  -3.8175,  -4.1166, -12.5944,
          -3.4740,   6.4559,  -4.5219,  -3.2981,  -3.5583, -19.6046, -16.2777,
         -10.9891,   2.1236],
        [ -7.7361, -19.7367,  -6.8259,  -8.3462,  -9.7218,  -2.4101,  -0.9426,
           0.7801,  18.8002,   8.0566, -15.4291, -15.0221, -30.1780, -22.3536,
         -26.7429, -13.4464],
        [-13.8864, -30.5788, -15.9615, -12.6319, -10.6343, -16.3717, -21.8710,
          -3.2883,   6.0773,   2.4859, -28.5422, -25.9780, -40.2581, -38.8573,
         -40.9040, -31.6399]], device='cuda:0')
LAYER_NUM:  2
FINAL_SUM:  [660, 1490, 1284, 760, 97, 1113, 1082, 689, 557, 1195]
acts len:  3
acts keys:  ['conv0', 'conv1', 'conv2']
acts:  {'conv0': [43, 77, 26, 11, 91, 46, 87, 34, 84, 35, 30, 55, 4, 15, 42, 67, 37, 66, 39, 92, 40], 'conv1': [78, 204, 61, 300, 77, 260, 92, 359, 32, 151, 210, 63, 349, 243, 332, 49, 116, 112, 53, 330, 19], 'conv2': [660, 1490, 1284, 760, 97, 1113, 1082, 689, 557, 1195, 205, 1005, 1483, 55, 268, 588, 1383, 1458, 786, 814, 627]}
final_sum len:  1536
delta_weights INFO: 
NUM OF TRACKED COV LAYERS:  1
NUM OF TRACKED WEIGHTS CHANGES PER LAYER:  20
avg_deltas INFO:  <class 'dict'>
avg_deltas keys:  ['blocks.0.layer.weight', 'blocks.1.layer.weight', 'blocks.2.layer.weight']
avg_deltas size:  3
num of averages for 2 layer:  torch.Size([96])
################################################
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.14e-02	time: 00:02:52	Acc_train 0.00	Acc_test 0.00	convergence: 1.73e+01	R1: 1	Info MB:0.000e+00/SB:0.000e+00/MW:5.224e-03/SW:3.132e-01/MR:1.827e+01/SR:2.337e+00/MeD:1.868e+00/MaD:1.727e+01/MW:0.421/MAW:0.579
|        0 |        1 |        2 |        3 |        4 |        5 |        6 |        7 |        8 |        9 |       10 |       11 |       12 |       13 |       14 |       15 |       16 |       17 |      18 |       19 |       20 |       21 |      22 |       23 |       24 |      25 |       26 |       27 |       28 |       29 |
|----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+---------+----------+----------+---------+----------+----------+----------+----------|
|   0.0445 |   0.0442 |   0.0426 |   0.0408 |   0.0408 |   0.0404 |   0.0444 |   0.0373 |   0.0419 |   0.0469 |   0.0391 |   0.0372 |   0.0426 |   0.0367 |   0.0419 |   0.0403 |   0.0442 |   0.0453 |   0.038 |   0.0414 |   0.0419 |   0.0371 |   0.042 |   0.0419 |   0.0439 |   0.035 |   0.0422 |   0.0439 |   0.0385 |   0.0434 |
|  20.8    |  20.5    |  19.18   |  17.64   |  17.68   |  17.31   |  20.75   |  14.89   |  18.56   |  22.99   |  16.27   |  14.8    |  19.13   |  14.49   |  18.52   |  17.22   |  20.5    |  21.49   |  15.46  |  18.11   |  18.59   |  14.76   |  18.64  |  18.52   |  20.26   |  13.25  |  18.79   |  20.29   |  15.85   |  19.8    |
|   0.06   |   0.04   |   0.07   |   0.06   |   0.05   |   0.05   |   0.05   |   0.03   |   0.05   |   0.05   |   0.05   |   0.05   |   0.12   |   0.05   |   0.14   |   0.05   |   0.04   |   0.09   |   0.1   |   0.04   |   0.06   |   0.07   |   0.09  |   0.05   |   0.05   |   0.07  |   0.08   |   0.05   |   0.05   |   0.04   |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models

 ********** Supervised learning of blocks [3] **********
SAVING FOLDER FOR SUP:  C10_4C_CL
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([3, 3, 9, 5, 9, 5, 9, 5, 2, 9, 5, 5, 9, 2, 9, 5, 5, 9, 3, 9])
[2, 3, 5, 9]
TARGETS AFTER CLEANER:  tensor([1, 1, 3, 2, 3, 2, 3, 2, 0, 3, 2, 2, 3, 0, 3, 2, 2, 3, 1, 3])
4000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 4000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 2, 3, 2, 9, 9, 9, 3, 2, 3, 2, 3, 5, 9, 3, 3, 3, 3, 5])
[2, 3, 5, 9]
TARGETS AFTER CLEANER:  tensor([3, 3, 0, 1, 0, 3, 3, 3, 1, 0, 1, 0, 1, 2, 3, 1, 1, 1, 1, 2])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 2, 3, 2, 9, 9, 9, 3, 2, 3, 2, 3, 5, 9, 3, 3, 3, 3, 5])
[2, 3, 5, 9]
TARGETS AFTER CLEANER:  tensor([3, 3, 0, 1, 0, 3, 3, 3, 1, 0, 1, 0, 1, 2, 3, 1, 1, 1, 1, 2])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  20000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Epoch: [1/50]	lr: 1.00e-03	time: 00:03:19	Loss_train 0.21154	Acc_train 65.93	/	Loss_test 0.00979	Acc_test 71.70
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
Epoch: [10/50]	lr: 1.00e-03	time: 00:03:28	Loss_train 0.20676	Acc_train 77.02	/	Loss_test 0.01640	Acc_test 78.00
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
Epoch: [20/50]	lr: 2.50e-04	time: 00:03:37	Loss_train 0.15991	Acc_train 82.50	/	Loss_test 0.01013	Acc_test 81.70
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
Epoch: [30/50]	lr: 1.25e-04	time: 00:03:47	Loss_train 0.11530	Acc_train 84.68	/	Loss_test 0.01011	Acc_test 81.03
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
Epoch: [40/50]	lr: 3.13e-05	time: 00:03:56	Loss_train 0.09265	Acc_train 85.94	/	Loss_test 0.00859	Acc_test 82.47
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
Epoch: [50/50]	lr: 7.81e-06	time: 00:04:06	Loss_train 0.08690	Acc_train 86.26	/	Loss_test 0.00845	Acc_test 82.25
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
RESULT:  {'train_loss': 0.08689773082733154, 'train_acc': 86.25500202178955, 'test_loss': 0.008453312329947948, 'test_acc': 82.25, 'convergence': 17.26828384399414, 'R1': 1, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [2, 3, 5, 9]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [2, 3, 5, 9]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}
IN R1:  {'R1': {'train_loss': 0.08689773082733154, 'train_acc': 86.25500202178955, 'test_loss': 0.008453312329947948, 'test_acc': 82.25, 'convergence': 17.26828384399414, 'R1': 1, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [2, 3, 5, 9]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [2, 3, 5, 9]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}

 Model C10_4C_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=4, bias=True)
[Sequential(
  (0): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=0.7)
  )
  (1): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=1.4)
  )
  (2): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (activation): Triangle(power=1.0)
  )
  (3): BasicBlock(
    (operations): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
    )
    (layer): Linear(in_features=24576, out_features=4, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
)]
LAYER NAME:  Sequential(
  (0): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=0.7)
  )
  (1): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=1.4)
  )
  (2): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (activation): Triangle(power=1.0)
  )
  (3): BasicBlock(
    (operations): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
    )
    (layer): Linear(in_features=24576, out_features=4, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
)
LAYER CHILDREN:  [BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
  (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
  (activation): Triangle(power=0.7)
), BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
  (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
  (activation): Triangle(power=1.4)
), BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (activation): Triangle(power=1.0)
), BasicBlock(
  (operations): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
  )
  (layer): Linear(in_features=24576, out_features=4, bias=True)
  (dropout): Dropout(p=0.5, inplace=False)
)]
subsubl NAME:  Sequential(
  (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
subsubl NAME:  Triangle(power=0.7)
subsubl NAME:  Sequential(
  (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
subsubl NAME:  Triangle(power=1.4)
subsubl NAME:  Sequential(
  (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  AvgPool2d(kernel_size=2, stride=2, padding=0)
subsubl NAME:  Triangle(power=1.0)
subsubl NAME:  Sequential(
  (0): Flatten(start_dim=1, end_dim=-1)
)
subsubl NAME:  Linear(in_features=24576, out_features=4, bias=True)
subsubl NAME:  Dropout(p=0.5, inplace=False)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([8, 8, 0, 6, 6, 1, 6, 1, 0, 8, 8, 6, 0, 0, 6, 6, 1, 6, 6, 0])
[0, 1, 6, 8]
TARGETS AFTER CLEANER:  tensor([3, 3, 0, 2, 2, 1, 2, 1, 0, 3, 3, 2, 0, 0, 2, 2, 1, 2, 2, 0])
4000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 4000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 1, 1, 8, 6, 6, 6, 6, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 8, 1])
[0, 1, 6, 8]
TARGETS AFTER CLEANER:  tensor([2, 1, 1, 3, 2, 2, 2, 2, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 3, 1])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 1, 1, 8, 6, 6, 6, 6, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 8, 1])
[0, 1, 6, 8]
TARGETS AFTER CLEANER:  tensor([2, 1, 1, 3, 2, 2, 2, 2, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 3, 1])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  20000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_4C_CL
DEPTH:  3
ACTIVATIONS SHAPE:  tensor([[  267.2111,   369.4770,    30.7930,  -616.4299,  -657.6948,  -627.4685,
          -578.7861,  -625.6632,  -645.3257,  -707.3281,  -766.8989,  -761.2722,
          -778.7638,  -780.4927,  -624.3306,  -177.9306],
        [  865.1919,  1002.0513,   606.1248,   113.7278,    30.6154,  -190.3437,
          -235.6262,  -342.7597,  -309.0282,  -218.9639,  -241.7423,  -303.0266,
          -377.1545,  -401.1166,  -155.0060,   479.5091],
        [ 1027.4604,  1026.9264,   651.0989,   301.8148,   237.9626,   197.7734,
            88.9366,  -124.9045,  -121.1213,    -5.5073,    -4.1876,     6.1887,
            25.5883,   104.6654,   419.0498,   831.8015],
        [ 1048.4551,   944.0860,   621.2342,   397.9162,   288.0685,   254.1680,
           204.3856,   -35.8506,  -135.6907,   -37.1566,   210.4658,   262.4255,
           336.7259,   386.3551,   631.8073,   813.6368],
        [ 1313.0559,  1101.9065,   993.1376,   573.7744,   609.1000,   474.1328,
           438.5452,   314.1497,   316.4808,   487.8028,   558.8585,   693.4374,
           676.6696,   535.7399,   856.7223,   984.1313],
        [ 1568.3005,  1154.4165,  1118.0234,   772.1075,   796.5856,   635.7002,
           584.7003,   617.5415,   724.1327,   927.0043,  1101.9607,  1150.9016,
           980.5623,   779.7460,  1033.8662,  1281.8809],
        [ 1623.2477,  1147.7354,  1080.0480,   752.2415,   845.6584,   934.7050,
           821.2544,   730.6929,   896.7109,   991.5923,  1170.8699,  1351.3059,
          1211.6228,  1022.3881,  1067.7681,  1354.8433],
        [ 1702.7994,  1184.0144,  1139.2064,   781.5921,   879.9144,  1013.6039,
           891.7274,   771.8322,   858.0297,  1051.2607,  1155.4138,  1153.5210,
          1073.3829,   890.4242,   987.4519,  1368.4937],
        [ 1710.2231,  1199.5381,  1048.1433,   559.2321,   731.3511,   860.5832,
           684.3979,   707.4663,   820.0562,   939.1927,  1045.1814,   905.4055,
           724.9103,   533.0180,   757.0983,  1246.9700],
        [ 1593.3760,  1045.6382,   754.9106,   319.9820,   379.0022,   486.4663,
           424.3756,   697.4538,   728.1906,   673.3957,   647.6547,   490.2256,
           395.4042,   324.9287,   522.2296,  1033.4777],
        [ 1238.6077,   698.2155,   334.4689,  -302.1311,  -124.5813,   199.9518,
           210.4892,   455.7261,   312.2375,   259.0391,   205.5646,    88.2273,
           -58.9278,   -60.7249,   249.5535,   747.0690],
        [  902.4015,   389.9161,    66.1286,  -523.4728,  -389.6703,   -60.3551,
           -79.2334,    51.0444,   108.3808,    43.3521,   -71.0823,  -258.8388,
          -495.4966,  -557.2830,  -196.5262,   352.8081],
        [  371.5927,    92.8609,  -366.9369,  -870.2991,  -716.4644,  -495.8713,
          -382.6105,  -155.3805,  -200.7201,  -200.8124,  -272.4582,  -405.0973,
          -688.9623,  -848.1052,  -491.3463,    97.1951],
        [ -106.3864,  -248.4455,  -688.1300, -1158.3895, -1056.7810,  -872.8906,
          -759.5290,  -703.4492,  -678.7648,  -676.1399,  -632.8713,  -735.5262,
          -913.6912,  -999.0009,  -717.0721,   -79.0967],
        [ -386.9702,  -485.0573,  -925.4836, -1429.2520, -1214.4741,  -937.0660,
          -857.5086,  -853.0985,  -971.0805,  -970.1971,  -956.8290, -1041.8577,
         -1081.5341, -1080.1274,  -952.5778,  -238.1868],
        [ -812.8423,  -885.7179, -1347.3579, -1810.6606, -1676.3763, -1369.7108,
         -1364.8805, -1449.7292, -1585.8412, -1579.4805, -1425.5498, -1512.2319,
         -1466.3374, -1522.3905, -1314.6257,  -830.2158]], device='cuda:0')
LAYER_NUM:  0
FINAL_SUM:  [11, 43, 42, 4, 67, 29, 77, 55, 87, 74]
acts len:  3
acts keys:  ['conv0', 'conv1', 'conv2']
acts:  {'conv0': [11, 43, 42, 4, 67, 29, 77, 55, 87, 74, 84, 26, 46, 41, 10, 37, 28, 91, 5, 19, 58], 'conv1': [78, 204, 61, 300, 77, 260, 92, 359, 32, 151, 210, 63, 349, 243, 332, 49, 116, 112, 53, 330, 19], 'conv2': [268, 1458, 350, 205, 1113, 660, 1284, 1490, 1005, 1383, 1323, 689, 1030, 1359, 537, 75, 61, 557, 964, 301, 924]}
final_sum len:  96
delta_weights INFO: 
NUM OF TRACKED COV LAYERS:  1
NUM OF TRACKED WEIGHTS CHANGES PER LAYER:  20
avg_deltas INFO:  <class 'dict'>
avg_deltas keys:  ['blocks.0.layer.weight', 'blocks.1.layer.weight', 'blocks.2.layer.weight']
avg_deltas size:  3
num of averages for 0 layer:  torch.Size([96])
################################################
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.29e-01	time: 00:00:38	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:5.932e-03/SW:4.950e-01/MR:4.014e+00/SR:1.514e+00/MeD:1.161e+00/MaD:3.395e+00/MW:0.603/MAW:0.397
|       0 |       1 |       2 |       3 |       4 |          5 |       6 |       7 |       8 |       9 |        10 |         11 |      12 |     13 |      14 |      15 |      16 |      17 |      18 |      19 |      20 |      21 |      22 |      23 |      24 |      25 |      26 |     27 |         28 |      29 |
|---------+---------+---------+---------+---------+------------+---------+---------+---------+---------+-----------+------------+---------+--------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+--------+------------+---------|
|   0.117 |   0.129 |   0.108 |   0.147 |   0.109 |   0.000322 |   0.121 |   0.149 |   0.161 |   0.188 |   0.00136 |   0.000132 |   0.149 |   0.15 |   0.134 |   0.183 |   0.124 |   0.165 |   0.161 |   0.177 |   0.172 |   0.125 |   0.128 |   0.141 |   0.161 |   0.148 |   0.151 |   0.17 |   0.000897 |   0.134 |
|   3.16  |   3.59  |   2.84  |   4.37  |   2.87  |   1        |   3.29  |   4.46  |   5.06  |   6.53  |   1       |   1        |   4.45  |   4.49 |   3.82  |   6.26  |   3.41  |   5.24  |   5.03  |   5.87  |   5.6   |   3.44  |   3.56  |   4.11  |   5.06  |   4.44  |   4.59  |   5.49 |   1        |   3.8   |
|   0.51  |   0.5   |   0.57  |   0.38  |   0.64  |  21.59     |   0.3   |   0.43  |   0.45  |   0.51  |   1.97    |   2.82     |   0.3   |   0.42 |   0.42  |   0.39  |   0.49  |   0.4   |   0.44  |   0.42  |   0.33  |   0.39  |   0.46  |   0.53  |   0.46  |   0.31  |   0.32  |   0.33 |   0.88     |   0.49  |
| nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan       | nan        | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan        | nan     |
| nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan       | nan        | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan        | nan     |
| nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan       | nan        | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan        | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([8, 8, 0, 6, 6, 1, 6, 1, 0, 8, 8, 6, 0, 0, 6, 6, 1, 6, 6, 0])
[0, 1, 6, 8]
TARGETS AFTER CLEANER:  tensor([3, 3, 0, 2, 2, 1, 2, 1, 0, 3, 3, 2, 0, 0, 2, 2, 1, 2, 2, 0])
4000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 4000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 1, 1, 8, 6, 6, 6, 6, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 8, 1])
[0, 1, 6, 8]
TARGETS AFTER CLEANER:  tensor([2, 1, 1, 3, 2, 2, 2, 2, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 3, 1])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 1, 1, 8, 6, 6, 6, 6, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 8, 1])
[0, 1, 6, 8]
TARGETS AFTER CLEANER:  tensor([2, 1, 1, 3, 2, 2, 2, 2, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 3, 1])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  20000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_4C_CL
DEPTH:  3
ACTIVATIONS SHAPE:  tensor([[ 4.8985e+00,  7.8911e+00, -6.4918e+00, -1.9614e+01, -2.5342e+01,
         -2.4849e+01, -2.7637e+01, -3.2337e+01, -3.8811e+01, -4.0322e+01,
         -3.4322e+01, -2.5733e+01, -2.8900e+01, -2.9623e+01, -3.0413e+01,
         -8.6312e+00],
        [ 1.2857e+01,  1.7405e+01, -1.6616e+00, -1.7168e+01, -2.5686e+01,
         -2.3925e+01, -1.3956e+01, -1.4781e+01, -2.3079e+01, -2.2945e+01,
         -2.5807e+01, -2.2591e+01, -2.6897e+01, -3.1698e+01, -3.7694e+01,
         -8.1947e+00],
        [ 1.2791e+01,  1.1669e+01,  3.0577e+00, -1.7815e+01, -2.4895e+01,
         -2.2902e+01, -2.1889e+01, -2.6617e+01, -4.3374e+01, -4.0306e+01,
         -3.2482e+01, -2.8964e+01, -2.5725e+01, -2.5208e+01, -2.6182e+01,
          9.4455e-02],
        [ 1.0812e+01,  9.0429e+00, -6.6169e+00, -2.5071e+01, -3.9215e+01,
         -3.7639e+01, -3.9857e+01, -3.0249e+01, -4.4548e+01, -4.9674e+01,
         -4.1162e+01, -3.3893e+01, -2.5075e+01, -2.1555e+01, -1.3866e+01,
          3.0354e+00],
        [ 1.7181e+01,  1.6413e+01,  1.2502e+01, -1.4481e+01, -3.5599e+01,
         -3.1986e+01, -2.3767e+01, -1.6294e+01, -2.9758e+01, -2.8439e+01,
         -2.3061e+01, -1.9616e+01, -4.4624e+00,  2.5426e+00, -1.2529e+01,
          1.2247e+01],
        [ 1.5399e+01,  1.5927e+01,  1.1293e+01, -1.2056e+01, -1.9025e+01,
         -1.1992e+01, -1.4963e+00, -6.5932e+00, -1.2671e+01, -6.1662e+00,
          3.6062e+00,  2.9943e-01, -2.4373e+00, -8.7214e-02, -1.3849e+01,
          1.5530e+01],
        [ 4.7633e+00,  8.5435e+00,  9.2470e+00, -1.6516e+01, -2.2333e+01,
         -2.1823e+01, -7.0928e+00, -1.6142e+00,  2.7320e+00,  4.3226e+00,
          2.9759e+00,  9.1477e+00, -7.5564e+00, -8.1883e+00, -5.7793e+00,
          2.4221e+01],
        [ 7.4480e+00,  9.3860e+00,  1.0980e+01, -2.0147e+01, -1.5186e+01,
         -1.7673e+01, -4.8237e+00, -2.3463e+00, -6.7988e+00, -1.2556e-01,
          7.0577e-02, -1.8823e+01, -2.9420e+01, -2.2705e+01,  1.9357e+00,
          2.5546e+01],
        [ 1.0368e+01,  1.1686e+01,  1.1684e+01,  3.1782e-01,  6.9289e+00,
         -4.1676e+00, -2.9879e+00, -1.4247e+00, -7.8493e+00, -6.1670e+00,
         -1.1722e+01, -2.8487e+01, -4.5552e+01, -4.1624e+01,  3.7426e+00,
          2.0482e+01],
        [ 2.0761e+01,  3.0528e+01,  1.7241e+01,  1.1766e+01,  1.2643e+01,
         -5.9870e+00,  1.2462e+00, -2.0598e+00, -3.7803e+00, -5.3810e+00,
         -6.5903e+00, -1.7982e+01, -4.8093e+01, -3.8076e+01,  8.7445e+00,
          2.6848e+01],
        [ 2.0775e+01,  3.1342e+01,  1.7835e+01,  6.8235e+00,  1.0303e+01,
          2.7935e-01, -1.4822e+00,  1.0255e+01, -2.1338e+00,  2.5370e+00,
         -2.9593e+00, -1.0636e+01, -2.6117e+01, -2.4711e+01, -8.7250e+00,
          1.5005e+01],
        [ 3.0422e+01,  3.3398e+01,  1.9758e+01, -1.6905e+00,  1.1436e+00,
         -1.8253e+00, -7.3245e-01,  1.0697e+01, -4.1010e+00,  2.1588e+00,
          1.9801e+00, -1.1911e+01, -1.9480e+01, -3.1912e+01, -2.8666e+01,
         -1.3123e+01],
        [ 2.4867e+01,  1.6377e+01,  1.5660e+01,  6.4183e+00, -4.4247e+00,
         -2.9905e+00, -2.2701e+00,  1.7845e-01, -1.6865e+01, -1.3454e+01,
         -6.9959e+00, -1.4118e+01, -2.0341e+01, -3.7746e+01, -3.0194e+01,
         -1.3964e+01],
        [ 2.7229e+01,  1.7514e+01,  2.5608e+01,  1.9733e+00, -3.6172e+00,
         -3.2371e+00, -1.6969e+01, -8.1409e+00, -1.4394e+01, -1.4365e+01,
         -1.4644e+01, -9.7564e+00, -1.7925e+01, -3.4133e+01, -2.6008e+01,
         -7.2356e+00],
        [ 6.8765e+00,  8.8222e+00,  1.0296e+01, -4.0341e+00, -3.3773e+00,
         -1.0475e+01, -1.7929e+01, -1.6497e+01, -1.5577e+01, -2.1963e+01,
         -2.0179e+01, -1.4100e+01, -2.4880e+01, -2.8393e+01, -1.9967e+01,
         -4.9113e+00],
        [ 3.6896e-02,  3.4786e+00,  4.4293e+00, -1.0498e+01, -1.4002e+01,
         -2.3899e+01, -3.4841e+01, -3.0664e+01, -2.4294e+01, -3.2316e+01,
         -3.4586e+01, -2.6259e+01, -3.7770e+01, -4.1104e+01, -3.2604e+01,
         -2.4342e+01]], device='cuda:0')
LAYER_NUM:  1
FINAL_SUM:  [349, 78, 63, 61, 330, 49, 19, 8, 276, 300]
acts len:  3
acts keys:  ['conv0', 'conv1', 'conv2']
acts:  {'conv0': [11, 43, 67, 26, 42, 58, 84, 10, 55, 46, 91, 74, 75, 28, 87, 5, 37, 4, 92, 77, 15], 'conv1': [349, 78, 63, 61, 330, 49, 19, 8, 276, 300, 174, 359, 44, 205, 180, 204, 77, 215, 32, 191, 324], 'conv2': [268, 1458, 350, 205, 1113, 660, 1284, 1490, 1005, 1383, 1323, 689, 1030, 1359, 537, 75, 61, 557, 964, 301, 924]}
final_sum len:  384
delta_weights INFO: 
NUM OF TRACKED COV LAYERS:  1
NUM OF TRACKED WEIGHTS CHANGES PER LAYER:  20
avg_deltas INFO:  <class 'dict'>
avg_deltas keys:  ['blocks.0.layer.weight', 'blocks.1.layer.weight', 'blocks.2.layer.weight']
avg_deltas size:  3
num of averages for 1 layer:  torch.Size([96])
################################################
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.29e-01	time: 00:01:26	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:3.835e-03/SW:1.718e-01/MR:4.786e+00/SR:1.615e+00/MeD:1.264e+00/MaD:4.718e+00/MW:0.630/MAW:0.370
|         0 |        1 |        2 |          3 |         4 |         5 |         6 |        7 |        8 |        9 |       10 |        11 |      12 |        13 |        14 |        15 |       16 |        17 |       18 |       19 |       20 |       21 |        22 |       23 |      24 |       25 |       26 |       27 |        28 |        29 |
|-----------+----------+----------+------------+-----------+-----------+-----------+----------+----------+----------+----------+-----------+---------+-----------+-----------+-----------+----------+-----------+----------+----------+----------+----------+-----------+----------+---------+----------+----------+----------+-----------+-----------|
|   0.00842 |   0.0116 |   0.0103 |   0.000507 |   0.00709 |   0.00346 |   0.00754 |   0.0106 |   0.0112 |   0.0115 |   0.0146 |   0.00885 |   0.011 |   0.00803 |   0.00814 |   0.00893 |   0.0114 |   0.00925 |   0.0016 |   0.0104 |   0.0124 |   0.0117 |   0.00968 |   0.0118 |   0.009 |   0.0128 |   0.0122 |   0.0091 |   0.00929 |   0.00973 |
|   3.84    |   6.39   |   5.28   |   1.01     |   3.01    |   1.48    |   3.28    |   5.48   |   6.05   |   6.25   |   9.5    |   4.13    |   5.83  |   3.58    |   3.65    |   4.19    |   6.2    |   4.42    |   1.1    |   5.36   |   7.1    |   6.5    |   4.75    |   6.61   |   4.24  |   7.55   |   6.91   |   4.31   |   4.45    |   4.79    |
|   0.07    |   0.05   |   0.14   |   0.58     |   0.09    |   0.16    |   0.13    |   0.11   |   0.16   |   0.17   |   0.08   |   0.15    |   0.15  |   0.13    |   0.14    |   0.1     |   0.13   |   0.11    |   0.16   |   0.29   |   0.17   |   0.15   |   0.17    |   0.2    |   0.09  |   0.22   |   0.17   |   0.12   |   0.12    |   0.13    |
| nan       | nan      | nan      | nan        | nan       | nan       | nan       | nan      | nan      | nan      | nan      | nan       | nan     | nan       | nan       | nan       | nan      | nan       | nan      | nan      | nan      | nan      | nan       | nan      | nan     | nan      | nan      | nan      | nan       | nan       |
| nan       | nan      | nan      | nan        | nan       | nan       | nan       | nan      | nan      | nan      | nan      | nan       | nan     | nan       | nan       | nan       | nan      | nan       | nan      | nan      | nan      | nan      | nan       | nan      | nan     | nan      | nan      | nan      | nan       | nan       |
| nan       | nan      | nan      | nan        | nan       | nan       | nan       | nan      | nan      | nan      | nan      | nan       | nan     | nan       | nan       | nan       | nan      | nan       | nan      | nan      | nan      | nan      | nan       | nan      | nan     | nan      | nan      | nan      | nan       | nan       |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([8, 8, 0, 6, 6, 1, 6, 1, 0, 8, 8, 6, 0, 0, 6, 6, 1, 6, 6, 0])
[0, 1, 6, 8]
TARGETS AFTER CLEANER:  tensor([3, 3, 0, 2, 2, 1, 2, 1, 0, 3, 3, 2, 0, 0, 2, 2, 1, 2, 2, 0])
4000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 4000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 1, 1, 8, 6, 6, 6, 6, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 8, 1])
[0, 1, 6, 8]
TARGETS AFTER CLEANER:  tensor([2, 1, 1, 3, 2, 2, 2, 2, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 3, 1])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 1, 1, 8, 6, 6, 6, 6, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 8, 1])
[0, 1, 6, 8]
TARGETS AFTER CLEANER:  tensor([2, 1, 1, 3, 2, 2, 2, 2, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 3, 1])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  20000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_4C_CL
DEPTH:  3
ACTIVATIONS SHAPE:  tensor([[ 17.7098,  22.5341,  10.1009,  -0.7360,  -5.0070,  -4.1957,  -4.2820,
          -8.0704, -15.1818, -19.3343, -18.9766, -12.5975, -14.4384, -15.1318,
         -15.7809,   4.6827],
        [ 21.1142,  25.4249,   9.8117,  -4.1339, -10.7475,  -9.0314,   0.1332,
          -1.2370,  -7.1735,  -9.7011, -17.4104, -14.8329, -15.6930, -18.1520,
         -24.6945,   3.6055],
        [ 19.7583,  19.3697,  13.2918,  -4.8500, -12.8242, -10.8253, -11.1475,
         -15.1497, -25.1317, -23.0133, -20.9342, -19.0409, -15.8292, -15.5219,
         -17.5025,   7.5487],
        [ 16.2439,  16.8690,   6.0882,  -9.7670, -24.2452, -23.0893, -25.8414,
         -16.5697, -25.7533, -30.3653, -25.7891, -21.7322, -13.5795, -11.9259,
          -9.8987,   5.7599],
        [ 19.6070,  22.5664,  21.6639,  -0.8634, -21.6818, -16.6911,  -6.0163,
          -2.5768, -13.2891, -11.3604, -10.6654,  -8.6466,   3.4243,   4.6279,
         -12.8868,  12.6462],
        [ 16.2386,  21.2896,  17.9903,  -1.9384,  -6.8499,  -0.2453,  11.2222,
           4.4222,  -1.1922,   3.5545,  10.8535,   5.5036,   1.9889,   2.2781,
         -11.7467,  15.9874],
        [  7.7341,  17.3840,  16.1802,  -4.8130,  -7.8737,  -9.0798,   4.0848,
           6.9413,  10.6013,  10.3297,   8.5863,  12.3529,  -1.1321,  -5.8532,
          -7.7526,  23.6210],
        [  9.6665,  14.9354,  15.9938,  -9.8235,  -5.1632,  -4.4780,   7.5410,
           6.3596,   0.9276,   8.4542,   8.8532,  -9.2294, -24.0639, -19.0080,
          -1.0016,  18.1538],
        [ 10.3999,  13.7913,  13.7828,   5.8902,  10.7124,   2.9350,   7.7554,
           7.3699,  -0.6970,   4.1714,   1.4679, -15.5545, -31.9008, -30.6065,
           1.7958,  13.7362],
        [ 14.7163,  28.4052,  17.5268,  14.1649,  14.8674,  -0.1958,   7.4426,
           4.5990,   0.6921,   0.4182,   5.3108,  -3.6247, -30.9237, -25.8424,
           9.2016,  20.2206],
        [ 12.4902,  29.1135,  18.4659,   9.3265,  12.4599,   3.8033,   1.9861,
          11.9720,   1.6457,   6.4451,   3.2915,   0.8676, -13.5942, -16.3712,
          -6.1300,  11.6573],
        [ 21.6746,  30.1829,  19.0618,   1.8626,   3.8977,  -0.0892,   0.7613,
          11.9750,  -2.3311,   3.7332,   2.8241,  -3.4880,  -6.3972, -21.8168,
         -19.2050,  -7.5015],
        [ 18.9611,  15.6527,  15.7719,   8.8918,  -1.1169,  -2.2581,  -1.1443,
           3.9749, -13.3233,  -8.4970,  -3.9623,  -5.1998,  -7.5353, -26.9338,
         -20.8504,  -5.1209],
        [ 25.5697,  19.0916,  29.4573,  10.5237,   4.1150,  -0.9332, -11.6328,
          -1.3942,  -7.9802,  -7.4254,  -5.8857,   2.0321,  -5.9196, -22.9602,
         -15.9866,   1.7025],
        [ 11.3921,  12.5917,  17.5264,   5.1766,   3.9061,  -4.2030, -10.4865,
          -4.2379,  -3.3841, -10.5650,  -8.3606,  -0.4975, -10.3587, -14.5299,
          -7.7857,   4.8061],
        [  6.3048,   8.8326,  12.5846,  -0.5777,  -4.2976, -16.5863, -25.8965,
         -18.6704, -12.8352, -19.6014, -21.7190, -12.8761, -21.9352, -26.6017,
         -18.2276, -11.2147]], device='cuda:0')
LAYER_NUM:  2
FINAL_SUM:  [436, 1261, 903, 760, 117, 1434, 354, 55, 676, 786]
acts len:  3
acts keys:  ['conv0', 'conv1', 'conv2']
acts:  {'conv0': [11, 43, 67, 26, 42, 58, 84, 10, 55, 46, 91, 74, 75, 28, 87, 5, 37, 4, 92, 77, 15], 'conv1': [349, 63, 61, 78, 300, 77, 330, 19, 53, 158, 49, 191, 204, 92, 324, 247, 67, 116, 243, 294, 10], 'conv2': [436, 1261, 903, 760, 117, 1434, 354, 55, 676, 786, 924, 927, 956, 128, 1113, 232, 61, 97, 1343, 1284, 286]}
final_sum len:  1536
delta_weights INFO: 
NUM OF TRACKED COV LAYERS:  1
NUM OF TRACKED WEIGHTS CHANGES PER LAYER:  20
avg_deltas INFO:  <class 'dict'>
avg_deltas keys:  ['blocks.0.layer.weight', 'blocks.1.layer.weight', 'blocks.2.layer.weight']
avg_deltas size:  3
num of averages for 2 layer:  torch.Size([96])
################################################
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 3.97e-02	time: 00:02:56	Acc_train 0.00	Acc_test 0.00	convergence: 1.59e+01	R1: 1	Info MB:0.000e+00/SB:0.000e+00/MW:1.097e-02/SW:2.886e-01/MR:1.686e+01/SR:1.979e+00/MeD:1.570e+00/MaD:1.586e+01/MW:0.462/MAW:0.538
|        0 |        1 |        2 |        3 |        4 |        5 |        6 |        7 |        8 |        9 |       10 |      11 |       12 |       13 |       14 |       15 |      16 |       17 |       18 |      19 |       20 |      21 |      22 |       23 |       24 |       25 |       26 |       27 |       28 |      29 |
|----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+---------+----------+----------+---------+----------+---------+---------+----------+----------+----------+----------+----------+----------+---------|
|   0.0418 |   0.0419 |   0.0437 |   0.0392 |   0.0386 |   0.0392 |   0.0387 |   0.0402 |   0.0402 |   0.0445 |   0.0438 |   0.039 |   0.0362 |   0.0377 |   0.0398 |   0.0383 |   0.045 |   0.0409 |   0.0356 |   0.039 |   0.0426 |   0.036 |   0.038 |   0.0417 |   0.0393 |   0.0371 |   0.0375 |   0.0388 |   0.0367 |   0.042 |
|  18.45   |  18.55   |  20.09   |  16.37   |  15.92   |  16.4    |  15.95   |  17.15   |  17.18   |  20.78   |  20.18   |  16.2   |  14.1    |  15.22   |  16.84   |  15.64   |  21.23  |  17.72   |  13.7    |  16.2   |  19.17   |  13.95  |  15.47  |  18.37   |  16.48   |  14.75   |  15.07   |  16.04   |  14.49   |  18.67  |
|   0.08   |   0.05   |   0.06   |   0.05   |   0.05   |   0.06   |   0.06   |   0.04   |   0.05   |   0.06   |   0.05   |   0.07  |   0.07   |   0.03   |   0.06   |   0.05   |   0.04  |   0.08   |   0.06   |   0.05  |   0.06   |   0.05  |   0.06  |   0.08   |   0.05   |   0.06   |   0.07   |   0.06   |   0.05   |   0.07  |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan     | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan     |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan     | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan     |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan     | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models

 ********** Supervised learning of blocks [3] **********
SAVING FOLDER FOR SUP:  C10_4C_CL
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([8, 8, 0, 6, 6, 1, 6, 1, 0, 8, 8, 6, 0, 0, 6, 6, 1, 6, 6, 0])
[0, 1, 6, 8]
TARGETS AFTER CLEANER:  tensor([3, 3, 0, 2, 2, 1, 2, 1, 0, 3, 3, 2, 0, 0, 2, 2, 1, 2, 2, 0])
4000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 4000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 1, 1, 8, 6, 6, 6, 6, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 8, 1])
[0, 1, 6, 8]
TARGETS AFTER CLEANER:  tensor([2, 1, 1, 3, 2, 2, 2, 2, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 3, 1])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 1, 1, 8, 6, 6, 6, 6, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 8, 1])
[0, 1, 6, 8]
TARGETS AFTER CLEANER:  tensor([2, 1, 1, 3, 2, 2, 2, 2, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 3, 1])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  20000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Epoch: [1/50]	lr: 1.00e-03	time: 00:03:27	Loss_train 0.33940	Acc_train 77.76	/	Loss_test 0.00915	Acc_test 88.00
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
Epoch: [10/50]	lr: 1.00e-03	time: 00:03:35	Loss_train 0.12302	Acc_train 90.22	/	Loss_test 0.00849	Acc_test 91.97
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
Epoch: [20/50]	lr: 2.50e-04	time: 00:03:44	Loss_train 0.05918	Acc_train 94.41	/	Loss_test 0.00732	Acc_test 92.85
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
Epoch: [30/50]	lr: 1.25e-04	time: 00:03:54	Loss_train 0.04016	Acc_train 95.61	/	Loss_test 0.00661	Acc_test 93.20
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
Epoch: [40/50]	lr: 3.13e-05	time: 00:04:03	Loss_train 0.03295	Acc_train 96.10	/	Loss_test 0.00647	Acc_test 93.18
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
Epoch: [50/50]	lr: 7.81e-06	time: 00:04:13	Loss_train 0.02927	Acc_train 96.38	/	Loss_test 0.00652	Acc_test 93.18
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_4C_CL/models
RESULT:  {'train_loss': 0.02927238680422306, 'train_acc': 96.38350009918213, 'test_loss': 0.006520681548863649, 'test_acc': 93.17500305175781, 'convergence': 15.863688468933105, 'R1': 1, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [0, 1, 6, 8]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [0, 1, 6, 8]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}
IN R2:  {'R1': {'train_loss': 0.08689773082733154, 'train_acc': 86.25500202178955, 'test_loss': 0.008453312329947948, 'test_acc': 82.25, 'convergence': 17.26828384399414, 'R1': 1, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [2, 3, 5, 9]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [2, 3, 5, 9]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}, 'R2': {'train_loss': 0.02927238680422306, 'train_acc': 96.38350009918213, 'test_loss': 0.006520681548863649, 'test_acc': 93.17500305175781, 'convergence': 15.863688468933105, 'R1': 1, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [0, 1, 6, 8]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 4, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 4, 'selected_classes': [0, 1, 6, 8]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}

 Model C10_4C_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=4, bias=True)
[Sequential(
  (0): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=0.7)
  )
  (1): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=1.4)
  )
  (2): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (activation): Triangle(power=1.0)
  )
  (3): BasicBlock(
    (operations): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
    )
    (layer): Linear(in_features=24576, out_features=4, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
)]
LAYER NAME:  Sequential(
  (0): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=0.7)
  )
  (1): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=1.4)
  )
  (2): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (activation): Triangle(power=1.0)
  )
  (3): BasicBlock(
    (operations): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
    )
    (layer): Linear(in_features=24576, out_features=4, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
)
LAYER CHILDREN:  [BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
  (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
  (activation): Triangle(power=0.7)
), BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
  (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
  (activation): Triangle(power=1.4)
), BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (activation): Triangle(power=1.0)
), BasicBlock(
  (operations): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
  )
  (layer): Linear(in_features=24576, out_features=4, bias=True)
  (dropout): Dropout(p=0.5, inplace=False)
)]
subsubl NAME:  Sequential(
  (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
subsubl NAME:  Triangle(power=0.7)
subsubl NAME:  Sequential(
  (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
subsubl NAME:  Triangle(power=1.4)
subsubl NAME:  Sequential(
  (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  AvgPool2d(kernel_size=2, stride=2, padding=0)
subsubl NAME:  Triangle(power=1.0)
subsubl NAME:  Sequential(
  (0): Flatten(start_dim=1, end_dim=-1)
)
subsubl NAME:  Linear(in_features=24576, out_features=4, bias=True)
subsubl NAME:  Dropout(p=0.5, inplace=False)
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([3, 3, 9, 5, 9, 5, 9, 5, 2, 9, 5, 5, 9, 2, 9, 5, 5, 9, 3, 9])
[2, 3, 5, 9]
TARGETS AFTER CLEANER:  tensor([1, 1, 3, 2, 3, 2, 3, 2, 0, 3, 2, 2, 3, 0, 3, 2, 2, 3, 1, 3])
4000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 4000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 2, 3, 2, 9, 9, 9, 3, 2, 3, 2, 3, 5, 9, 3, 3, 3, 3, 5])
[2, 3, 5, 9]
TARGETS AFTER CLEANER:  tensor([3, 3, 0, 1, 0, 3, 3, 3, 1, 0, 1, 0, 1, 2, 3, 1, 1, 1, 1, 2])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 2, 3, 2, 9, 9, 9, 3, 2, 3, 2, 3, 5, 9, 3, 3, 3, 3, 5])
[2, 3, 5, 9]
TARGETS AFTER CLEANER:  tensor([3, 3, 0, 1, 0, 3, 3, 3, 1, 0, 1, 0, 1, 2, 3, 1, 1, 1, 1, 2])
20000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 20000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  20000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Accuracy of the network on the 1st dataset: 32.175 %
Test loss on the 1st dataset: 0.169

