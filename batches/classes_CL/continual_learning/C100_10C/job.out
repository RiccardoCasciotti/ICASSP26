--------------- /leonardo/prod/opt/modulefiles/deeplrn/libraries ---------------
cineca-ai/3.0.0  cineca-ai/4.0.0  cineca-ai/4.1.1(default)  
cineca-ai/3.0.1  cineca-ai/4.1.0  cineca-ai/4.3.0           

Key:
(symbolic-version)  
BLOCKS:  {'b0': {'arch': 'CNN', 'preset': 'softkrotov-c96-k5-p2-s1-d1-b0-t1-lr0.08-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 0, 'batch_norm': False, 'pool': {'type': 'max', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 0.7}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5}}, 'b1': {'arch': 'CNN', 'preset': 'softkrotov-c384-k3-p1-s1-d1-b0-t0.65-lr0.005-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 1, 'batch_norm': False, 'pool': {'type': 'max', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 1.4}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3}}, 'b2': {'arch': 'CNN', 'preset': 'softkrotov-c1536-k3-p1-s1-d1-b0-t0.25-lr0.01-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 2, 'batch_norm': False, 'pool': {'type': 'avg', 'kernel_size': 2, 'stride': 2, 'padding': 0}, 'activation': {'function': 'triangle', 'param': 1.0}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3}}, 'b3': {'arch': 'MLP', 'preset': 'BP-c10', 'operation': 'flatten', 'num': 3, 'att_dropout': None, 'dropout': 0.5, 'layer': {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.25, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10}, 'pool': None, 'activation': None}}
CL:  True
{'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 100, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True}
CL:  True
{'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 100, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 50, 'validation': False, 'continual_learning': True}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.11048543456039805, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10, 'in_channels': 24576, 'old_channels': 1536, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=10, bias=True)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([71, 71, 25, 63, 17,  2, 32, 71, 77, 63, 66, 32, 32, 77, 71, 17, 25, 71,
        25, 77])
[2, 17, 25, 32, 63, 66, 71, 77, 80, 98]
TARGETS AFTER CLEANER:  tensor([6, 6, 2, 4, 1, 0, 3, 6, 7, 4, 5, 3, 3, 7, 6, 1, 2, 6, 2, 7])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([17, 71, 80, 71, 17, 71, 98, 66, 77, 32, 66, 63, 63, 32, 32, 66, 98, 80,
         2, 63])
[2, 17, 25, 32, 63, 66, 71, 77, 80, 98]
TARGETS AFTER CLEANER:  tensor([1, 6, 8, 6, 1, 6, 9, 5, 7, 3, 5, 4, 4, 3, 3, 5, 9, 8, 0, 4])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([17, 71, 80, 71, 17, 71, 98, 66, 77, 32, 66, 63, 63, 32, 32, 66, 98, 80,
         2, 63])
[2, 17, 25, 32, 63, 66, 71, 77, 80, 98]
TARGETS AFTER CLEANER:  tensor([1, 6, 8, 6, 1, 6, 9, 5, 7, 3, 5, 4, 4, 3, 3, 5, 9, 8, 0, 4])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  5000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_10C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.66e-01	time: 00:00:19	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.861e-02/SW:6.808e-01/MR:5.600e+00/SR:1.858e+00/MeD:1.501e+00/MaD:4.600e+00/MW:0.563/MAW:0.437
|       0 |       1 |       2 |       3 |       4 |       5 |       6 |       7 |       8 |       9 |      10 |      11 |      12 |      13 |      14 |      15 |         16 |      17 |      18 |      19 |      20 |      21 |      22 |      23 |      24 |         25 |      26 |      27 |      28 |      29 |
|---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+------------+---------+---------+---------+---------+---------+---------+---------+---------+------------+---------+---------+---------+---------|
|   0.149 |   0.212 |   0.179 |   0.196 |   0.135 |   0.165 |   0.184 |   0.209 |   0.138 |   0.224 |   0.103 |   0.139 |   0.184 |   0.154 |   0.168 |   0.204 |   4.78e-05 |   0.167 |   0.184 |   0.195 |   0.199 |   0.179 |   0.171 |   0.207 |   0.188 |   3.91e-05 |   0.212 |   0.172 |   0.149 |   0.219 |
|   4.47  |   8.04  |   6.01  |   6.99  |   3.83  |   5.27  |   6.27  |   7.81  |   3.98  |   8.87  |   2.66  |   4.04  |   6.31  |   4.68  |   5.42  |   7.52  |   1        |   5.37  |   6.27  |   6.94  |   7.19  |   6     |   5.56  |   7.72  |   6.5   |   1        |   8.02  |   5.63  |   4.48  |   8.47  |
|   0.65  |   0.49  |   0.4   |   0.5   |   1.05  |   1.62  |   0.78  |   0.49  |   0.92  |   0.39  |   1.1   |   0.58  |   0.65  |   0.44  |   1.01  |   0.47  |   8.51     |   0.61  |   0.59  |   0.92  |   0.69  |   0.85  |   0.53  |   0.49  |   0.49  |  10.9      |   0.62  |   0.85  |   0.51  |   0.5   |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([71, 71, 25, 63, 17,  2, 32, 71, 77, 63, 66, 32, 32, 77, 71, 17, 25, 71,
        25, 77])
[2, 17, 25, 32, 63, 66, 71, 77, 80, 98]
TARGETS AFTER CLEANER:  tensor([6, 6, 2, 4, 1, 0, 3, 6, 7, 4, 5, 3, 3, 7, 6, 1, 2, 6, 2, 7])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([17, 71, 80, 71, 17, 71, 98, 66, 77, 32, 66, 63, 63, 32, 32, 66, 98, 80,
         2, 63])
[2, 17, 25, 32, 63, 66, 71, 77, 80, 98]
TARGETS AFTER CLEANER:  tensor([1, 6, 8, 6, 1, 6, 9, 5, 7, 3, 5, 4, 4, 3, 3, 5, 9, 8, 0, 4])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([17, 71, 80, 71, 17, 71, 98, 66, 77, 32, 66, 63, 63, 32, 32, 66, 98, 80,
         2, 63])
[2, 17, 25, 32, 63, 66, 71, 77, 80, 98]
TARGETS AFTER CLEANER:  tensor([1, 6, 8, 6, 1, 6, 9, 5, 7, 3, 5, 4, 4, 3, 3, 5, 9, 8, 0, 4])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  5000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_10C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.66e-01	time: 00:00:30	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:-1.527e-03/SW:5.241e-01/MR:1.522e+01/SR:2.387e+00/MeD:1.933e+00/MaD:7.046e+00/MW:0.693/MAW:0.307
|        0 |        1 |        2 |        3 |        4 |       5 |        6 |        7 |        8 |        9 |       10 |       11 |       12 |       13 |       14 |       15 |       16 |       17 |       18 |       19 |       20 |       21 |       22 |       23 |       24 |       25 |       26 |       27 |      28 |       29 |
|----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------|
|   0.0196 |   0.0178 |   0.0186 |   0.0196 |   0.0148 |   0.018 |   0.0188 |   0.0186 |   0.0174 |   0.0184 |   0.0192 |   0.0199 |   0.0193 |   0.0192 |   0.0202 |   0.0187 |   0.0196 |   0.0169 |   0.0158 |   0.0178 |   0.0198 |   0.0208 |   0.0171 |   0.0183 |   0.0169 |   0.0189 |   0.0202 |   0.0183 |   0.017 |   0.0201 |
|  16.39   |  13.65   |  14.82   |  16.37   |   9.82   |  14.02  |  15.19   |  14.87   |  13.05   |  14.48   |  15.68   |  16.91   |  15.86   |  15.75   |  17.3    |  14.94   |  16.32   |  12.47   |  10.95   |  13.61   |  16.74   |  18.33   |  12.73   |  14.33   |  12.39   |  15.25   |  17.3    |  14.35   |  12.59  |  17.17   |
|   0.22   |   0.26   |   0.3    |   0.17   |   0.89   |   0.26  |   0.25   |   0.22   |   0.24   |   0.25   |   0.19   |   0.21   |   0.26   |   0.23   |   0.16   |   0.23   |   0.18   |   0.41   |   0.36   |   0.26   |   0.15   |   0.22   |   0.54   |   0.35   |   0.65   |   0.39   |   0.16   |   0.2    |   0.3   |   0.2    |
| nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      |
| nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      |
| nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([71, 71, 25, 63, 17,  2, 32, 71, 77, 63, 66, 32, 32, 77, 71, 17, 25, 71,
        25, 77])
[2, 17, 25, 32, 63, 66, 71, 77, 80, 98]
TARGETS AFTER CLEANER:  tensor([6, 6, 2, 4, 1, 0, 3, 6, 7, 4, 5, 3, 3, 7, 6, 1, 2, 6, 2, 7])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([17, 71, 80, 71, 17, 71, 98, 66, 77, 32, 66, 63, 63, 32, 32, 66, 98, 80,
         2, 63])
[2, 17, 25, 32, 63, 66, 71, 77, 80, 98]
TARGETS AFTER CLEANER:  tensor([1, 6, 8, 6, 1, 6, 9, 5, 7, 3, 5, 4, 4, 3, 3, 5, 9, 8, 0, 4])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([17, 71, 80, 71, 17, 71, 98, 66, 77, 32, 66, 63, 63, 32, 32, 66, 98, 80,
         2, 63])
[2, 17, 25, 32, 63, 66, 71, 77, 80, 98]
TARGETS AFTER CLEANER:  tensor([1, 6, 8, 6, 1, 6, 9, 5, 7, 3, 5, 4, 4, 3, 3, 5, 9, 8, 0, 4])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  5000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_10C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.64e-02	time: 00:00:43	Acc_train 0.00	Acc_test 0.00	convergence: 2.16e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:4.360e-04/SW:3.871e-01/MR:2.260e+01/SR:2.658e+00/MeD:2.140e+00/MaD:9.102e+00/MW:0.460/MAW:0.540
|        0 |       1 |        2 |        3 |        4 |        5 |        6 |      7 |        8 |        9 |       10 |       11 |       12 |       13 |       14 |       15 |       16 |       17 |       18 |       19 |       20 |       21 |       22 |       23 |       24 |       25 |       26 |       27 |       28 |       29 |
|----------+---------+----------+----------+----------+----------+----------+--------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------|
|   0.0475 |   0.047 |   0.0489 |   0.0495 |   0.0478 |   0.0463 |   0.0509 |   0.04 |   0.0503 |   0.0498 |   0.0465 |   0.0453 |   0.0472 |   0.0382 |   0.0447 |   0.0452 |   0.0475 |   0.0508 |   0.0456 |   0.0459 |   0.0473 |   0.0451 |   0.0455 |   0.0485 |   0.0482 |   0.0406 |   0.0443 |   0.0468 |   0.0439 |   0.0432 |
|  23.59   |  23.12  |  24.91   |  25.55   |  23.83   |  22.39   |  26.91   |  17    |  26.28   |  25.77   |  22.63   |  21.54   |  23.27   |  15.62   |  21.02   |  21.43   |  23.57   |  26.83   |  21.83   |  22.07   |  23.41   |  21.35   |  21.7    |  24.52   |  24.22   |  17.48   |  20.59   |  22.9    |  20.29   |  19.65   |
|   0.03   |   0.03  |   0.07   |   0.01   |   0.03   |   0.07   |   0.02   |   0.06 |   0.02   |   0.01   |   0.08   |   0.08   |   0.15   |   0.12   |   0.22   |   0.04   |   0.05   |   0.04   |   0.09   |   0.05   |   0.06   |   0.08   |   0.28   |   0.04   |   0.03   |   0.08   |   0.06   |   0.06   |   0.06   |   0.05   |
| nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan    | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan    | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan    | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models

 ********** Supervised learning of blocks [3] **********
SAVING FOLDER FOR SUP:  C100_10C_CL
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([71, 71, 25, 63, 17,  2, 32, 71, 77, 63, 66, 32, 32, 77, 71, 17, 25, 71,
        25, 77])
[2, 17, 25, 32, 63, 66, 71, 77, 80, 98]
TARGETS AFTER CLEANER:  tensor([6, 6, 2, 4, 1, 0, 3, 6, 7, 4, 5, 3, 3, 7, 6, 1, 2, 6, 2, 7])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([17, 71, 80, 71, 17, 71, 98, 66, 77, 32, 66, 63, 63, 32, 32, 66, 98, 80,
         2, 63])
[2, 17, 25, 32, 63, 66, 71, 77, 80, 98]
TARGETS AFTER CLEANER:  tensor([1, 6, 8, 6, 1, 6, 9, 5, 7, 3, 5, 4, 4, 3, 3, 5, 9, 8, 0, 4])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([17, 71, 80, 71, 17, 71, 98, 66, 77, 32, 66, 63, 63, 32, 32, 66, 98, 80,
         2, 63])
[2, 17, 25, 32, 63, 66, 71, 77, 80, 98]
TARGETS AFTER CLEANER:  tensor([1, 6, 8, 6, 1, 6, 9, 5, 7, 3, 5, 4, 4, 3, 3, 5, 9, 8, 0, 4])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  5000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Epoch: [1/50]	lr: 1.00e-03	time: 00:00:56	Loss_train 0.86418	Acc_train 43.96	/	Loss_test 0.01967	Acc_test 54.70
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models
Epoch: [10/50]	lr: 1.00e-03	time: 00:00:58	Loss_train 0.23069	Acc_train 72.19	/	Loss_test 0.02775	Acc_test 63.10
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models
Epoch: [20/50]	lr: 2.50e-04	time: 00:01:00	Loss_train 0.06933	Acc_train 88.87	/	Loss_test 0.01917	Acc_test 71.30
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models
Epoch: [30/50]	lr: 1.25e-04	time: 00:01:02	Loss_train 0.03255	Acc_train 93.29	/	Loss_test 0.01843	Acc_test 70.80
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models
Epoch: [40/50]	lr: 3.13e-05	time: 00:01:04	Loss_train 0.02156	Acc_train 94.92	/	Loss_test 0.01778	Acc_test 71.70
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models
Epoch: [50/50]	lr: 7.81e-06	time: 00:01:06	Loss_train 0.01882	Acc_train 95.42	/	Loss_test 0.01747	Acc_test 71.90
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models
RESULT:  {'train_loss': 0.018824245780706406, 'train_acc': 95.41599750518799, 'test_loss': 0.017468981444835663, 'test_acc': 71.9000015258789, 'convergence': 21.598419189453125, 'R1': 0, 'dataset_sup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 10, 'selected_classes': [2, 17, 25, 32, 63, 66, 71, 77, 80, 98]}, 'dataset_unsup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 50, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 10, 'selected_classes': [2, 17, 25, 32, 63, 66, 71, 77, 80, 98]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}
IN R1:  {'R1': {'train_loss': 0.018824245780706406, 'train_acc': 95.41599750518799, 'test_loss': 0.017468981444835663, 'test_acc': 71.9000015258789, 'convergence': 21.598419189453125, 'R1': 0, 'dataset_sup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 10, 'selected_classes': [2, 17, 25, 32, 63, 66, 71, 77, 80, 98]}, 'dataset_unsup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 50, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 10, 'selected_classes': [2, 17, 25, 32, 63, 66, 71, 77, 80, 98]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.11048543456039805, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10, 'in_channels': 24576, 'old_channels': 1536, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 Model C100_10C_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=10, bias=True)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 0, 53, 21, 58, 58,  6, 82, 82,  6, 21, 21,  0, 21, 58, 58, 58, 58,  6,
         6, 44])
[0, 6, 21, 31, 44, 53, 58, 79, 82, 88]
TARGETS AFTER CLEANER:  tensor([0, 5, 2, 6, 6, 1, 8, 8, 1, 2, 2, 0, 2, 6, 6, 6, 6, 1, 1, 4])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 0, 31, 82, 21,  6, 53, 53, 88, 53, 53, 79, 82, 21,  0, 44, 31, 79, 79,
        21, 79])
[0, 6, 21, 31, 44, 53, 58, 79, 82, 88]
TARGETS AFTER CLEANER:  tensor([0, 3, 8, 2, 1, 5, 5, 9, 5, 5, 7, 8, 2, 0, 4, 3, 7, 7, 2, 7])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 0, 31, 82, 21,  6, 53, 53, 88, 53, 53, 79, 82, 21,  0, 44, 31, 79, 79,
        21, 79])
[0, 6, 21, 31, 44, 53, 58, 79, 82, 88]
TARGETS AFTER CLEANER:  tensor([0, 3, 8, 2, 1, 5, 5, 9, 5, 5, 7, 8, 2, 0, 4, 3, 7, 7, 2, 7])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  5000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_10C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.38e-01	time: 00:00:11	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.666e-02/SW:5.198e-01/MR:4.252e+00/SR:1.492e+00/MeD:1.211e+00/MaD:3.252e+00/MW:0.569/MAW:0.431
|       0 |       1 |       2 |       3 |       4 |       5 |       6 |       7 |       8 |       9 |         10 |      11 |      12 |      13 |      14 |      15 |         16 |      17 |      18 |      19 |      20 |      21 |      22 |      23 |      24 |         25 |      26 |     27 |      28 |      29 |
|---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+------------+---------+---------+---------+---------+---------+------------+---------+---------+---------+---------+---------+---------+---------+---------+------------+---------+--------+---------+---------|
|   0.133 |   0.138 |   0.167 |   0.183 |   0.116 |   0.113 |   0.132 |   0.183 |   0.127 |   0.188 |   0.000704 |   0.128 |   0.168 |   0.139 |   0.141 |   0.189 |   0.000226 |   0.156 |   0.157 |   0.174 |   0.156 |   0.148 |   0.134 |   0.189 |   0.171 |   0.000263 |   0.169 |   0.12 |   0.112 |   0.168 |
|   3.74  |   3.99  |   5.38  |   6.22  |   3.12  |   2.98  |   3.72  |   6.25  |   3.5   |   6.53  |   1        |   3.58  |   5.42  |   4     |   4.1   |   6.59  |   1        |   4.78  |   4.86  |   5.7   |   4.78  |   4.4   |   3.81  |   6.57  |   5.57  |   1        |   5.48  |   3.25 |   2.95  |   5.43  |
|   0.57  |   0.62  |   0.58  |   0.69  |   0.53  |   0.52  |   0.52  |   0.51  |   0.57  |   0.59  |   4.55     |   0.52  |   0.6   |   0.52  |   0.46  |   0.6   |  14.21     |   0.57  |   0.56  |   0.51  |   0.44  |   0.48  |   0.61  |   0.56  |   0.55  |  22.2      |   0.5   |   1.22 |   0.55  |   0.48  |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan    | nan     | nan     |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan    | nan     | nan     |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan    | nan     | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 0, 53, 21, 58, 58,  6, 82, 82,  6, 21, 21,  0, 21, 58, 58, 58, 58,  6,
         6, 44])
[0, 6, 21, 31, 44, 53, 58, 79, 82, 88]
TARGETS AFTER CLEANER:  tensor([0, 5, 2, 6, 6, 1, 8, 8, 1, 2, 2, 0, 2, 6, 6, 6, 6, 1, 1, 4])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 0, 31, 82, 21,  6, 53, 53, 88, 53, 53, 79, 82, 21,  0, 44, 31, 79, 79,
        21, 79])
[0, 6, 21, 31, 44, 53, 58, 79, 82, 88]
TARGETS AFTER CLEANER:  tensor([0, 3, 8, 2, 1, 5, 5, 9, 5, 5, 7, 8, 2, 0, 4, 3, 7, 7, 2, 7])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 0, 31, 82, 21,  6, 53, 53, 88, 53, 53, 79, 82, 21,  0, 44, 31, 79, 79,
        21, 79])
[0, 6, 21, 31, 44, 53, 58, 79, 82, 88]
TARGETS AFTER CLEANER:  tensor([0, 3, 8, 2, 1, 5, 5, 9, 5, 5, 7, 8, 2, 0, 4, 3, 7, 7, 2, 7])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  5000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_10C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.38e-01	time: 00:00:26	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.049e-03/SW:3.084e-01/MR:8.936e+00/SR:1.528e+00/MeD:1.170e+00/MaD:6.994e+00/MW:0.565/MAW:0.435
|        0 |        1 |        2 |        3 |        4 |        5 |        6 |        7 |        8 |        9 |       10 |       11 |       12 |       13 |       14 |       15 |       16 |       17 |       18 |       19 |       20 |       21 |       22 |       23 |       24 |       25 |       26 |       27 |       28 |       29 |
|----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------|
|   0.0152 |   0.0131 |   0.0143 |   0.0128 |   0.0121 |   0.0137 |   0.0146 |   0.0122 |   0.0141 |   0.0142 |   0.0135 |   0.0152 |   0.0137 |   0.0157 |   0.0165 |   0.0138 |   0.0147 |   0.0143 |   0.0115 |   0.0128 |   0.0152 |   0.0159 |   0.0129 |   0.0149 |   0.0111 |   0.0141 |   0.0138 |   0.0121 |   0.0137 |   0.0145 |
|  10.21   |   7.84   |   9.13   |   7.54   |   6.85   |   8.54   |   9.56   |   7      |   8.97   |   9.03   |   8.29   |  10.18   |   8.53   |  10.9    |  11.89   |   8.65   |   9.69   |   9.16   |   6.31   |   7.58   |  10.25   |  11.17   |   7.64   |   9.91   |   5.97   |   8.9    |   8.63   |   6.82   |   8.47   |   9.38   |
|   0.2    |   0.15   |   0.23   |   0.25   |   0.63   |   0.2    |   0.26   |   0.3    |   0.17   |   0.19   |   0.25   |   0.29   |   0.34   |   0.15   |   0.17   |   0.24   |   0.26   |   0.2    |   0.24   |   0.24   |   0.19   |   0.35   |   0.55   |   0.22   |   0.99   |   0.72   |   0.22   |   0.29   |   0.18   |   0.37   |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 0, 53, 21, 58, 58,  6, 82, 82,  6, 21, 21,  0, 21, 58, 58, 58, 58,  6,
         6, 44])
[0, 6, 21, 31, 44, 53, 58, 79, 82, 88]
TARGETS AFTER CLEANER:  tensor([0, 5, 2, 6, 6, 1, 8, 8, 1, 2, 2, 0, 2, 6, 6, 6, 6, 1, 1, 4])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 0, 31, 82, 21,  6, 53, 53, 88, 53, 53, 79, 82, 21,  0, 44, 31, 79, 79,
        21, 79])
[0, 6, 21, 31, 44, 53, 58, 79, 82, 88]
TARGETS AFTER CLEANER:  tensor([0, 3, 8, 2, 1, 5, 5, 9, 5, 5, 7, 8, 2, 0, 4, 3, 7, 7, 2, 7])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 0, 31, 82, 21,  6, 53, 53, 88, 53, 53, 79, 82, 21,  0, 44, 31, 79, 79,
        21, 79])
[0, 6, 21, 31, 44, 53, 58, 79, 82, 88]
TARGETS AFTER CLEANER:  tensor([0, 3, 8, 2, 1, 5, 5, 9, 5, 5, 7, 8, 2, 0, 4, 3, 7, 7, 2, 7])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  5000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_10C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.49e-02	time: 00:00:38	Acc_train 0.00	Acc_test 0.00	convergence: 2.02e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.067e-03/SW:3.642e-01/MR:2.122e+01/SR:2.815e+00/MeD:2.241e+00/MaD:1.575e+01/MW:0.447/MAW:0.553
|        0 |        1 |        2 |        3 |        4 |        5 |        6 |       7 |        8 |        9 |       10 |       11 |       12 |      13 |       14 |      15 |       16 |       17 |       18 |       19 |       20 |       21 |       22 |       23 |       24 |       25 |       26 |       27 |       28 |       29 |
|----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+---------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------|
|   0.0466 |   0.0437 |   0.0458 |   0.0484 |   0.0463 |   0.0454 |   0.0498 |   0.039 |   0.0428 |   0.0485 |   0.0434 |   0.0456 |   0.0442 |   0.038 |   0.0431 |   0.044 |   0.0479 |   0.0511 |   0.0422 |   0.0446 |   0.0474 |   0.0448 |   0.0212 |   0.0442 |   0.0453 |   0.0389 |   0.0457 |   0.0455 |   0.0416 |   0.0435 |
|  22.7    |  20.06   |  21.95   |  24.44   |  22.39   |  21.64   |  25.83   |  16.19  |  19.31   |  24.49   |  19.86   |  21.82   |  20.56   |  15.45  |  19.58   |  20.36  |  23.98   |  27.12   |  18.77   |  20.91   |  23.44   |  21.11   |   5.47   |  20.57   |  21.48   |  16.12   |  21.89   |  21.75   |  18.31   |  19.89   |
|   0.04   |   0.05   |   0.08   |   0.03   |   0.04   |   0.05   |   0.08   |   0.04  |   0.13   |   0.06   |   0.08   |   0.06   |   0.19   |   0.08  |   0.21   |   0.02  |   0.03   |   0.09   |   0.09   |   0.04   |   0.03   |   0.05   |   0.46   |   0.05   |   0.06   |   0.05   |   0.02   |   0.04   |   0.03   |   0.02   |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models

 ********** Supervised learning of blocks [3] **********
SAVING FOLDER FOR SUP:  C100_10C_CL
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 0, 53, 21, 58, 58,  6, 82, 82,  6, 21, 21,  0, 21, 58, 58, 58, 58,  6,
         6, 44])
[0, 6, 21, 31, 44, 53, 58, 79, 82, 88]
TARGETS AFTER CLEANER:  tensor([0, 5, 2, 6, 6, 1, 8, 8, 1, 2, 2, 0, 2, 6, 6, 6, 6, 1, 1, 4])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 0, 31, 82, 21,  6, 53, 53, 88, 53, 53, 79, 82, 21,  0, 44, 31, 79, 79,
        21, 79])
[0, 6, 21, 31, 44, 53, 58, 79, 82, 88]
TARGETS AFTER CLEANER:  tensor([0, 3, 8, 2, 1, 5, 5, 9, 5, 5, 7, 8, 2, 0, 4, 3, 7, 7, 2, 7])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 0, 31, 82, 21,  6, 53, 53, 88, 53, 53, 79, 82, 21,  0, 44, 31, 79, 79,
        21, 79])
[0, 6, 21, 31, 44, 53, 58, 79, 82, 88]
TARGETS AFTER CLEANER:  tensor([0, 3, 8, 2, 1, 5, 5, 9, 5, 5, 7, 8, 2, 0, 4, 3, 7, 7, 2, 7])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  5000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Epoch: [1/50]	lr: 1.00e-03	time: 00:00:49	Loss_train 0.90182	Acc_train 51.10	/	Loss_test 0.02736	Acc_test 65.50
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models
Epoch: [10/50]	lr: 1.00e-03	time: 00:00:51	Loss_train 0.21236	Acc_train 81.09	/	Loss_test 0.01794	Acc_test 79.30
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models
Epoch: [20/50]	lr: 2.50e-04	time: 00:00:53	Loss_train 0.04599	Acc_train 93.54	/	Loss_test 0.01479	Acc_test 81.00
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models
Epoch: [30/50]	lr: 1.25e-04	time: 00:00:56	Loss_train 0.02372	Acc_train 95.84	/	Loss_test 0.01424	Acc_test 81.70
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models
Epoch: [40/50]	lr: 3.13e-05	time: 00:00:58	Loss_train 0.01547	Acc_train 96.95	/	Loss_test 0.01350	Acc_test 81.40
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models
Epoch: [50/50]	lr: 7.81e-06	time: 00:01:00	Loss_train 0.01372	Acc_train 97.27	/	Loss_test 0.01337	Acc_test 81.90
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models
RESULT:  {'train_loss': 0.013717176392674446, 'train_acc': 97.26799726486206, 'test_loss': 0.013367867097258568, 'test_acc': 81.9000015258789, 'convergence': 20.223682403564453, 'R1': 0, 'dataset_sup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 10, 'selected_classes': [0, 6, 21, 31, 44, 53, 58, 79, 82, 88]}, 'dataset_unsup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 50, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 10, 'selected_classes': [0, 6, 21, 31, 44, 53, 58, 79, 82, 88]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}
IN R2:  {'R1': {'train_loss': 0.018824245780706406, 'train_acc': 95.41599750518799, 'test_loss': 0.017468981444835663, 'test_acc': 71.9000015258789, 'convergence': 21.598419189453125, 'R1': 0, 'dataset_sup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 10, 'selected_classes': [2, 17, 25, 32, 63, 66, 71, 77, 80, 98]}, 'dataset_unsup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 50, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 10, 'selected_classes': [2, 17, 25, 32, 63, 66, 71, 77, 80, 98]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}, 'R2': {'train_loss': 0.013717176392674446, 'train_acc': 97.26799726486206, 'test_loss': 0.013367867097258568, 'test_acc': 81.9000015258789, 'convergence': 20.223682403564453, 'R1': 0, 'dataset_sup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 10, 'selected_classes': [0, 6, 21, 31, 44, 53, 58, 79, 82, 88]}, 'dataset_unsup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 50, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 10, 'selected_classes': [0, 6, 21, 31, 44, 53, 58, 79, 82, 88]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.11048543456039805, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10, 'in_channels': 24576, 'old_channels': 1536, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 Model C100_10C_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=10, bias=True)
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([71, 71, 25, 63, 17,  2, 32, 71, 77, 63, 66, 32, 32, 77, 71, 17, 25, 71,
        25, 77])
[2, 17, 25, 32, 63, 66, 71, 77, 80, 98]
TARGETS AFTER CLEANER:  tensor([6, 6, 2, 4, 1, 0, 3, 6, 7, 4, 5, 3, 3, 7, 6, 1, 2, 6, 2, 7])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([17, 71, 80, 71, 17, 71, 98, 66, 77, 32, 66, 63, 63, 32, 32, 66, 98, 80,
         2, 63])
[2, 17, 25, 32, 63, 66, 71, 77, 80, 98]
TARGETS AFTER CLEANER:  tensor([1, 6, 8, 6, 1, 6, 9, 5, 7, 3, 5, 4, 4, 3, 3, 5, 9, 8, 0, 4])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([17, 71, 80, 71, 17, 71, 98, 66, 77, 32, 66, 63, 63, 32, 32, 66, 98, 80,
         2, 63])
[2, 17, 25, 32, 63, 66, 71, 77, 80, 98]
TARGETS AFTER CLEANER:  tensor([1, 6, 8, 6, 1, 6, 9, 5, 7, 3, 5, 4, 4, 3, 3, 5, 9, 8, 0, 4])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  5000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Accuracy of the network on the 1st dataset: 13.800 %
Test loss on the 1st dataset: 0.198

