BLOCKS:  {'b0': {'arch': 'CNN', 'preset': 'softkrotov-c96-k5-p2-s1-d1-b0-t1-lr0.08-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 0, 'batch_norm': False, 'pool': {'type': 'max', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 0.7}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5}}, 'b1': {'arch': 'CNN', 'preset': 'softkrotov-c384-k3-p1-s1-d1-b0-t0.65-lr0.005-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 1, 'batch_norm': False, 'pool': {'type': 'max', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 1.4}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3}}, 'b2': {'arch': 'CNN', 'preset': 'softkrotov-c1536-k3-p1-s1-d1-b0-t0.25-lr0.01-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 2, 'batch_norm': False, 'pool': {'type': 'avg', 'kernel_size': 2, 'stride': 2, 'padding': 0}, 'activation': {'function': 'triangle', 'param': 1.0}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3}}, 'b3': {'arch': 'MLP', 'preset': 'BP-c10', 'operation': 'flatten', 'num': 3, 'att_dropout': None, 'dropout': 0.5, 'layer': {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.25, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10}, 'pool': None, 'activation': None}}
CL:  True
{'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 100, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True}
CL:  True
{'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 100, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 50, 'validation': False, 'continual_learning': True}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.11048543456039805, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10, 'in_channels': 24576, 'old_channels': 1536, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=10, bias=True)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([51, 92, 75, 81, 92, 75, 41, 25, 41, 75, 77, 65, 92, 77, 75, 25, 92, 25,
        51, 77])
[25, 28, 41, 51, 55, 65, 75, 77, 81, 92]
TARGETS AFTER CLEANER:  tensor([3, 9, 6, 8, 9, 6, 2, 0, 2, 6, 7, 5, 9, 7, 6, 0, 9, 0, 3, 7])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([28, 65, 81, 55, 51, 92, 75, 77, 75, 55, 51, 28, 28, 65, 81, 81, 65, 41,
        77, 28])
[25, 28, 41, 51, 55, 65, 75, 77, 81, 92]
TARGETS AFTER CLEANER:  tensor([1, 5, 8, 4, 3, 9, 6, 7, 6, 4, 3, 1, 1, 5, 8, 8, 5, 2, 7, 1])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([28, 65, 81, 55, 51, 92, 75, 77, 75, 55, 51, 28, 28, 65, 81, 81, 65, 41,
        77, 28])
[25, 28, 41, 51, 55, 65, 75, 77, 81, 92]
TARGETS AFTER CLEANER:  tensor([1, 5, 8, 4, 3, 9, 6, 7, 6, 4, 3, 1, 1, 5, 8, 8, 5, 2, 7, 1])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  5000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_10C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.59e-01	time: 00:00:34	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:2.041e-02/SW:6.312e-01/MR:5.209e+00/SR:1.674e+00/MeD:1.383e+00/MaD:4.209e+00/MW:0.571/MAW:0.429
|       0 |       1 |       2 |       3 |       4 |       5 |      6 |       7 |      8 |       9 |      10 |      11 |      12 |      13 |      14 |     15 |         16 |      17 |      18 |      19 |     20 |      21 |      22 |      23 |      24 |         25 |      26 |      27 |      28 |     29 |
|---------+---------+---------+---------+---------+---------+--------+---------+--------+---------+---------+---------+---------+---------+---------+--------+------------+---------+---------+---------+--------+---------+---------+---------+---------+------------+---------+---------+---------+--------|
|   0.155 |   0.203 |   0.176 |   0.183 |   0.136 |   0.145 |   0.17 |   0.204 |   0.15 |   0.216 |   0.102 |   0.138 |   0.174 |   0.142 |   0.167 |   0.2  |   0.000242 |   0.145 |   0.175 |   0.187 |   0.18 |   0.177 |   0.165 |   0.207 |   0.185 |   0.000258 |   0.182 |   0.141 |   0.139 |   0.21 |
|   4.76  |   7.47  |   5.82  |   6.23  |   3.88  |   4.31  |   5.5  |   7.49  |   4.5  |   8.26  |   2.63  |   3.97  |   5.71  |   4.15  |   5.35  |   7.24 |   1        |   4.29  |   5.79  |   6.47  |   6.08 |   5.87  |   5.28  |   7.66  |   6.33  |   1        |   6.16  |   4.09  |   4.01  |   7.92 |
|   0.66  |   0.48  |   0.41  |   0.53  |   0.95  |   1.77  |   0.7  |   0.57  |   0.94 |   0.4   |   0.96  |   0.61  |   0.61  |   0.45  |   1.11  |   0.45 |   8.17     |   0.57  |   0.62  |   0.89  |   0.67 |   0.91  |   0.54  |   0.53  |   0.54  |  10.72     |   0.51  |   0.74  |   0.53  |   0.48 |
| nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan        | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan    |
| nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan        | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan    |
| nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan        | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan    |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([51, 92, 75, 81, 92, 75, 41, 25, 41, 75, 77, 65, 92, 77, 75, 25, 92, 25,
        51, 77])
[25, 28, 41, 51, 55, 65, 75, 77, 81, 92]
TARGETS AFTER CLEANER:  tensor([3, 9, 6, 8, 9, 6, 2, 0, 2, 6, 7, 5, 9, 7, 6, 0, 9, 0, 3, 7])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([28, 65, 81, 55, 51, 92, 75, 77, 75, 55, 51, 28, 28, 65, 81, 81, 65, 41,
        77, 28])
[25, 28, 41, 51, 55, 65, 75, 77, 81, 92]
TARGETS AFTER CLEANER:  tensor([1, 5, 8, 4, 3, 9, 6, 7, 6, 4, 3, 1, 1, 5, 8, 8, 5, 2, 7, 1])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([28, 65, 81, 55, 51, 92, 75, 77, 75, 55, 51, 28, 28, 65, 81, 81, 65, 41,
        77, 28])
[25, 28, 41, 51, 55, 65, 75, 77, 81, 92]
TARGETS AFTER CLEANER:  tensor([1, 5, 8, 4, 3, 9, 6, 7, 6, 4, 3, 1, 1, 5, 8, 8, 5, 2, 7, 1])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  5000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_10C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.59e-01	time: 00:00:51	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:-1.595e-03/SW:5.274e-01/MR:1.531e+01/SR:2.422e+00/MeD:1.971e+00/MaD:7.162e+00/MW:0.688/MAW:0.312
|        0 |        1 |        2 |      3 |        4 |        5 |        6 |        7 |        8 |        9 |       10 |       11 |       12 |       13 |      14 |       15 |       16 |       17 |       18 |       19 |       20 |      21 |       22 |       23 |      24 |       25 |       26 |       27 |       28 |       29 |
|----------+----------+----------+--------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+---------+----------+----------+---------+----------+----------+----------+----------+----------|
|   0.0184 |   0.0186 |   0.0197 |   0.02 |   0.0153 |   0.0178 |   0.0197 |   0.0188 |   0.0184 |   0.0181 |   0.0185 |   0.0199 |   0.0191 |   0.0207 |   0.021 |   0.0192 |   0.0187 |   0.0172 |   0.0158 |   0.0174 |   0.0197 |   0.019 |   0.0181 |   0.0161 |   0.016 |   0.0188 |   0.0201 |   0.0174 |   0.0178 |   0.0193 |
|  14.48   |  14.8    |  16.55   |  17.03 |  10.37   |  13.62   |  16.45   |  15.13   |  14.51   |  14.13   |  14.69   |  16.81   |  15.6    |  18.17   |  18.7   |  15.72   |  15.04   |  12.88   |  10.96   |  13.04   |  16.51   |  15.5   |  14.05   |  11.33   |  11.19  |  15.18   |  17.1    |  13.07   |  13.66   |  15.84   |
|   0.36   |   0.25   |   0.2    |   0.17 |   0.88   |   0.26   |   0.22   |   0.19   |   0.21   |   0.27   |   0.22   |   0.24   |   0.33   |   0.16   |   0.14  |   0.21   |   0.2    |   0.39   |   0.38   |   0.27   |   0.15   |   0.4   |   0.44   |   0.48   |   0.8   |   0.42   |   0.15   |   0.23   |   0.26   |   0.2    |
| nan      | nan      | nan      | nan    | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan    | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan    | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([51, 92, 75, 81, 92, 75, 41, 25, 41, 75, 77, 65, 92, 77, 75, 25, 92, 25,
        51, 77])
[25, 28, 41, 51, 55, 65, 75, 77, 81, 92]
TARGETS AFTER CLEANER:  tensor([3, 9, 6, 8, 9, 6, 2, 0, 2, 6, 7, 5, 9, 7, 6, 0, 9, 0, 3, 7])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([28, 65, 81, 55, 51, 92, 75, 77, 75, 55, 51, 28, 28, 65, 81, 81, 65, 41,
        77, 28])
[25, 28, 41, 51, 55, 65, 75, 77, 81, 92]
TARGETS AFTER CLEANER:  tensor([1, 5, 8, 4, 3, 9, 6, 7, 6, 4, 3, 1, 1, 5, 8, 8, 5, 2, 7, 1])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([28, 65, 81, 55, 51, 92, 75, 77, 75, 55, 51, 28, 28, 65, 81, 81, 65, 41,
        77, 28])
[25, 28, 41, 51, 55, 65, 75, 77, 81, 92]
TARGETS AFTER CLEANER:  tensor([1, 5, 8, 4, 3, 9, 6, 7, 6, 4, 3, 1, 1, 5, 8, 8, 5, 2, 7, 1])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  5000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_10C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.62e-02	time: 00:01:08	Acc_train 0.00	Acc_test 0.00	convergence: 2.15e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:4.544e-04/SW:3.849e-01/MR:2.246e+01/SR:2.740e+00/MeD:2.203e+00/MaD:9.249e+00/MW:0.454/MAW:0.546
|        0 |        1 |        2 |        3 |        4 |        5 |      6 |        7 |      8 |        9 |       10 |       11 |       12 |       13 |       14 |      15 |       16 |       17 |       18 |       19 |       20 |       21 |       22 |       23 |       24 |       25 |       26 |       27 |       28 |       29 |
|----------+----------+----------+----------+----------+----------+--------+----------+--------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------|
|   0.0486 |   0.0468 |   0.0474 |   0.0493 |   0.0464 |   0.0453 |   0.05 |   0.0414 |   0.05 |   0.0497 |   0.0441 |   0.0473 |   0.0464 |   0.0382 |   0.0469 |   0.046 |   0.0468 |   0.0509 |   0.0442 |   0.0472 |   0.0463 |   0.0466 |   0.0385 |   0.0476 |   0.0469 |   0.0407 |   0.0449 |   0.0461 |   0.0438 |   0.0454 |
|  24.67   |  22.91   |  23.5    |  25.3    |  22.56   |  21.49   |  26.04 |  18.11   |  25.99 |  25.73   |  20.44   |  23.34   |  22.53   |  15.62   |  22.95   |  22.18  |  22.91   |  26.89   |  20.49   |  23.23   |  22.45   |  22.76   |  15.79   |  23.64   |  22.95   |  17.57   |  21.13   |  22.23   |  20.23   |  21.57   |
|   0.04   |   0.03   |   0.06   |   0.02   |   0.03   |   0.06   |   0.03 |   0.06   |   0.03 |   0.01   |   0.07   |   0.08   |   0.18   |   0.11   |   0.17   |   0.05  |   0.05   |   0.04   |   0.09   |   0.03   |   0.09   |   0.06   |   0.35   |   0.02   |   0.04   |   0.08   |   0.07   |   0.07   |   0.06   |   0.06   |
| nan      | nan      | nan      | nan      | nan      | nan      | nan    | nan      | nan    | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan    | nan      | nan    | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan    | nan      | nan    | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models

 ********** Supervised learning of blocks [3] **********
SAVING FOLDER FOR SUP:  C100_10C_CL
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([51, 92, 75, 81, 92, 75, 41, 25, 41, 75, 77, 65, 92, 77, 75, 25, 92, 25,
        51, 77])
[25, 28, 41, 51, 55, 65, 75, 77, 81, 92]
TARGETS AFTER CLEANER:  tensor([3, 9, 6, 8, 9, 6, 2, 0, 2, 6, 7, 5, 9, 7, 6, 0, 9, 0, 3, 7])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([28, 65, 81, 55, 51, 92, 75, 77, 75, 55, 51, 28, 28, 65, 81, 81, 65, 41,
        77, 28])
[25, 28, 41, 51, 55, 65, 75, 77, 81, 92]
TARGETS AFTER CLEANER:  tensor([1, 5, 8, 4, 3, 9, 6, 7, 6, 4, 3, 1, 1, 5, 8, 8, 5, 2, 7, 1])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([28, 65, 81, 55, 51, 92, 75, 77, 75, 55, 51, 28, 28, 65, 81, 81, 65, 41,
        77, 28])
[25, 28, 41, 51, 55, 65, 75, 77, 81, 92]
TARGETS AFTER CLEANER:  tensor([1, 5, 8, 4, 3, 9, 6, 7, 6, 4, 3, 1, 1, 5, 8, 8, 5, 2, 7, 1])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  5000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Epoch: [1/50]	lr: 1.00e-03	time: 00:01:25	Loss_train 0.82310	Acc_train 45.94	/	Loss_test 0.02229	Acc_test 60.70
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models
Epoch: [10/50]	lr: 1.00e-03	time: 00:01:28	Loss_train 0.18548	Acc_train 75.77	/	Loss_test 0.02778	Acc_test 67.40
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models
Epoch: [20/50]	lr: 2.50e-04	time: 00:01:32	Loss_train 0.05251	Acc_train 90.78	/	Loss_test 0.01694	Acc_test 75.10
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models
Epoch: [30/50]	lr: 1.25e-04	time: 00:01:35	Loss_train 0.02424	Acc_train 94.66	/	Loss_test 0.01617	Acc_test 76.50
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models
Epoch: [40/50]	lr: 3.13e-05	time: 00:01:39	Loss_train 0.01504	Acc_train 96.14	/	Loss_test 0.01475	Acc_test 76.70
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models
Epoch: [50/50]	lr: 7.81e-06	time: 00:01:42	Loss_train 0.01312	Acc_train 96.58	/	Loss_test 0.01464	Acc_test 77.90
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models
RESULT:  {'train_loss': 0.013124372810125351, 'train_acc': 96.57599925994873, 'test_loss': 0.014639913104474545, 'test_acc': 77.9000015258789, 'convergence': 21.46358871459961, 'R1': 0, 'dataset_sup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 10, 'selected_classes': [25, 28, 41, 51, 55, 65, 75, 77, 81, 92]}, 'dataset_unsup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 50, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 10, 'selected_classes': [25, 28, 41, 51, 55, 65, 75, 77, 81, 92]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}
IN R1:  {'R1': {'train_loss': 0.013124372810125351, 'train_acc': 96.57599925994873, 'test_loss': 0.014639913104474545, 'test_acc': 77.9000015258789, 'convergence': 21.46358871459961, 'R1': 0, 'dataset_sup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 10, 'selected_classes': [25, 28, 41, 51, 55, 65, 75, 77, 81, 92]}, 'dataset_unsup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 50, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 10, 'selected_classes': [25, 28, 41, 51, 55, 65, 75, 77, 81, 92]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.11048543456039805, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10, 'in_channels': 24576, 'old_channels': 1536, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 Model C100_10C_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=10, bias=True)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([39,  4, 32, 27, 32, 32, 54, 27, 27, 46,  4, 39,  4, 54,  4, 32, 39, 80,
        12, 80])
[4, 5, 12, 27, 32, 39, 46, 54, 79, 80]
TARGETS AFTER CLEANER:  tensor([5, 0, 4, 3, 4, 4, 7, 3, 3, 6, 0, 5, 0, 7, 0, 4, 5, 9, 2, 9])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([39, 39, 80, 27, 46, 39, 46, 39,  4,  4, 32, 46,  4, 27, 39, 79, 32, 46,
        32, 39])
[4, 5, 12, 27, 32, 39, 46, 54, 79, 80]
TARGETS AFTER CLEANER:  tensor([5, 5, 9, 3, 6, 5, 6, 5, 0, 0, 4, 6, 0, 3, 5, 8, 4, 6, 4, 5])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([39, 39, 80, 27, 46, 39, 46, 39,  4,  4, 32, 46,  4, 27, 39, 79, 32, 46,
        32, 39])
[4, 5, 12, 27, 32, 39, 46, 54, 79, 80]
TARGETS AFTER CLEANER:  tensor([5, 5, 9, 3, 6, 5, 6, 5, 0, 0, 4, 6, 0, 3, 5, 8, 4, 6, 4, 5])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  5000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_10C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.55e-01	time: 00:00:16	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:8.620e-03/SW:6.379e-01/MR:5.129e+00/SR:2.064e+00/MeD:1.667e+00/MaD:6.713e+00/MW:0.584/MAW:0.416
|      0 |       1 |       2 |       3 |       4 |       5 |       6 |       7 |       8 |       9 |        10 |      11 |      12 |      13 |      14 |      15 |         16 |      17 |     18 |      19 |      20 |      21 |      22 |      23 |      24 |         25 |      26 |     27 |      28 |      29 |
|--------+---------+---------+---------+---------+---------+---------+---------+---------+---------+-----------+---------+---------+---------+---------+---------+------------+---------+--------+---------+---------+---------+---------+---------+---------+------------+---------+--------+---------+---------|
|   0.13 |   0.159 |   0.152 |   0.181 |   0.116 |   0.124 |   0.181 |   0.184 |   0.132 |   0.218 |   0.00555 |   0.143 |   0.196 |   0.145 |   0.157 |   0.198 |   6.18e-05 |   0.158 |   0.17 |   0.187 |   0.201 |   0.188 |   0.143 |   0.204 |   0.181 |   8.74e-05 |   0.211 |   0.15 |   0.116 |   0.202 |
|   3.63 |   4.94  |   4.59  |   6.11  |   3.11  |   3.42  |   6.14  |   6.28  |   3.71  |   8.46  |   1       |   4.22  |   7     |   4.27  |   4.84  |   7.14  |   1        |   4.9   |   5.51 |   6.45  |   7.32  |   6.54  |   4.19  |   7.51  |   6.1   |   1        |   7.97  |   4.5  |   3.1   |   7.38  |
|   0.55 |   0.56  |   0.55  |   0.73  |   0.53  |   0.56  |   0.55  |   0.48  |   0.58  |   0.63  |   1.67    |   0.52  |   0.64  |   0.48  |   0.48  |   0.53  |  17.82     |   0.59  |   0.61 |   0.54  |   0.59  |   0.64  |   0.64  |   0.59  |   0.55  |  23.69     |   0.55  |   0.86 |   0.55  |   0.67  |
| nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan       | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan    | nan     | nan     |
| nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan       | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan    | nan     | nan     |
| nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan       | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan    | nan     | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([39,  4, 32, 27, 32, 32, 54, 27, 27, 46,  4, 39,  4, 54,  4, 32, 39, 80,
        12, 80])
[4, 5, 12, 27, 32, 39, 46, 54, 79, 80]
TARGETS AFTER CLEANER:  tensor([5, 0, 4, 3, 4, 4, 7, 3, 3, 6, 0, 5, 0, 7, 0, 4, 5, 9, 2, 9])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([39, 39, 80, 27, 46, 39, 46, 39,  4,  4, 32, 46,  4, 27, 39, 79, 32, 46,
        32, 39])
[4, 5, 12, 27, 32, 39, 46, 54, 79, 80]
TARGETS AFTER CLEANER:  tensor([5, 5, 9, 3, 6, 5, 6, 5, 0, 0, 4, 6, 0, 3, 5, 8, 4, 6, 4, 5])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([39, 39, 80, 27, 46, 39, 46, 39,  4,  4, 32, 46,  4, 27, 39, 79, 32, 46,
        32, 39])
[4, 5, 12, 27, 32, 39, 46, 54, 79, 80]
TARGETS AFTER CLEANER:  tensor([5, 5, 9, 3, 6, 5, 6, 5, 0, 0, 4, 6, 0, 3, 5, 8, 4, 6, 4, 5])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  5000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_10C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.55e-01	time: 00:00:33	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.150e-03/SW:3.178e-01/MR:9.209e+00/SR:1.574e+00/MeD:1.230e+00/MaD:6.694e+00/MW:0.553/MAW:0.447
|        0 |        1 |        2 |        3 |        4 |        5 |        6 |        7 |        8 |        9 |       10 |       11 |       12 |       13 |      14 |       15 |       16 |       17 |       18 |       19 |       20 |       21 |       22 |      23 |       24 |       25 |      26 |       27 |       28 |       29 |
|----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+---------+----------+----------+----------|
|   0.0154 |   0.0135 |   0.0147 |   0.0141 |   0.0117 |   0.0131 |   0.0151 |   0.0124 |   0.0144 |   0.0146 |   0.0139 |   0.0156 |   0.0132 |   0.0156 |   0.016 |   0.0142 |   0.0162 |   0.0144 |   0.0113 |   0.0127 |   0.0151 |   0.0154 |   0.0137 |   0.014 |   0.0132 |   0.0144 |   0.014 |   0.0123 |   0.0136 |   0.0141 |
|  10.45   |   8.3    |   9.6    |   8.98   |   6.49   |   7.91   |  10.09   |   7.18   |   9.26   |   9.49   |   8.76   |  10.68   |   7.98   |  10.8    |  11.23  |   9.02   |  11.49   |   9.28   |   6.15   |   7.44   |  10.11   |  10.48   |   8.47   |   8.81  |   7.92   |   9.26   |   8.83  |   7.09   |   8.44   |   9      |
|   0.17   |   0.17   |   0.25   |   0.26   |   0.71   |   0.2    |   0.26   |   0.25   |   0.19   |   0.16   |   0.21   |   0.35   |   0.35   |   0.26   |   0.24  |   0.24   |   0.11   |   0.23   |   0.24   |   0.21   |   0.19   |   0.38   |   0.57   |   0.21  |   0.67   |   0.65   |   0.27  |   0.23   |   0.19   |   0.28   |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([39,  4, 32, 27, 32, 32, 54, 27, 27, 46,  4, 39,  4, 54,  4, 32, 39, 80,
        12, 80])
[4, 5, 12, 27, 32, 39, 46, 54, 79, 80]
TARGETS AFTER CLEANER:  tensor([5, 0, 4, 3, 4, 4, 7, 3, 3, 6, 0, 5, 0, 7, 0, 4, 5, 9, 2, 9])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([39, 39, 80, 27, 46, 39, 46, 39,  4,  4, 32, 46,  4, 27, 39, 79, 32, 46,
        32, 39])
[4, 5, 12, 27, 32, 39, 46, 54, 79, 80]
TARGETS AFTER CLEANER:  tensor([5, 5, 9, 3, 6, 5, 6, 5, 0, 0, 4, 6, 0, 3, 5, 8, 4, 6, 4, 5])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([39, 39, 80, 27, 46, 39, 46, 39,  4,  4, 32, 46,  4, 27, 39, 79, 32, 46,
        32, 39])
[4, 5, 12, 27, 32, 39, 46, 54, 79, 80]
TARGETS AFTER CLEANER:  tensor([5, 5, 9, 3, 6, 5, 6, 5, 0, 0, 4, 6, 0, 3, 5, 8, 4, 6, 4, 5])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  5000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_10C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.49e-02	time: 00:00:50	Acc_train 0.00	Acc_test 0.00	convergence: 2.03e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.173e-03/SW:3.650e-01/MR:2.126e+01/SR:2.877e+00/MeD:2.310e+00/MaD:1.432e+01/MW:0.434/MAW:0.566
|        0 |        1 |        2 |        3 |        4 |        5 |        6 |        7 |        8 |        9 |       10 |       11 |       12 |       13 |       14 |       15 |       16 |       17 |      18 |       19 |       20 |       21 |       22 |       23 |       24 |       25 |       26 |       27 |      28 |       29 |
|----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------|
|   0.0474 |   0.0444 |   0.0458 |   0.0466 |   0.0452 |   0.0434 |   0.0508 |   0.0397 |   0.0495 |   0.0484 |   0.0442 |   0.0466 |   0.0468 |   0.0381 |   0.0463 |   0.0431 |   0.0465 |   0.0495 |   0.046 |   0.0452 |   0.0466 |   0.0455 |   0.0244 |   0.0452 |   0.0439 |   0.0376 |   0.0447 |   0.0425 |   0.041 |   0.0423 |
|  23.48   |  20.68   |  21.99   |  22.69   |  21.47   |  19.85   |  26.79   |  16.76   |  25.46   |  24.39   |  20.5    |  22.72   |  22.89   |  15.54   |  22.45   |  19.62   |  22.59   |  25.49   |  22.13  |  21.39   |  22.72   |  21.73   |   6.94   |  21.42   |  20.29   |  15.14   |  21      |  19.08   |  17.79  |  18.89   |
|   0.05   |   0.05   |   0.07   |   0.03   |   0.02   |   0.05   |   0.07   |   0.04   |   0.09   |   0.05   |   0.07   |   0.07   |   0.19   |   0.09   |   0.13   |   0.03   |   0.03   |   0.06   |   0.05  |   0.03   |   0.05   |   0.05   |   0.4    |   0.05   |   0.04   |   0.07   |   0.05   |   0.06   |   0.05  |   0.05   |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models

 ********** Supervised learning of blocks [3] **********
SAVING FOLDER FOR SUP:  C100_10C_CL
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([39,  4, 32, 27, 32, 32, 54, 27, 27, 46,  4, 39,  4, 54,  4, 32, 39, 80,
        12, 80])
[4, 5, 12, 27, 32, 39, 46, 54, 79, 80]
TARGETS AFTER CLEANER:  tensor([5, 0, 4, 3, 4, 4, 7, 3, 3, 6, 0, 5, 0, 7, 0, 4, 5, 9, 2, 9])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([39, 39, 80, 27, 46, 39, 46, 39,  4,  4, 32, 46,  4, 27, 39, 79, 32, 46,
        32, 39])
[4, 5, 12, 27, 32, 39, 46, 54, 79, 80]
TARGETS AFTER CLEANER:  tensor([5, 5, 9, 3, 6, 5, 6, 5, 0, 0, 4, 6, 0, 3, 5, 8, 4, 6, 4, 5])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([39, 39, 80, 27, 46, 39, 46, 39,  4,  4, 32, 46,  4, 27, 39, 79, 32, 46,
        32, 39])
[4, 5, 12, 27, 32, 39, 46, 54, 79, 80]
TARGETS AFTER CLEANER:  tensor([5, 5, 9, 3, 6, 5, 6, 5, 0, 0, 4, 6, 0, 3, 5, 8, 4, 6, 4, 5])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  5000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Epoch: [1/50]	lr: 1.00e-03	time: 00:01:05	Loss_train 1.21320	Acc_train 39.56	/	Loss_test 0.04360	Acc_test 55.30
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models
Epoch: [10/50]	lr: 1.00e-03	time: 00:01:08	Loss_train 0.34173	Acc_train 71.32	/	Loss_test 0.03025	Acc_test 66.90
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models
Epoch: [20/50]	lr: 2.50e-04	time: 00:01:12	Loss_train 0.08949	Acc_train 88.14	/	Loss_test 0.02491	Acc_test 71.10
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models
Epoch: [30/50]	lr: 1.25e-04	time: 00:01:15	Loss_train 0.04618	Acc_train 92.25	/	Loss_test 0.02396	Acc_test 72.10
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models
Epoch: [40/50]	lr: 3.13e-05	time: 00:01:19	Loss_train 0.03391	Acc_train 93.83	/	Loss_test 0.02325	Acc_test 73.60
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models
Epoch: [50/50]	lr: 7.81e-06	time: 00:01:22	Loss_train 0.02720	Acc_train 94.62	/	Loss_test 0.02319	Acc_test 72.80
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_10C_CL/models
RESULT:  {'train_loss': 0.027201944962143898, 'train_acc': 94.6179986000061, 'test_loss': 0.023192372173070908, 'test_acc': 72.80000305175781, 'convergence': 20.262283325195312, 'R1': 0, 'dataset_sup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 10, 'selected_classes': [4, 5, 12, 27, 32, 39, 46, 54, 79, 80]}, 'dataset_unsup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 50, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 10, 'selected_classes': [4, 5, 12, 27, 32, 39, 46, 54, 79, 80]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}
IN R2:  {'R1': {'train_loss': 0.013124372810125351, 'train_acc': 96.57599925994873, 'test_loss': 0.014639913104474545, 'test_acc': 77.9000015258789, 'convergence': 21.46358871459961, 'R1': 0, 'dataset_sup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 10, 'selected_classes': [25, 28, 41, 51, 55, 65, 75, 77, 81, 92]}, 'dataset_unsup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 50, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 10, 'selected_classes': [25, 28, 41, 51, 55, 65, 75, 77, 81, 92]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}, 'R2': {'train_loss': 0.027201944962143898, 'train_acc': 94.6179986000061, 'test_loss': 0.023192372173070908, 'test_acc': 72.80000305175781, 'convergence': 20.262283325195312, 'R1': 0, 'dataset_sup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 10, 'selected_classes': [4, 5, 12, 27, 32, 39, 46, 54, 79, 80]}, 'dataset_unsup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 50, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 10, 'selected_classes': [4, 5, 12, 27, 32, 39, 46, 54, 79, 80]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.11048543456039805, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10, 'in_channels': 24576, 'old_channels': 1536, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 Model C100_10C_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=10, bias=True)
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([51, 92, 75, 81, 92, 75, 41, 25, 41, 75, 77, 65, 92, 77, 75, 25, 92, 25,
        51, 77])
[25, 28, 41, 51, 55, 65, 75, 77, 81, 92]
TARGETS AFTER CLEANER:  tensor([3, 9, 6, 8, 9, 6, 2, 0, 2, 6, 7, 5, 9, 7, 6, 0, 9, 0, 3, 7])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([28, 65, 81, 55, 51, 92, 75, 77, 75, 55, 51, 28, 28, 65, 81, 81, 65, 41,
        77, 28])
[25, 28, 41, 51, 55, 65, 75, 77, 81, 92]
TARGETS AFTER CLEANER:  tensor([1, 5, 8, 4, 3, 9, 6, 7, 6, 4, 3, 1, 1, 5, 8, 8, 5, 2, 7, 1])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([28, 65, 81, 55, 51, 92, 75, 77, 75, 55, 51, 28, 28, 65, 81, 81, 65, 41,
        77, 28])
[25, 28, 41, 51, 55, 65, 75, 77, 81, 92]
TARGETS AFTER CLEANER:  tensor([1, 5, 8, 4, 3, 9, 6, 7, 6, 4, 3, 1, 1, 5, 8, 8, 5, 2, 7, 1])
5000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 5000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  5000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Accuracy of the network on the 1st dataset: 8.700 %
Test loss on the 1st dataset: 0.193

