BLOCKS:  {'b0': {'arch': 'CNN', 'preset': 'softkrotov-c96-k5-p2-s1-d1-b0-t1-lr0.08-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 0, 'batch_norm': False, 'pool': {'type': 'max', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 0.7}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5}}, 'b1': {'arch': 'CNN', 'preset': 'softkrotov-c384-k3-p1-s1-d1-b0-t0.65-lr0.005-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 1, 'batch_norm': False, 'pool': {'type': 'max', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 1.4}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3}}, 'b2': {'arch': 'CNN', 'preset': 'softkrotov-c1536-k3-p1-s1-d1-b0-t0.25-lr0.01-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 2, 'batch_norm': False, 'pool': {'type': 'avg', 'kernel_size': 2, 'stride': 2, 'padding': 0}, 'activation': {'function': 'triangle', 'param': 1.0}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3}}, 'b3': {'arch': 'MLP', 'preset': 'BP-c10', 'operation': 'flatten', 'num': 3, 'att_dropout': None, 'dropout': 0.5, 'layer': {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.25, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10}, 'pool': None, 'activation': None}}
CL:  True
{'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True}
CL:  True
{'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.11048543456039805, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 2, 'in_channels': 24576, 'old_channels': 1536, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=2, bias=True)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([0, 0, 9, 9, 0, 9, 0, 9, 9, 9, 0, 9, 9, 9, 0, 0, 9, 9, 0, 0])
[0, 9]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 9, 9, 9, 0, 0, 9, 0, 0, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9])
[0, 9]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 9, 9, 9, 0, 0, 9, 0, 0, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9])
[0, 9]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_2C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.44e-01	time: 00:00:25	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:6.217e-03/SW:5.681e-01/MR:4.618e+00/SR:1.706e+00/MeD:1.308e+00/MaD:4.280e+00/MW:0.623/MAW:0.377
|       0 |       1 |       2 |       3 |       4 |      5 |       6 |       7 |       8 |       9 |      10 |      11 |      12 |      13 |     14 |      15 |         16 |      17 |      18 |      19 |      20 |      21 |      22 |      23 |      24 |         25 |      26 |      27 |      28 |      29 |
|---------+---------+---------+---------+---------+--------+---------+---------+---------+---------+---------+---------+---------+---------+--------+---------+------------+---------+---------+---------+---------+---------+---------+---------+---------+------------+---------+---------+---------+---------|
|   0.128 |   0.145 |   0.117 |   0.158 |   0.129 |   0.11 |   0.161 |   0.173 |   0.146 |   0.225 |   0.166 |   0.149 |   0.124 |   0.129 |   0.15 |   0.183 |   8.29e-05 |   0.126 |   0.161 |   0.186 |   0.195 |   0.169 |   0.126 |   0.178 |   0.161 |   0.000117 |   0.171 |   0.174 |   0.121 |   0.193 |
|   3.55  |   4.29  |   3.14  |   4.9   |   3.61  |   2.89 |   5.06  |   5.66  |   4.33  |   8.9   |   5.31  |   4.45  |   3.41  |   3.61  |   4.53 |   6.25  |   1        |   3.49  |   5.06  |   6.41  |   6.92  |   5.44  |   3.46  |   5.95  |   5.03  |   1        |   5.56  |   5.72  |   3.28  |   6.84  |
|   0.54  |   0.51  |   0.46  |   0.5   |   0.83  |   1.14 |   0.52  |   0.38  |   0.67  |   0.51  |   0.93  |   0.51  |   0.56  |   0.41  |   0.68 |   0.47  |  16.03     |   0.5   |   0.51  |   0.66  |   0.58  |   0.68  |   0.51  |   0.47  |   0.47  |  16.17     |   0.44  |   0.84  |   0.45  |   0.54  |
| nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     |
| nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     |
| nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([0, 0, 9, 9, 0, 9, 0, 9, 9, 9, 0, 9, 9, 9, 0, 0, 9, 9, 0, 0])
[0, 9]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 9, 9, 9, 0, 0, 9, 0, 0, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9])
[0, 9]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 9, 9, 9, 0, 0, 9, 0, 0, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9])
[0, 9]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_2C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.44e-01	time: 00:00:49	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.481e-03/SW:3.379e-01/MR:9.765e+00/SR:1.823e+00/MeD:1.405e+00/MaD:7.763e+00/MW:0.573/MAW:0.427
|        0 |        1 |        2 |        3 |         4 |        5 |        6 |        7 |        8 |        9 |       10 |       11 |       12 |       13 |      14 |       15 |      16 |       17 |       18 |       19 |       20 |       21 |       22 |       23 |      24 |       25 |       26 |      27 |       28 |      29 |
|----------+----------+----------+----------+-----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+---------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+---------+----------+---------|
|   0.0153 |   0.0142 |   0.0143 |   0.0137 |   0.00758 |   0.0131 |   0.0145 |   0.0133 |   0.0148 |   0.0159 |   0.0142 |   0.0158 |   0.0158 |   0.0173 |   0.016 |   0.0151 |   0.016 |   0.0156 |   0.0113 |   0.0131 |   0.0155 |   0.0164 |   0.0146 |   0.0169 |   0.012 |   0.0168 |   0.0143 |   0.013 |   0.0149 |   0.015 |
|  10.36   |   9.12   |   9.21   |   8.51   |   3.3     |   7.86   |   9.41   |   8.12   |   9.76   |  11.15   |   9.08   |  10.93   |  10.97   |  13.03   |  11.29  |  10.06   |  11.21  |  10.75   |   6.15   |   7.89   |  10.56   |  11.79   |   9.53   |  12.36   |   6.75  |  12.26   |   9.21   |   7.72  |   9.88   |   9.98  |
|   0.21   |   0.2    |   0.21   |   0.24   |   1.23    |   0.31   |   0.25   |   0.26   |   0.19   |   0.16   |   0.2    |   0.26   |   0.2    |   0.16   |   0.15  |   0.18   |   0.13  |   0.29   |   0.35   |   0.26   |   0.16   |   0.25   |   0.58   |   0.16   |   0.94  |   0.39   |   0.15   |   0.25  |   0.17   |   0.27  |
| nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan     |
| nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan     |
| nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([0, 0, 9, 9, 0, 9, 0, 9, 9, 9, 0, 9, 9, 9, 0, 0, 9, 9, 0, 0])
[0, 9]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 9, 9, 9, 0, 0, 9, 0, 0, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9])
[0, 9]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 9, 9, 9, 0, 0, 9, 0, 0, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9])
[0, 9]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_2C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.52e-02	time: 00:01:14	Acc_train 0.00	Acc_test 0.00	convergence: 2.05e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.015e-03/SW:3.696e-01/MR:2.153e+01/SR:2.944e+00/MeD:2.323e+00/MaD:2.044e+01/MW:0.452/MAW:0.548
|       0 |        1 |        2 |        3 |        4 |        5 |        6 |        7 |        8 |        9 |       10 |       11 |       12 |       13 |       14 |       15 |      16 |       17 |       18 |       19 |       20 |      21 |       22 |       23 |       24 |       25 |      26 |       27 |       28 |       29 |
|---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+---------+----------+----------+----------+----------+---------+----------+----------+----------|
|   0.049 |   0.0424 |   0.0441 |   0.0458 |   0.0452 |   0.0422 |   0.0464 |   0.0409 |   0.0478 |   0.0475 |   0.0441 |   0.0486 |   0.0458 |   0.0382 |   0.0466 |   0.0445 |   0.046 |   0.0518 |   0.0504 |   0.0441 |   0.0476 |   0.045 |   0.0426 |   0.0444 |   0.0449 |   0.0349 |   0.048 |   0.0449 |   0.0423 |   0.0458 |
|  24.98  |  18.98   |  20.41   |  22.01   |  21.39   |  18.84   |  22.51   |  17.73   |  23.87   |  23.53   |  20.44   |  24.58   |  21.94   |  15.59   |  22.68   |  20.82   |  22.12  |  27.83   |  26.44   |  20.45   |  23.65   |  21.28  |  19.19   |  20.67   |  21.14   |  13.2    |  24     |  21.19   |  18.88   |  22      |
|   0.03  |   0.06   |   0.07   |   0.04   |   0.03   |   0.04   |   0.07   |   0.05   |   0.07   |   0.03   |   0.1    |   0.07   |   0.15   |   0.09   |   0.19   |   0.04   |   0.04  |   0.07   |   0.07   |   0.04   |   0.05   |   0.05  |   0.4    |   0.05   |   0.04   |   0.09   |   0.05  |   0.07   |   0.05   |   0.03   |
| nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      |
| nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      |
| nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models

 ********** Supervised learning of blocks [3] **********
SAVING FOLDER FOR SUP:  C10_2C_CL
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([0, 0, 9, 9, 0, 9, 0, 9, 9, 9, 0, 9, 9, 9, 0, 0, 9, 9, 0, 0])
[0, 9]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 9, 9, 9, 0, 0, 9, 0, 0, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9])
[0, 9]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 9, 9, 9, 0, 0, 9, 0, 0, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9])
[0, 9]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Epoch: [1/50]	lr: 1.00e-03	time: 00:01:35	Loss_train 0.18737	Acc_train 86.70	/	Loss_test 0.00358	Acc_test 90.50
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [10/50]	lr: 1.00e-03	time: 00:01:41	Loss_train 0.04985	Acc_train 93.85	/	Loss_test 0.00520	Acc_test 92.95
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [20/50]	lr: 2.50e-04	time: 00:01:48	Loss_train 0.03167	Acc_train 96.44	/	Loss_test 0.00501	Acc_test 93.90
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [30/50]	lr: 1.25e-04	time: 00:01:54	Loss_train 0.02179	Acc_train 97.22	/	Loss_test 0.00381	Acc_test 94.60
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [40/50]	lr: 3.13e-05	time: 00:02:01	Loss_train 0.01626	Acc_train 97.67	/	Loss_test 0.00378	Acc_test 94.60
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [50/50]	lr: 7.81e-06	time: 00:02:08	Loss_train 0.01464	Acc_train 97.84	/	Loss_test 0.00369	Acc_test 94.65
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
RESULT:  {'train_loss': 0.014643830247223377, 'train_acc': 97.83999919891357, 'test_loss': 0.0036855635698884726, 'test_acc': 94.6500015258789, 'convergence': 20.526851654052734, 'R1': 0, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [0, 9]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [0, 9]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}
IN R1:  {'R1': {'train_loss': 0.014643830247223377, 'train_acc': 97.83999919891357, 'test_loss': 0.0036855635698884726, 'test_acc': 94.6500015258789, 'convergence': 20.526851654052734, 'R1': 0, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [0, 9]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [0, 9]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.11048543456039805, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 2, 'in_channels': 24576, 'old_channels': 1536, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 Model C10_2C_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=2, bias=True)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([8, 8, 7, 8, 7, 8, 7, 7, 8, 8, 8, 7, 7, 7, 7, 8, 8, 8, 8, 7])
[7, 8]
TARGETS AFTER CLEANER:  tensor([1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([7, 8, 7, 7, 7, 7, 7, 8, 7, 8, 7, 7, 7, 7, 8, 8, 8, 8, 7, 7])
[7, 8]
TARGETS AFTER CLEANER:  tensor([0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([7, 8, 7, 7, 7, 7, 7, 8, 7, 8, 7, 7, 7, 7, 8, 8, 8, 8, 7, 7])
[7, 8]
TARGETS AFTER CLEANER:  tensor([0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_2C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.48e-01	time: 00:00:22	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.077e-02/SW:6.194e-01/MR:4.933e+00/SR:2.120e+00/MeD:1.516e+00/MaD:6.108e+00/MW:0.600/MAW:0.400
|       0 |       1 |       2 |       3 |       4 |       5 |       6 |       7 |       8 |       9 |      10 |      11 |      12 |      13 |      14 |     15 |         16 |      17 |      18 |      19 |      20 |      21 |      22 |      23 |      24 |      25 |      26 |      27 |        28 |      29 |
|---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+--------+------------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+-----------+---------|
|   0.132 |   0.142 |   0.134 |   0.168 |   0.158 |   0.143 |   0.164 |   0.154 |   0.141 |   0.231 |   0.213 |   0.152 |   0.146 |   0.132 |   0.146 |   0.16 |   3.91e-05 |   0.158 |   0.149 |   0.181 |   0.167 |   0.153 |   0.155 |   0.183 |   0.171 |   8e-07 |   0.221 |   0.253 |   0.00316 |   0.223 |
|   3.72  |   4.15  |   3.79  |   5.43  |   4.89  |   4.18  |   5.19  |   4.71  |   4.11  |   9.35  |   8.1   |   4.61  |   4.34  |   3.71  |   4.35  |   4.98 |   1        |   4.88  |   4.48  |   6.14  |   5.35  |   4.67  |   4.77  |   6.22  |   5.59  |   1     |   8.64  |  11.04  |   1       |   8.8   |
|   0.46  |   0.51  |   0.5   |   0.53  |   0.48  |   0.54  |   0.48  |   0.43  |   0.51  |   0.57  |   0.84  |   0.51  |   0.48  |   0.45  |   0.46  |   0.42 |  21.16     |   0.52  |   0.4   |   0.53  |   0.54  |   0.43  |   0.45  |   0.53  |   0.44  |  24.72  |   0.45  |   0.61  |   0.84    |   0.6   |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan       | nan     |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan       | nan     |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan       | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([8, 8, 7, 8, 7, 8, 7, 7, 8, 8, 8, 7, 7, 7, 7, 8, 8, 8, 8, 7])
[7, 8]
TARGETS AFTER CLEANER:  tensor([1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([7, 8, 7, 7, 7, 7, 7, 8, 7, 8, 7, 7, 7, 7, 8, 8, 8, 8, 7, 7])
[7, 8]
TARGETS AFTER CLEANER:  tensor([0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([7, 8, 7, 7, 7, 7, 7, 8, 7, 8, 7, 7, 7, 7, 8, 8, 8, 8, 7, 7])
[7, 8]
TARGETS AFTER CLEANER:  tensor([0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_2C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.48e-01	time: 00:00:44	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:4.967e-03/SW:2.031e-01/MR:5.819e+00/SR:1.344e+00/MeD:1.034e+00/MaD:4.819e+00/MW:0.576/MAW:0.424
|        0 |        1 |         2 |         3 |          4 |        5 |         6 |        7 |        8 |        9 |       10 |       11 |       12 |       13 |       14 |       15 |       16 |       17 |        18 |       19 |       20 |       21 |        22 |       23 |       24 |       25 |       26 |        27 |       28 |        29 |
|----------+----------+-----------+-----------+------------+----------+-----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+-----------+----------+----------+----------+-----------+----------+----------+----------+----------+-----------+----------+-----------|
|   0.0107 |   0.0116 |   0.00916 |   0.00664 |   7.66e-05 |   0.0118 |   0.00981 |   0.0107 |   0.0114 |   0.0121 |   0.0117 |   0.0117 |   0.0108 |   0.0123 |   0.0107 |   0.0114 |   0.0111 |   0.0114 |   0.00654 |   0.0113 |   0.0123 |   0.0114 |   0.00997 |   0.0123 |   0.0101 |   0.0123 |   0.0115 |   0.00961 |   0.0123 |   0.00865 |
|   5.6    |   6.36   |   4.36    |   2.76    |   1        |   6.54   |   4.85    |   5.56   |   6.2    |   6.82   |   6.48   |   6.44   |   5.68   |   7.08   |   5.55   |   6.23   |   5.93   |   6.23   |   2.71    |   6.13   |   7.1    |   6.19   |   4.98    |   7.04   |   5.09   |   7.06   |   6.28   |   4.7     |   7.03   |   4       |
|   0.17   |   0.14   |   0.16    |   0.26    |   7.18     |   0.2    |   0.23    |   0.24   |   0.16   |   0.16   |   0.19   |   0.23   |   0.23   |   0.2    |   0.15   |   0.19   |   0.14   |   0.25   |   0.24    |   0.2    |   0.19   |   0.25   |   0.3     |   0.2    |   0.44   |   0.25   |   0.13   |   0.21    |   0.11   |   0.33    |
| nan      | nan      | nan       | nan       | nan        | nan      | nan       | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan       | nan      | nan       |
| nan      | nan      | nan       | nan       | nan        | nan      | nan       | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan       | nan      | nan       |
| nan      | nan      | nan       | nan       | nan        | nan      | nan       | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan       | nan      | nan       |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([8, 8, 7, 8, 7, 8, 7, 7, 8, 8, 8, 7, 7, 7, 7, 8, 8, 8, 8, 7])
[7, 8]
TARGETS AFTER CLEANER:  tensor([1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([7, 8, 7, 7, 7, 7, 7, 8, 7, 8, 7, 7, 7, 7, 8, 8, 8, 8, 7, 7])
[7, 8]
TARGETS AFTER CLEANER:  tensor([0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([7, 8, 7, 7, 7, 7, 7, 8, 7, 8, 7, 7, 7, 7, 8, 8, 8, 8, 7, 7])
[7, 8]
TARGETS AFTER CLEANER:  tensor([0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_2C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.27e-02	time: 00:01:08	Acc_train 0.00	Acc_test 0.00	convergence: 1.83e+01	R1: 1	Info MB:0.000e+00/SB:0.000e+00/MW:2.820e-03/SW:3.310e-01/MR:1.931e+01/SR:2.409e+00/MeD:1.893e+00/MaD:1.831e+01/MW:0.447/MAW:0.553
|       0 |        1 |        2 |       3 |        4 |        5 |        6 |        7 |        8 |        9 |       10 |      11 |       12 |       13 |      14 |      15 |      16 |       17 |       18 |       19 |       20 |       21 |       22 |      23 |       24 |       25 |       26 |       27 |       28 |      29 |
|---------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+---------+---------+---------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+---------|
|   0.044 |   0.0399 |   0.0433 |   0.043 |   0.0415 |   0.0414 |   0.0445 |   0.0406 |   0.0401 |   0.0444 |   0.0432 |   0.045 |   0.0359 |   0.0375 |   0.041 |   0.043 |   0.045 |   0.0477 |   0.0427 |   0.0428 |   0.0403 |   0.0409 |   0.0414 |   0.044 |   0.0406 |   0.0366 |   0.0454 |   0.0455 |   0.0391 |   0.042 |
|  20.34  |  16.91   |  19.72   |  19.46  |  18.21   |  18.11   |  20.8    |  17.47   |  17.11   |  20.73   |  19.67   |  21.28  |  13.86   |  15.1    |  17.85  |  19.52  |  21.24  |  23.78   |  19.19   |  19.28   |  17.21   |  17.71   |  18.13   |  20.35  |  17.46   |  14.37   |  21.59   |  21.67   |  16.31   |  18.61  |
|   0.06  |   0.05   |   0.06   |   0.07  |   0.04   |   0.04   |   0.1    |   0.02   |   0.07   |   0.05   |   0.06   |   0.09  |   0.17   |   0.02   |   0.16  |   0.05  |   0.05  |   0.11   |   0.06   |   0.03   |   0.1    |   0.06   |   0.05   |   0.06  |   0.05   |   0.05   |   0.09   |   0.04   |   0.05   |   0.05  |
| nan     | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan     | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan     |
| nan     | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan     | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan     |
| nan     | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan     | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models

 ********** Supervised learning of blocks [3] **********
SAVING FOLDER FOR SUP:  C10_2C_CL
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([8, 8, 7, 8, 7, 8, 7, 7, 8, 8, 8, 7, 7, 7, 7, 8, 8, 8, 8, 7])
[7, 8]
TARGETS AFTER CLEANER:  tensor([1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([7, 8, 7, 7, 7, 7, 7, 8, 7, 8, 7, 7, 7, 7, 8, 8, 8, 8, 7, 7])
[7, 8]
TARGETS AFTER CLEANER:  tensor([0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([7, 8, 7, 7, 7, 7, 7, 8, 7, 8, 7, 7, 7, 7, 8, 8, 8, 8, 7, 7])
[7, 8]
TARGETS AFTER CLEANER:  tensor([0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Epoch: [1/50]	lr: 1.00e-03	time: 00:01:28	Loss_train 0.13367	Acc_train 93.55	/	Loss_test 0.01096	Acc_test 93.25
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [10/50]	lr: 1.00e-03	time: 00:01:34	Loss_train 0.02766	Acc_train 98.10	/	Loss_test 0.00282	Acc_test 98.25
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [20/50]	lr: 2.50e-04	time: 00:01:41	Loss_train 0.00862	Acc_train 99.26	/	Loss_test 0.00258	Acc_test 98.20
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [30/50]	lr: 1.25e-04	time: 00:01:48	Loss_train 0.00424	Acc_train 99.55	/	Loss_test 0.00265	Acc_test 98.10
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [40/50]	lr: 3.13e-05	time: 00:01:55	Loss_train 0.00270	Acc_train 99.67	/	Loss_test 0.00264	Acc_test 98.15
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [50/50]	lr: 7.81e-06	time: 00:02:01	Loss_train 0.00255	Acc_train 99.71	/	Loss_test 0.00271	Acc_test 98.10
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
RESULT:  {'train_loss': 0.0025458973832428455, 'train_acc': 99.71200227737427, 'test_loss': 0.0027066145557910204, 'test_acc': 98.0999984741211, 'convergence': 18.31085205078125, 'R1': 1, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [7, 8]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [7, 8]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}
IN R2:  {'R1': {'train_loss': 0.014643830247223377, 'train_acc': 97.83999919891357, 'test_loss': 0.0036855635698884726, 'test_acc': 94.6500015258789, 'convergence': 20.526851654052734, 'R1': 0, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [0, 9]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [0, 9]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}, 'R2': {'train_loss': 0.0025458973832428455, 'train_acc': 99.71200227737427, 'test_loss': 0.0027066145557910204, 'test_acc': 98.0999984741211, 'convergence': 18.31085205078125, 'R1': 1, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [7, 8]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [7, 8]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.11048543456039805, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 2, 'in_channels': 24576, 'old_channels': 1536, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 Model C10_2C_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=2, bias=True)
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([0, 0, 9, 9, 0, 9, 0, 9, 9, 9, 0, 9, 9, 9, 0, 0, 9, 9, 0, 0])
[0, 9]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 9, 9, 9, 0, 0, 9, 0, 0, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9])
[0, 9]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 9, 9, 9, 0, 0, 9, 0, 0, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9])
[0, 9]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Accuracy of the network on the 1st dataset: 49.350 %
Test loss on the 1st dataset: 0.183

