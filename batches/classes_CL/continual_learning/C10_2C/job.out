--------------- /leonardo/prod/opt/modulefiles/deeplrn/libraries ---------------
cineca-ai/3.0.0  cineca-ai/4.0.0  cineca-ai/4.1.1(default)  
cineca-ai/3.0.1  cineca-ai/4.1.0  cineca-ai/4.3.0           

Key:
(symbolic-version)  
BLOCKS:  {'b0': {'arch': 'CNN', 'preset': 'softkrotov-c96-k5-p2-s1-d1-b0-t1-lr0.08-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 0, 'batch_norm': False, 'pool': {'type': 'max', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 0.7}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5}}, 'b1': {'arch': 'CNN', 'preset': 'softkrotov-c384-k3-p1-s1-d1-b0-t0.65-lr0.005-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 1, 'batch_norm': False, 'pool': {'type': 'max', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 1.4}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3}}, 'b2': {'arch': 'CNN', 'preset': 'softkrotov-c1536-k3-p1-s1-d1-b0-t0.25-lr0.01-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 2, 'batch_norm': False, 'pool': {'type': 'avg', 'kernel_size': 2, 'stride': 2, 'padding': 0}, 'activation': {'function': 'triangle', 'param': 1.0}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3}}, 'b3': {'arch': 'MLP', 'preset': 'BP-c10', 'operation': 'flatten', 'num': 3, 'att_dropout': None, 'dropout': 0.5, 'layer': {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.25, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10}, 'pool': None, 'activation': None}}
CL:  True
{'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True}
CL:  True
{'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.11048543456039805, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 2, 'in_channels': 24576, 'old_channels': 1536, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=2, bias=True)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([3, 6, 6, 6, 3, 6, 6, 6, 6, 6, 3, 6, 3, 6, 3, 6, 3, 6, 3, 6])
[3, 6]
TARGETS AFTER CLEANER:  tensor([0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 3, 3, 6, 3, 6, 6, 6, 3, 3, 3, 3, 3, 3, 6, 3, 3, 3, 3, 6])
[3, 6]
TARGETS AFTER CLEANER:  tensor([1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 3, 3, 6, 3, 6, 6, 6, 3, 3, 3, 3, 3, 3, 6, 3, 3, 3, 3, 6])
[3, 6]
TARGETS AFTER CLEANER:  tensor([1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_2C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.52e-01	time: 00:00:19	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.021e-02/SW:6.009e-01/MR:4.930e+00/SR:1.677e+00/MeD:1.387e+00/MaD:3.930e+00/MW:0.567/MAW:0.433
|       0 |       1 |       2 |       3 |       4 |       5 |       6 |       7 |       8 |       9 |        10 |      11 |      12 |      13 |      14 |      15 |      16 |      17 |      18 |      19 |      20 |      21 |     22 |      23 |      24 |         25 |     26 |     27 |      28 |      29 |
|---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+-----------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+--------+---------+---------+------------+--------+--------+---------+---------|
|   0.121 |   0.151 |   0.172 |   0.185 |   0.124 |   0.122 |   0.176 |   0.198 |   0.136 |   0.204 |   0.00308 |   0.142 |   0.201 |   0.149 |   0.156 |   0.202 |   0.177 |   0.132 |   0.185 |   0.192 |   0.203 |   0.182 |   0.15 |   0.197 |   0.175 |   0.000308 |   0.19 |   0.13 |   0.123 |   0.197 |
|   3.29  |   4.57  |   5.62  |   6.36  |   3.42  |   3.33  |   5.82  |   7.13  |   3.9   |   7.51  |   1       |   4.16  |   7.33  |   4.46  |   4.79  |   7.37  |   5.89  |   3.73  |   6.32  |   6.74  |   7.43  |   6.16  |   4.51 |   7.05  |   5.79  |   1        |   6.66 |   3.63 |   3.38  |   7.04  |
|   0.66  |   0.62  |   0.57  |   0.65  |   0.68  |   0.98  |   0.76  |   0.57  |   0.74  |   0.53  |   1.75    |   0.55  |   0.69  |   0.48  |   0.79  |   0.6   |   1.3   |   0.62  |   0.65  |   0.74  |   0.7   |   0.77  |   0.63 |   0.56  |   0.57  |  18.12     |   0.59 |   0.68 |   0.58  |   0.6   |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan       | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan        | nan    | nan    | nan     | nan     |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan       | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan        | nan    | nan    | nan     | nan     |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan       | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan        | nan    | nan    | nan     | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([3, 6, 6, 6, 3, 6, 6, 6, 6, 6, 3, 6, 3, 6, 3, 6, 3, 6, 3, 6])
[3, 6]
TARGETS AFTER CLEANER:  tensor([0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 3, 3, 6, 3, 6, 6, 6, 3, 3, 3, 3, 3, 3, 6, 3, 3, 3, 3, 6])
[3, 6]
TARGETS AFTER CLEANER:  tensor([1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 3, 3, 6, 3, 6, 6, 6, 3, 3, 3, 3, 3, 3, 6, 3, 3, 3, 3, 6])
[3, 6]
TARGETS AFTER CLEANER:  tensor([1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_2C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.52e-01	time: 00:00:36	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.687e-03/SW:2.723e-01/MR:7.878e+00/SR:1.415e+00/MeD:1.084e+00/MaD:6.813e+00/MW:0.535/MAW:0.465
|        0 |        1 |        2 |        3 |         4 |       5 |       6 |        7 |        8 |        9 |       10 |       11 |       12 |       13 |       14 |       15 |       16 |      17 |       18 |       19 |       20 |       21 |       22 |       23 |        24 |       25 |       26 |       27 |       28 |       29 |
|----------+----------+----------+----------+-----------+---------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+-----------+----------+----------+----------+----------+----------|
|   0.0141 |   0.0114 |   0.0138 |   0.0115 |   0.00984 |   0.013 |   0.013 |   0.0115 |   0.0134 |   0.0129 |   0.0122 |   0.0138 |   0.0127 |   0.0149 |   0.0138 |   0.0133 |   0.0134 |   0.012 |   0.0106 |   0.0111 |   0.0144 |   0.0135 |   0.0131 |   0.0124 |   0.00128 |   0.0157 |   0.0125 |   0.0117 |   0.0129 |   0.0126 |
|   8.91   |   6.23   |   8.66   |   6.3    |   4.87    |   7.77  |   7.73  |   6.25   |   8.2    |   7.63   |   6.99   |   8.65   |   7.42   |   9.83   |   8.61   |   8.06   |   8.13   |   6.79  |   5.5    |   5.89   |   9.34   |   8.24   |   7.88   |   7.18   |   1.07    |  10.83   |   7.24   |   6.48   |   7.7    |   7.34   |
|   0.19   |   0.19   |   0.2    |   0.22   |   0.77    |   0.24  |   0.29  |   0.24   |   0.22   |   0.22   |   0.26   |   0.32   |   0.21   |   0.2    |   0.19   |   0.24   |   0.29   |   0.31  |   0.28   |   0.29   |   0.18   |   0.31   |   0.53   |   0.36   |   1.26    |   0.41   |   0.28   |   0.27   |   0.23   |   0.31   |
| nan      | nan      | nan      | nan      | nan       | nan     | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan       | nan     | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan       | nan     | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([3, 6, 6, 6, 3, 6, 6, 6, 6, 6, 3, 6, 3, 6, 3, 6, 3, 6, 3, 6])
[3, 6]
TARGETS AFTER CLEANER:  tensor([0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 3, 3, 6, 3, 6, 6, 6, 3, 3, 3, 3, 3, 3, 6, 3, 3, 3, 3, 6])
[3, 6]
TARGETS AFTER CLEANER:  tensor([1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 3, 3, 6, 3, 6, 6, 6, 3, 3, 3, 3, 3, 3, 6, 3, 3, 3, 3, 6])
[3, 6]
TARGETS AFTER CLEANER:  tensor([1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_2C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.50e-02	time: 00:00:54	Acc_train 0.00	Acc_test 0.00	convergence: 2.04e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.121e-03/SW:3.666e-01/MR:2.135e+01/SR:2.930e+00/MeD:2.372e+00/MaD:1.017e+01/MW:0.440/MAW:0.560
|        0 |        1 |        2 |        3 |        4 |        5 |        6 |        7 |        8 |        9 |      10 |       11 |       12 |       13 |       14 |       15 |       16 |       17 |      18 |       19 |       20 |       21 |       22 |       23 |       24 |       25 |       26 |       27 |       28 |       29 |
|----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------|
|   0.0467 |   0.0442 |   0.0439 |   0.0484 |   0.0469 |   0.0398 |   0.0466 |   0.0371 |   0.0474 |   0.0489 |   0.049 |   0.0473 |   0.0445 |   0.0385 |   0.0477 |   0.0436 |   0.0501 |   0.0498 |   0.045 |   0.0449 |   0.0474 |   0.0429 |   0.0354 |   0.0461 |   0.0474 |   0.0393 |   0.0472 |   0.0457 |   0.0431 |   0.0446 |
|  22.85   |  20.52   |  20.23   |  24.46   |  23.03   |  16.8    |  22.7    |  14.75   |  23.51   |  24.93   |  25.06  |  23.36   |  20.84   |  15.85   |  23.8    |  19.99   |  26.12   |  25.83   |  21.21  |  21.15   |  23.43   |  19.42   |  13.5    |  22.22   |  23.44   |  16.43   |  23.3    |  21.88   |  19.56   |  20.86   |
|   0.04   |   0.05   |   0.07   |   0.03   |   0.03   |   0.08   |   0.06   |   0.07   |   0.05   |   0.05   |   0.04  |   0.08   |   0.14   |   0.09   |   0.13   |   0.04   |   0.04   |   0.09   |   0.04  |   0.04   |   0.05   |   0.06   |   0.21   |   0.04   |   0.04   |   0.06   |   0.06   |   0.05   |   0.04   |   0.04   |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models

 ********** Supervised learning of blocks [3] **********
SAVING FOLDER FOR SUP:  C10_2C_CL
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([3, 6, 6, 6, 3, 6, 6, 6, 6, 6, 3, 6, 3, 6, 3, 6, 3, 6, 3, 6])
[3, 6]
TARGETS AFTER CLEANER:  tensor([0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 3, 3, 6, 3, 6, 6, 6, 3, 3, 3, 3, 3, 3, 6, 3, 3, 3, 3, 6])
[3, 6]
TARGETS AFTER CLEANER:  tensor([1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 3, 3, 6, 3, 6, 6, 6, 3, 3, 3, 3, 3, 3, 6, 3, 3, 3, 3, 6])
[3, 6]
TARGETS AFTER CLEANER:  tensor([1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Epoch: [1/50]	lr: 1.00e-03	time: 00:01:09	Loss_train 0.17862	Acc_train 81.28	/	Loss_test 0.00393	Acc_test 88.15
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [10/50]	lr: 1.00e-03	time: 00:01:13	Loss_train 0.11659	Acc_train 87.92	/	Loss_test 0.00709	Acc_test 89.85
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [20/50]	lr: 2.50e-04	time: 00:01:17	Loss_train 0.08007	Acc_train 91.52	/	Loss_test 0.00630	Acc_test 90.75
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [30/50]	lr: 1.25e-04	time: 00:01:21	Loss_train 0.05932	Acc_train 92.76	/	Loss_test 0.00551	Acc_test 91.15
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [40/50]	lr: 3.13e-05	time: 00:01:26	Loss_train 0.04852	Acc_train 93.45	/	Loss_test 0.00525	Acc_test 91.55
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [50/50]	lr: 7.81e-06	time: 00:01:30	Loss_train 0.04612	Acc_train 93.57	/	Loss_test 0.00523	Acc_test 91.40
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
RESULT:  {'train_loss': 0.04612022638320923, 'train_acc': 93.5699999332428, 'test_loss': 0.0052311173640191555, 'test_acc': 91.4000015258789, 'convergence': 20.352340698242188, 'R1': 0, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [3, 6]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [3, 6]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}
IN R1:  {'R1': {'train_loss': 0.04612022638320923, 'train_acc': 93.5699999332428, 'test_loss': 0.0052311173640191555, 'test_acc': 91.4000015258789, 'convergence': 20.352340698242188, 'R1': 0, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [3, 6]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [3, 6]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.11048543456039805, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 2, 'in_channels': 24576, 'old_channels': 1536, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 Model C10_2C_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=2, bias=True)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([8, 8, 8, 8, 2, 2, 8, 8, 8, 2, 2, 2, 8, 8, 2, 8, 8, 2, 2, 8])
[2, 8]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([2, 8, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 8, 2, 8, 2, 8, 8, 8, 2])
[2, 8]
TARGETS AFTER CLEANER:  tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([2, 8, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 8, 2, 8, 2, 8, 8, 8, 2])
[2, 8]
TARGETS AFTER CLEANER:  tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_2C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.35e-01	time: 00:00:16	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:8.423e-03/SW:5.170e-01/MR:4.203e+00/SR:1.554e+00/MeD:1.182e+00/MaD:3.775e+00/MW:0.612/MAW:0.388
|       0 |      1 |       2 |      3 |       4 |        5 |       6 |       7 |       8 |       9 |        10 |      11 |      12 |      13 |      14 |      15 |      16 |      17 |      18 |      19 |      20 |      21 |      22 |      23 |      24 |         25 |      26 |      27 |       28 |      29 |
|---------+--------+---------+--------+---------+----------+---------+---------+---------+---------+-----------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+------------+---------+---------+----------+---------|
|   0.105 |   0.12 |   0.112 |   0.15 |   0.137 |   0.0917 |   0.156 |   0.196 |   0.139 |   0.176 |   0.00128 |   0.147 |   0.157 |   0.122 |   0.153 |   0.187 |   0.147 |   0.142 |   0.153 |   0.182 |   0.186 |   0.175 |   0.141 |   0.206 |   0.167 |   0.000328 |   0.135 |   0.087 |   0.0762 |   0.211 |
|   2.71  |   3.25 |   2.96  |   4.5  |   3.92  |   2.32   |   4.8   |   7     |   4.03  |   5.82  |   1       |   4.38  |   4.83  |   3.34  |   4.64  |   6.44  |   4.37  |   4.14  |   4.65  |   6.18  |   6.39  |   5.76  |   4.12  |   7.62  |   5.35  |   1        |   3.87  |   2.18  |   1.91   |   7.98  |
|   0.5   |   0.49 |   0.52  |   0.54 |   0.47  |   0.55   |   0.5   |   0.47  |   0.5   |   0.51  |   3.09    |   0.48  |   0.43  |   0.44  |   0.39  |   0.5   |   0.57  |   0.47  |   0.43  |   0.5   |   0.52  |   0.52  |   0.51  |   0.56  |   0.48  |  24.56     |   0.39  |   0.79  |   0.47   |   0.54  |
| nan     | nan    | nan     | nan    | nan     | nan      | nan     | nan     | nan     | nan     | nan       | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan      | nan     |
| nan     | nan    | nan     | nan    | nan     | nan      | nan     | nan     | nan     | nan     | nan       | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan      | nan     |
| nan     | nan    | nan     | nan    | nan     | nan      | nan     | nan     | nan     | nan     | nan       | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan      | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([8, 8, 8, 8, 2, 2, 8, 8, 8, 2, 2, 2, 8, 8, 2, 8, 8, 2, 2, 8])
[2, 8]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([2, 8, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 8, 2, 8, 2, 8, 8, 8, 2])
[2, 8]
TARGETS AFTER CLEANER:  tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([2, 8, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 8, 2, 8, 2, 8, 8, 8, 2])
[2, 8]
TARGETS AFTER CLEANER:  tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_2C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.35e-01	time: 00:00:33	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:4.878e-03/SW:2.137e-01/MR:6.109e+00/SR:1.476e+00/MeD:1.149e+00/MaD:5.108e+00/MW:0.587/MAW:0.413
|         0 |         1 |        2 |         3 |         4 |       5 |        6 |         7 |        8 |        9 |       10 |       11 |     12 |      13 |       14 |       15 |       16 |       17 |       18 |       19 |       20 |        21 |        22 |       23 |         24 |       25 |       26 |        27 |       28 |       29 |
|-----------+-----------+----------+-----------+-----------+---------+----------+-----------+----------+----------+----------+----------+--------+---------+----------+----------+----------+----------+----------+----------+----------+-----------+-----------+----------+------------+----------+----------+-----------+----------+----------|
|   0.00888 |   0.00896 |   0.0118 |   0.00843 |   0.00727 |   0.011 |   0.0121 |   0.00621 |   0.0126 |   0.0114 |   0.0109 |   0.0112 |   0.01 |   0.012 |   0.0117 |   0.0121 |   0.0106 |   0.0112 |   0.0107 |   0.0102 |   0.0135 |   0.00927 |   0.00952 |   0.0123 |   6.21e-05 |   0.0124 |   0.0129 |   0.00987 |   0.0124 |   0.0094 |
|   4.15    |   4.21    |   6.59   |   3.84    |   3.12    |   5.8   |   6.89   |   2.54    |   7.4    |   6.18   |   5.77   |   6.04   |   5.01 |   6.76  |   6.51   |   6.86   |   5.48   |   6.06   |   5.56   |   5.17   |   8.27   |   4.44    |   4.63    |   7.08   |   1        |   7.18   |   7.64   |   4.9     |   7.15   |   4.53   |
|   0.29    |   0.11    |   0.13   |   0.2     |   0.28    |   0.21  |   0.21   |   0.24    |   0.17   |   0.12   |   0.23   |   0.27   |   0.17 |   0.18  |   0.18   |   0.15   |   0.13   |   0.18   |   0.13   |   0.2    |   0.16   |   0.28    |   0.28    |   0.19   |   9.62     |   0.38   |   0.14   |   0.18    |   0.08   |   0.17   |
| nan       | nan       | nan      | nan       | nan       | nan     | nan      | nan       | nan      | nan      | nan      | nan      | nan    | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan       | nan      | nan        | nan      | nan      | nan       | nan      | nan      |
| nan       | nan       | nan      | nan       | nan       | nan     | nan      | nan       | nan      | nan      | nan      | nan      | nan    | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan       | nan      | nan        | nan      | nan      | nan       | nan      | nan      |
| nan       | nan       | nan      | nan       | nan       | nan     | nan      | nan       | nan      | nan      | nan      | nan      | nan    | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan       | nan      | nan        | nan      | nan      | nan       | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([8, 8, 8, 8, 2, 2, 8, 8, 8, 2, 2, 2, 8, 8, 2, 8, 8, 2, 2, 8])
[2, 8]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([2, 8, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 8, 2, 8, 2, 8, 8, 8, 2])
[2, 8]
TARGETS AFTER CLEANER:  tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([2, 8, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 8, 2, 8, 2, 8, 8, 8, 2])
[2, 8]
TARGETS AFTER CLEANER:  tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_2C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.24e-02	time: 00:00:50	Acc_train 0.00	Acc_test 0.00	convergence: 1.81e+01	R1: 1	Info MB:0.000e+00/SB:0.000e+00/MW:3.378e-03/SW:3.278e-01/MR:1.911e+01/SR:2.533e+00/MeD:2.032e+00/MaD:1.810e+01/MW:0.441/MAW:0.559
|        0 |        1 |        2 |        3 |        4 |        5 |       6 |       7 |       8 |        9 |       10 |       11 |       12 |       13 |      14 |       15 |      16 |       17 |       18 |      19 |       20 |       21 |       22 |       23 |       24 |      25 |       26 |       27 |       28 |       29 |
|----------+----------+----------+----------+----------+----------+---------+---------+---------+----------+----------+----------+----------+----------+---------+----------+---------+----------+----------+---------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------|
|   0.0439 |   0.0435 |   0.0455 |   0.0428 |   0.0387 |   0.0408 |   0.045 |   0.038 |   0.042 |   0.0454 |   0.0438 |   0.0438 |   0.0435 |   0.0371 |   0.045 |   0.0437 |   0.047 |   0.0441 |   0.0372 |   0.043 |   0.0425 |   0.0385 |   0.0386 |   0.0432 |   0.0434 |   0.038 |   0.0413 |   0.0415 |   0.0406 |   0.0427 |
|  20.27   |  19.91   |  21.72   |  19.29   |  15.99   |  17.62   |  21.28  |  15.4   |  18.61  |  21.64   |  20.18   |  20.22   |  19.89   |  14.74   |  21.22  |  20.07   |  23.11  |  20.45   |  14.81   |  19.5   |  19.1    |  15.8    |  15.88   |  19.68   |  19.81   |  15.45  |  18.04   |  18.24   |  17.45   |  19.2    |
|   0.07   |   0.03   |   0.06   |   0.09   |   0.05   |   0.01   |   0.05  |   0.03  |   0.07  |   0.06   |   0.1    |   0.09   |   0.1    |   0.04   |   0.14  |   0.03   |   0.07  |   0.13   |   0.05   |   0.04  |   0.07   |   0.05   |   0.01   |   0.06   |   0.04   |   0.05  |   0.07   |   0.06   |   0.03   |   0.03   |
| nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan     | nan     | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan     | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan     | nan     | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan     | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan     | nan     | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan     | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models

 ********** Supervised learning of blocks [3] **********
SAVING FOLDER FOR SUP:  C10_2C_CL
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([8, 8, 8, 8, 2, 2, 8, 8, 8, 2, 2, 2, 8, 8, 2, 8, 8, 2, 2, 8])
[2, 8]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([2, 8, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 8, 2, 8, 2, 8, 8, 8, 2])
[2, 8]
TARGETS AFTER CLEANER:  tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([2, 8, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 8, 2, 8, 2, 8, 8, 8, 2])
[2, 8]
TARGETS AFTER CLEANER:  tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Epoch: [1/50]	lr: 1.00e-03	time: 00:01:05	Loss_train 0.15286	Acc_train 90.33	/	Loss_test 0.00585	Acc_test 93.10
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [10/50]	lr: 1.00e-03	time: 00:01:09	Loss_train 0.04870	Acc_train 96.35	/	Loss_test 0.00369	Acc_test 96.50
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [20/50]	lr: 2.50e-04	time: 00:01:14	Loss_train 0.01857	Acc_train 98.36	/	Loss_test 0.00335	Acc_test 97.10
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [30/50]	lr: 1.25e-04	time: 00:01:18	Loss_train 0.01070	Acc_train 98.83	/	Loss_test 0.00323	Acc_test 97.20
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [40/50]	lr: 3.13e-05	time: 00:01:22	Loss_train 0.00831	Acc_train 99.05	/	Loss_test 0.00335	Acc_test 96.95
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [50/50]	lr: 7.81e-06	time: 00:01:27	Loss_train 0.00757	Acc_train 99.07	/	Loss_test 0.00342	Acc_test 97.05
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
RESULT:  {'train_loss': 0.007571916561573744, 'train_acc': 99.07100200653076, 'test_loss': 0.0034159154165536165, 'test_acc': 97.05000305175781, 'convergence': 18.10685157775879, 'R1': 1, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [2, 8]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [2, 8]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}
IN R2:  {'R1': {'train_loss': 0.04612022638320923, 'train_acc': 93.5699999332428, 'test_loss': 0.0052311173640191555, 'test_acc': 91.4000015258789, 'convergence': 20.352340698242188, 'R1': 0, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [3, 6]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [3, 6]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}, 'R2': {'train_loss': 0.007571916561573744, 'train_acc': 99.07100200653076, 'test_loss': 0.0034159154165536165, 'test_acc': 97.05000305175781, 'convergence': 18.10685157775879, 'R1': 1, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [2, 8]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [2, 8]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.11048543456039805, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 2, 'in_channels': 24576, 'old_channels': 1536, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 Model C10_2C_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=2, bias=True)
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([3, 6, 6, 6, 3, 6, 6, 6, 6, 6, 3, 6, 3, 6, 3, 6, 3, 6, 3, 6])
[3, 6]
TARGETS AFTER CLEANER:  tensor([0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 3, 3, 6, 3, 6, 6, 6, 3, 3, 3, 3, 3, 3, 6, 3, 3, 3, 3, 6])
[3, 6]
TARGETS AFTER CLEANER:  tensor([1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 3, 3, 6, 3, 6, 6, 6, 3, 3, 3, 3, 3, 3, 6, 3, 3, 3, 3, 6])
[3, 6]
TARGETS AFTER CLEANER:  tensor([1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Accuracy of the network on the 1st dataset: 49.300 %
Test loss on the 1st dataset: 0.159

