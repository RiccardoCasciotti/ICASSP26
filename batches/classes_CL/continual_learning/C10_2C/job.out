--------------- /leonardo/prod/opt/modulefiles/deeplrn/libraries ---------------
cineca-ai/3.0.0  cineca-ai/4.0.0  cineca-ai/4.1.1(default)  
cineca-ai/3.0.1  cineca-ai/4.1.0  cineca-ai/4.3.0           

Key:
(symbolic-version)  
The device used will be: 
True
cuda:0
BLOCKS:  {'b0': {'arch': 'CNN', 'preset': 'softkrotov-c96-k5-p2-s1-d1-b0-t1-lr0.08-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 0, 'batch_norm': False, 'pool': {'type': 'max', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 0.7}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5}}, 'b1': {'arch': 'CNN', 'preset': 'softkrotov-c384-k3-p1-s1-d1-b0-t0.65-lr0.005-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 1, 'batch_norm': False, 'pool': {'type': 'max', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 1.4}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3}}, 'b2': {'arch': 'CNN', 'preset': 'softkrotov-c1536-k3-p1-s1-d1-b0-t0.25-lr0.01-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 2, 'batch_norm': False, 'pool': {'type': 'avg', 'kernel_size': 2, 'stride': 2, 'padding': 0}, 'activation': {'function': 'triangle', 'param': 1.0}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3}}, 'b3': {'arch': 'MLP', 'preset': 'BP-c10', 'operation': 'flatten', 'num': 3, 'att_dropout': None, 'dropout': 0.5, 'layer': {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.25, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10}, 'pool': None, 'activation': None}}
CL:  True
{'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True}
CL:  True
{'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}

 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=2, bias=True)
[Sequential(
  (0): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=0.7)
  )
  (1): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=1.4)
  )
  (2): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (activation): Triangle(power=1.0)
  )
  (3): BasicBlock(
    (operations): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
    )
    (layer): Linear(in_features=24576, out_features=2, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
)]
LAYER NAME:  Sequential(
  (0): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=0.7)
  )
  (1): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=1.4)
  )
  (2): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (activation): Triangle(power=1.0)
  )
  (3): BasicBlock(
    (operations): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
    )
    (layer): Linear(in_features=24576, out_features=2, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
)
LAYER CHILDREN:  [BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
  (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
  (activation): Triangle(power=0.7)
), BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
  (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
  (activation): Triangle(power=1.4)
), BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (activation): Triangle(power=1.0)
), BasicBlock(
  (operations): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
  )
  (layer): Linear(in_features=24576, out_features=2, bias=True)
  (dropout): Dropout(p=0.5, inplace=False)
)]
subsubl NAME:  Sequential(
  (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
subsubl NAME:  Triangle(power=0.7)
subsubl NAME:  Sequential(
  (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
subsubl NAME:  Triangle(power=1.4)
subsubl NAME:  Sequential(
  (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  AvgPool2d(kernel_size=2, stride=2, padding=0)
subsubl NAME:  Triangle(power=1.0)
subsubl NAME:  Sequential(
  (0): Flatten(start_dim=1, end_dim=-1)
)
subsubl NAME:  Linear(in_features=24576, out_features=2, bias=True)
subsubl NAME:  Dropout(p=0.5, inplace=False)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([0, 0, 9, 9, 0, 9, 0, 9, 9, 9, 0, 9, 9, 9, 0, 0, 9, 9, 0, 0])
[0, 9]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 9, 9, 9, 0, 0, 9, 0, 0, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9])
[0, 9]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 9, 9, 9, 0, 0, 9, 0, 0, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9])
[0, 9]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_2C_CL
DEPTH:  3
WTA IN delta_weight:  tensor([[[-3.3113e-30, -3.2928e-30, -6.0078e-30,  ..., -1.6437e-27,
          -1.0669e-31, -9.9924e-31],
         [-2.9133e-30, -1.2605e-30, -5.6454e-30,  ..., -3.9230e-33,
          -1.0312e-27, -8.1433e-32],
         [-1.0585e-30, -1.2633e-30, -3.3702e-30,  ..., -4.7083e-23,
          -1.2090e-23, -6.4507e-31],
         ...,
         [-9.0020e-30, -7.8514e-30, -2.4543e-29,  ..., -1.9157e-29,
          -1.8272e-29, -8.2049e-30],
         [-5.4322e-31, -4.4382e-31, -1.1733e-30,  ..., -1.2053e-30,
          -1.0935e-30, -6.2616e-31],
         [-3.3113e-30, -3.4913e-30, -7.3060e-30,  ..., -5.4776e-30,
          -5.7970e-30, -3.8458e-30]],

        [[-2.2909e-37, -1.7076e-37, -5.0545e-38,  ..., -2.5275e-35,
          -3.6920e-36, -2.8398e-36],
         [-7.4374e-38, -2.6079e-38, -1.5235e-38,  ..., -7.0063e-35,
          -4.5236e-35, -3.0437e-39],
         [-1.0030e-37, -1.0138e-37, -2.7711e-38,  ..., -2.2099e-29,
          -8.1572e-36, -2.4875e-39],
         ...,
         [-1.9495e-37, -1.1566e-37, -3.4713e-38,  ..., -1.1949e-37,
          -5.2418e-38, -1.7943e-37],
         [-6.6379e-38, -2.7026e-38, -8.5392e-39,  ..., -4.0957e-38,
          -1.6354e-38, -6.5319e-38],
         [-2.2909e-37, -1.4161e-37, -3.3381e-38,  ..., -1.3762e-37,
          -5.7053e-38, -2.4278e-37]],

        [[-2.8904e-35, -2.2260e-35, -1.0591e-35,  ..., -5.8730e-37,
          -1.0027e-36, -3.0095e-35],
         [-1.1009e-35, -5.2662e-36, -4.2189e-36,  ..., -1.0150e-35,
          -4.4510e-34, -5.6842e-36],
         [-2.1462e-35, -2.2633e-35, -1.1571e-35,  ..., -3.7184e-27,
          -1.4409e-33, -9.7490e-36],
         ...,
         [-5.5029e-35, -3.1271e-35, -2.0295e-35,  ..., -2.0195e-35,
          -3.2510e-35, -4.5749e-35],
         [-5.3929e-36, -3.4579e-36, -1.4432e-36,  ..., -1.9636e-36,
          -3.7425e-36, -6.0731e-36],
         [-2.8904e-35, -1.9121e-35, -8.3909e-36,  ..., -1.1650e-35,
          -1.7464e-35, -2.6208e-35]],

        ...,

        [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         ...,
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00]],

        [[-1.8134e-20, -2.4423e-20, -7.3781e-21,  ..., -2.1291e-23,
          -6.7796e-24, -1.6826e-22],
         [-3.0283e-21, -3.7059e-21, -1.2211e-21,  ..., -5.0981e-22,
          -3.5288e-22, -5.6514e-25],
         [-4.3975e-21, -9.3362e-21, -2.1744e-21,  ..., -1.5954e-16,
          -2.1857e-20, -1.4892e-24],
         ...,
         [-1.9104e-20, -2.3595e-20, -5.9696e-21,  ..., -7.3467e-21,
          -3.3442e-20, -1.5298e-20],
         [-9.4794e-22, -1.5600e-21, -2.0377e-22,  ..., -4.2281e-22,
          -2.0657e-21, -1.0283e-21],
         [-1.8134e-20, -1.8838e-20, -4.1141e-21,  ..., -5.8697e-21,
          -2.8273e-20, -1.6072e-20]],

        [[-1.6087e-42, -6.1797e-43, -1.1673e-42,  ..., -5.1848e-44,
          -4.2039e-45, -1.8930e-41],
         [-4.8485e-43, -1.3873e-43, -4.9746e-43,  ..., -6.3058e-44,
          -2.0837e-42, -2.5055e-42],
         [-2.4663e-43, -9.6690e-44, -2.2281e-43,  ..., -1.3130e-39,
          -7.5942e-39, -1.9245e-41],
         ...,
         [-1.3551e-42, -5.1708e-43, -9.8091e-43,  ..., -6.7823e-43,
          -1.0131e-42, -1.1673e-42],
         [-1.9758e-43, -5.7453e-44, -1.0370e-43,  ..., -9.3887e-44,
          -1.4574e-43, -2.0879e-43],
         [-1.6087e-42, -5.3530e-43, -8.1976e-43,  ..., -7.4269e-43,
          -1.0061e-42, -1.6171e-42]]], device='cuda:0')
LAYER_NUM:  0
FINAL_SUM:  [66, 34, 46, 26, 77, 91, 55, 43, 4, 30]
acts len:  1
acts keys:  ['conv0']
acts:  {'conv0': [66, 34, 46, 26, 77, 91, 55, 43, 4, 30, 11, 87, 92, 53, 40, 15, 39, 95, 84, 64, 35]}
final_sum len:  96
delta_weights INFO: 
NUM OF TRACKED COV LAYERS:  1
NUM OF TRACKED WEIGHTS CHANGES PER LAYER:  10
avg_deltas INFO:  <class 'dict'>
avg_deltas keys:  ['blocks.0.layer.weight']
avg_deltas size:  1
num of averages for 0 layer:  torch.Size([96])
################################################
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.45e-01	time: 00:00:22	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:6.485e-03/SW:5.718e-01/MR:4.644e+00/SR:1.728e+00/MeD:1.328e+00/MaD:4.314e+00/MW:0.623/MAW:0.377
|       0 |       1 |       2 |       3 |       4 |       5 |      6 |       7 |       8 |       9 |     10 |      11 |      12 |      13 |      14 |      15 |         16 |      17 |      18 |      19 |      20 |      21 |      22 |      23 |     24 |         25 |     26 |      27 |      28 |      29 |
|---------+---------+---------+---------+---------+---------+--------+---------+---------+---------+--------+---------+---------+---------+---------+---------+------------+---------+---------+---------+---------+---------+---------+---------+--------+------------+--------+---------+---------+---------|
|   0.127 |   0.146 |   0.117 |   0.158 |   0.132 |   0.109 |   0.16 |   0.172 |   0.145 |   0.226 |   0.16 |   0.146 |   0.124 |   0.129 |   0.149 |   0.179 |   0.000394 |   0.127 |   0.161 |   0.185 |   0.195 |   0.169 |   0.127 |   0.179 |   0.16 |   0.000317 |   0.17 |   0.177 |   0.118 |   0.199 |
|   3.52  |   4.34  |   3.15  |   4.92  |   3.72  |   2.86  |   5.01 |   5.61  |   4.3   |   8.96  |   4.99 |   4.31  |   3.42  |   3.59  |   4.49  |   6.03  |   1        |   3.5   |   5.06  |   6.37  |   6.97  |   5.44  |   3.51  |   6.01  |   5.01 |   1        |   5.54 |   5.88  |   3.19  |   7.17  |
|   0.54  |   0.51  |   0.45  |   0.49  |   0.85  |   1.16  |   0.52 |   0.38  |   0.67  |   0.51  |   0.91 |   0.51  |   0.56  |   0.41  |   0.7   |   0.46  |  15.86     |   0.51  |   0.51  |   0.66  |   0.58  |   0.68  |   0.51  |   0.47  |   0.47 |  15.99     |   0.44 |   0.85  |   0.45  |   0.55  |
| nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan        | nan    | nan     | nan     | nan     |
| nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan        | nan    | nan     | nan     | nan     |
| nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan        | nan    | nan     | nan     | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([0, 0, 9, 9, 0, 9, 0, 9, 9, 9, 0, 9, 9, 9, 0, 0, 9, 9, 0, 0])
[0, 9]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 9, 9, 9, 0, 0, 9, 0, 0, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9])
[0, 9]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 9, 9, 9, 0, 0, 9, 0, 0, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9])
[0, 9]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_2C_CL
DEPTH:  3
ACTIVATIONS SHAPE:  tensor([[-8.3445e+01, -8.3359e+01, -5.9403e+01, -9.3091e+01, -7.4481e+01,
         -3.8906e+01, -1.7674e+01, -4.8725e+01, -1.3285e+02, -1.7550e+02,
         -1.9565e+02, -1.8679e+02, -1.7607e+02, -1.6870e+02, -1.9575e+02,
         -1.6465e+02],
        [-8.4987e+01, -8.7286e+01, -7.8636e+01, -1.1323e+02, -8.5292e+01,
         -5.2294e+01, -5.0219e+00, -1.5636e+01, -6.2581e+01, -8.1062e+01,
         -1.5874e+02, -1.6614e+02, -9.2983e+01, -1.0629e+02, -1.9528e+02,
         -1.1866e+02],
        [-5.3139e+01, -4.4004e+01, -1.9154e+01, -9.1173e+01, -9.5940e+01,
         -2.5557e+00,  6.5622e+00, -4.2806e+01, -1.1451e+02, -9.7358e+01,
         -1.2492e+02, -1.0600e+02, -6.6459e+01, -9.8043e+01, -1.9454e+02,
         -1.4098e+02],
        [-9.5051e+00, -5.2935e+00,  6.6886e+00, -5.6994e+01, -5.1135e+01,
         -2.1203e+01, -2.4039e+01, -8.2722e+01, -8.1033e+01, -6.4741e+01,
         -7.0136e+01, -6.2080e+01, -1.1705e+02, -9.9668e+01, -1.8506e+02,
         -1.5714e+02],
        [-2.8466e+01, -3.8085e+01,  7.9055e-01, -6.6064e+01, -1.6835e+02,
         -1.0713e+02, -2.1604e+01,  5.5774e+01, -4.2862e+01, -7.1947e+01,
         -1.1995e+02, -7.9612e+01, -1.3919e+02, -1.4918e+02, -1.9413e+02,
         -1.3976e+02],
        [ 1.4502e+01,  4.3505e+01,  2.0199e+01, -8.8256e+01, -1.5306e+02,
         -1.7578e+02, -1.2221e+02,  1.5899e+01, -3.4273e+01, -9.0447e+01,
         -1.6886e+02, -1.8584e+02, -2.0288e+02, -2.0150e+02, -2.7024e+02,
         -2.1614e+02],
        [ 1.5234e+01, -4.3914e+01, -4.1361e+01, -1.0349e+02, -3.2088e+01,
         -3.2227e+01, -1.3464e-01,  2.1736e+01, -3.9936e+01, -1.3210e+02,
         -1.7144e+02, -1.7671e+02, -2.1421e+02, -2.0147e+02, -2.4913e+02,
         -1.9324e+02],
        [-5.3808e+00, -3.4512e+01, -3.0240e+01,  2.2979e+01,  2.7148e+01,
          4.5517e+01,  8.7974e+01,  1.4709e+01,  1.1109e+02,  5.2154e+01,
         -1.0874e+02, -2.0616e+02, -2.2278e+02, -1.8399e+02, -1.1804e+02,
         -1.0082e+02],
        [-1.7108e+02, -8.6656e+01, -9.3743e+01, -6.2244e+01, -1.3796e+01,
          7.2902e+01,  1.6111e+02,  8.0298e+01,  1.3256e+02,  5.6858e+01,
         -1.7554e+02, -2.0200e+02, -2.2485e+02, -1.8112e+02, -7.5674e+01,
         -1.2623e+02],
        [-6.6690e+01, -1.1821e+02, -1.2591e+02, -1.1942e+02, -2.4165e+01,
          1.6715e+01,  9.4826e+01,  1.4991e+02,  1.2491e+02, -1.3559e+01,
         -2.1099e+02, -2.5891e+02, -2.2286e+02, -2.1854e+02, -1.5553e+02,
         -1.2082e+02],
        [ 1.0123e+01, -7.4580e+01, -6.1473e+01, -1.5236e+01, -2.1656e+01,
          5.6788e+00,  4.2663e+01,  9.3508e+01,  1.3748e+01, -2.2941e+01,
         -1.6281e+02, -1.7434e+02, -2.2031e+02, -2.7508e+02, -2.2813e+02,
         -1.8613e+02],
        [-3.1251e+00, -6.3749e+01, -1.0062e+02, -4.1702e+01,  2.8537e+00,
         -2.6696e+01, -1.4381e+01, -1.7383e+01,  5.0880e+01,  2.1254e+01,
         -8.2270e+01, -7.9068e+01, -1.6707e+02, -2.4294e+02, -2.3566e+02,
         -1.6238e+02],
        [ 4.2105e+01,  5.9567e+00, -3.4288e+01, -6.9111e+01, -7.9347e+01,
         -3.0280e+01, -2.2136e+01, -3.8273e+00, -1.3461e+01, -1.7640e+01,
         -7.0967e+01, -1.4562e+02, -1.6227e+02, -1.5794e+02, -1.5989e+02,
         -1.5114e+02],
        [ 3.3282e+01,  1.7047e+01,  4.4210e+00, -1.7718e+01, -6.8759e+01,
         -6.4151e+01, -1.1204e+01,  5.6012e+00,  2.6420e+01,  2.0713e+01,
         -3.0555e+01, -7.7923e+01, -7.1418e+01, -1.1149e+02, -1.4085e+02,
         -1.1275e+02],
        [ 5.5828e+01,  1.9942e+01, -1.1761e+01, -2.7007e+01, -4.7317e+01,
         -6.8046e+01, -4.6909e+01, -2.0461e+01, -1.5603e+01, -3.3999e+01,
         -4.1226e+01, -9.1602e+01, -9.6554e+01, -1.1959e+02, -8.7531e+01,
         -8.7381e+01],
        [ 9.3881e+00, -2.9493e+01, -4.7194e+01, -3.2683e+01,  1.1858e+00,
         -2.3677e+01, -7.3357e+01, -9.4731e+01, -1.0742e+02, -7.2049e+01,
         -8.0284e+01, -1.3190e+02, -8.5166e+01, -1.4199e+02, -1.4369e+02,
         -8.0216e+01]], device='cuda:0')
LAYER_NUM:  1
FINAL_SUM:  [204, 8, 59, 243, 259, 359, 175, 164, 66, 61]
acts len:  2
acts keys:  ['conv0', 'conv1']
acts:  {'conv0': [26, 43, 87, 46, 91, 34, 55, 77, 35, 66, 4, 67, 84, 53, 15, 30, 29, 11, 39, 92, 56], 'conv1': [204, 8, 59, 243, 259, 359, 175, 164, 66, 61, 247, 260, 49, 116, 291, 115, 351, 151, 147, 174, 324]}
final_sum len:  384
delta_weights INFO: 
NUM OF TRACKED COV LAYERS:  1
NUM OF TRACKED WEIGHTS CHANGES PER LAYER:  10
avg_deltas INFO:  <class 'dict'>
avg_deltas keys:  ['blocks.0.layer.weight', 'blocks.1.layer.weight']
avg_deltas size:  2
num of averages for 1 layer:  torch.Size([96])
################################################
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.45e-01	time: 00:00:40	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.487e-03/SW:3.379e-01/MR:9.767e+00/SR:1.800e+00/MeD:1.395e+00/MaD:8.416e+00/MW:0.579/MAW:0.421
|        0 |        1 |        2 |        3 |         4 |        5 |        6 |        7 |        8 |       9 |       10 |       11 |       12 |       13 |       14 |       15 |      16 |       17 |       18 |       19 |       20 |       21 |       22 |       23 |       24 |       25 |       26 |       27 |      28 |       29 |
|----------+----------+----------+----------+-----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------|
|   0.0154 |   0.0141 |   0.0144 |   0.0138 |   0.00794 |   0.0131 |   0.0145 |   0.0133 |   0.0148 |   0.016 |   0.0142 |   0.0157 |   0.0156 |   0.0174 |   0.0162 |   0.0152 |   0.016 |   0.0154 |   0.0113 |   0.0131 |   0.0155 |   0.0164 |   0.0149 |   0.0167 |   0.0115 |   0.0167 |   0.0142 |   0.0129 |   0.015 |   0.0149 |
|  10.44   |   8.96   |   9.26   |   8.66   |   3.52    |   7.81   |   9.35   |   8.1    |   9.74   |  11.22  |   9.12   |  10.87   |  10.77   |  13.09   |  11.52   |  10.19   |  11.21  |  10.53   |   6.11   |   7.84   |  10.55   |  11.72   |   9.83   |  12.19   |   6.3    |  12.22   |   9.03   |   7.68   |  10     |   9.87   |
|   0.21   |   0.21   |   0.21   |   0.24   |   1.23    |   0.31   |   0.26   |   0.26   |   0.19   |   0.16  |   0.2    |   0.25   |   0.21   |   0.16   |   0.16   |   0.18   |   0.14  |   0.3    |   0.35   |   0.26   |   0.16   |   0.25   |   0.59   |   0.17   |   0.94   |   0.39   |   0.15   |   0.25   |   0.18  |   0.29   |
| nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      |
| nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      |
| nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([0, 0, 9, 9, 0, 9, 0, 9, 9, 9, 0, 9, 9, 9, 0, 0, 9, 9, 0, 0])
[0, 9]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 9, 9, 9, 0, 0, 9, 0, 0, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9])
[0, 9]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 9, 9, 9, 0, 0, 9, 0, 0, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9])
[0, 9]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_2C_CL
DEPTH:  3
ACTIVATIONS SHAPE:  tensor([[-7.4402e+00, -6.3089e+00,  4.1032e+00, -1.0016e+01, -1.3708e+00,
          1.9722e+01,  3.3597e+01,  1.7285e+01, -2.2252e+01, -3.1660e+01,
         -3.5912e+01, -3.1998e+01, -2.8511e+01, -2.1591e+01, -3.0079e+01,
         -2.2712e+01],
        [-7.2618e+00, -9.0046e+00, -5.2255e+00, -1.8389e+01, -2.2824e+00,
          1.7205e+01,  3.9800e+01,  3.5758e+01,  1.0444e+01,  7.7609e+00,
         -2.2671e+01, -2.1255e+01,  7.6699e+00, -2.9392e+00, -3.5020e+01,
         -1.2743e+01],
        [ 6.9838e+00,  8.4185e+00,  2.0598e+01, -7.5966e+00, -6.8727e+00,
          4.3203e+01,  4.9125e+01,  2.4585e+01, -7.7163e+00,  3.6185e-01,
         -8.5757e+00,  2.5105e+00,  1.3601e+01,  6.6597e+00, -3.6737e+01,
         -1.6810e+01],
        [ 3.0635e+01,  3.0492e+01,  3.7669e+01,  1.2818e+01,  1.9839e+01,
          3.4362e+01,  3.4678e+01,  1.2405e+01,  7.6718e+00,  1.0424e+01,
          1.0296e+01,  1.5677e+01, -7.7738e+00, -8.0521e-02, -3.1071e+01,
         -2.6645e+01],
        [ 2.4085e+01,  1.2742e+01,  3.8854e+01,  1.2925e+01, -2.7400e+01,
         -1.8579e+00,  3.4196e+01,  6.8029e+01,  2.5165e+01,  1.1424e+01,
         -3.6460e+00,  7.7430e+00, -1.3604e+01, -2.3388e+01, -3.7990e+01,
         -1.9654e+01],
        [ 4.2410e+01,  4.4321e+01,  3.7398e+01, -7.2926e+00, -3.4683e+01,
         -3.5101e+01, -7.8971e+00,  4.4535e+01,  2.5957e+01, -7.9112e+00,
         -4.1894e+01, -3.8307e+01, -3.9525e+01, -4.4187e+01, -7.2098e+01,
         -5.3122e+01],
        [ 4.3845e+01,  1.3893e+01,  5.0360e+00, -2.2046e+01,  1.0072e+01,
          1.4166e+01,  2.8832e+01,  4.0985e+01,  8.1797e+00, -3.5542e+01,
         -4.8112e+01, -3.8670e+01, -5.4019e+01, -5.0966e+01, -6.5202e+01,
         -4.7590e+01],
        [ 4.1238e+01,  1.6116e+01,  2.1223e+01,  3.7602e+01,  4.1693e+01,
          5.3566e+01,  5.9804e+01,  2.8414e+01,  6.3227e+01,  4.0725e+01,
         -2.1714e+01, -5.5482e+01, -5.5437e+01, -4.1890e+01, -1.1610e+01,
         -9.9602e+00],
        [-1.9057e+01,  1.6553e+00,  4.8772e+00,  1.8000e+01,  3.2345e+01,
          6.2616e+01,  9.0126e+01,  5.1629e+01,  7.3418e+01,  4.4299e+01,
         -5.3722e+01, -5.6558e+01, -6.1009e+01, -3.3002e+01,  7.6278e+00,
         -1.8335e+01],
        [ 1.3049e+01, -2.0119e+01, -1.3929e+01, -1.1292e+01,  2.9418e+01,
          3.8579e+01,  6.2928e+01,  7.7895e+01,  6.4162e+01,  7.2407e-02,
         -7.8643e+01, -8.7919e+01, -6.8553e+01, -5.8162e+01, -3.1588e+01,
         -2.7706e+01],
        [ 2.0351e+01, -1.4467e+01, -2.5703e+00,  2.2290e+01,  2.1107e+01,
          2.8408e+01,  3.4992e+01,  4.3668e+01,  9.1727e+00, -1.5323e+01,
         -6.3001e+01, -5.9121e+01, -6.8975e+01, -8.6087e+01, -6.7065e+01,
         -5.3116e+01],
        [ 1.1277e+01, -8.6891e+00, -1.3255e+01,  1.0780e+01,  2.3681e+01,
          1.2032e+01,  1.0696e+01,  1.5074e+00,  2.7035e+01,  1.3040e+01,
         -1.8727e+01, -1.2219e+01, -4.6795e+01, -7.5173e+01, -7.2653e+01,
         -4.5575e+01],
        [ 3.4420e+01,  1.9998e+01,  6.3883e+00, -5.4551e+00, -1.4626e+01,
          7.0085e+00,  1.0966e+01,  1.5803e+01,  5.7494e+00,  9.8361e+00,
         -9.7630e+00, -3.5997e+01, -4.3270e+01, -4.3136e+01, -3.8460e+01,
         -3.2645e+01],
        [ 3.1598e+01,  2.4271e+01,  1.7915e+01,  6.9003e+00, -6.9887e+00,
         -3.0095e+00,  1.6417e+01,  2.1674e+01,  3.1175e+01,  3.2098e+01,
          1.0161e+01, -5.1917e+00, -2.1658e+00, -2.2026e+01, -2.4268e+01,
         -1.1814e+01],
        [ 3.8077e+01,  2.3260e+01,  1.1872e+01,  4.8646e+00,  2.3064e+00,
         -3.0757e+00,  3.2969e+00,  7.9998e+00,  1.6957e+01,  1.1501e+01,
          1.2465e+01, -9.4927e+00, -1.1811e+01, -1.8784e+01, -3.2020e-02,
         -3.3992e+00],
        [ 2.0752e+01,  4.6008e+00, -4.0132e+00,  2.1191e+00,  2.0038e+01,
          1.4692e+01, -5.6745e+00, -1.5515e+01, -1.7805e+01,  2.0008e+00,
         -5.0275e+00, -2.6149e+01, -8.8603e+00, -3.5295e+01, -2.9871e+01,
         -5.1058e+00]], device='cuda:0')
LAYER_NUM:  2
FINAL_SUM:  [660, 1323, 888, 1082, 268, 332, 193, 1458, 269, 882]
acts len:  3
acts keys:  ['conv0', 'conv1', 'conv2']
acts:  {'conv0': [26, 43, 87, 46, 91, 34, 55, 77, 35, 66, 4, 67, 84, 53, 15, 30, 29, 11, 39, 92, 56], 'conv1': [8, 61, 59, 247, 78, 63, 204, 147, 175, 116, 351, 49, 19, 324, 46, 66, 254, 71, 243, 120, 115], 'conv2': [660, 1323, 888, 1082, 268, 332, 193, 1458, 269, 882, 1371, 108, 75, 196, 1412, 998, 205, 503, 1066, 451, 847]}
final_sum len:  1536
delta_weights INFO: 
NUM OF TRACKED COV LAYERS:  1
NUM OF TRACKED WEIGHTS CHANGES PER LAYER:  10
avg_deltas INFO:  <class 'dict'>
avg_deltas keys:  ['blocks.0.layer.weight', 'blocks.1.layer.weight', 'blocks.2.layer.weight']
avg_deltas size:  3
num of averages for 2 layer:  torch.Size([96])
################################################
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.52e-02	time: 00:00:58	Acc_train 0.00	Acc_test 0.00	convergence: 2.06e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.001e-03/SW:3.701e-01/MR:2.155e+01/SR:2.966e+00/MeD:2.332e+00/MaD:2.038e+01/MW:0.450/MAW:0.550
|        0 |       1 |        2 |        3 |        4 |        5 |        6 |        7 |        8 |        9 |       10 |       11 |      12 |       13 |       14 |       15 |       16 |       17 |       18 |       19 |       20 |       21 |       22 |       23 |       24 |       25 |       26 |       27 |       28 |       29 |
|----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------|
|   0.0489 |   0.042 |   0.0444 |   0.0462 |   0.0457 |   0.0422 |   0.0461 |   0.0409 |   0.0479 |   0.0476 |   0.0439 |   0.0484 |   0.046 |   0.0382 |   0.0462 |   0.0442 |   0.0453 |   0.0515 |   0.0507 |   0.0445 |   0.0479 |   0.0458 |   0.0232 |   0.0444 |   0.0444 |   0.0352 |   0.0476 |   0.0448 |   0.0422 |   0.0458 |
|  24.96   |  18.66  |  20.73   |  22.34   |  21.91   |  18.78   |  22.21   |  17.72   |  23.96   |  23.65   |  20.23   |  24.39   |  22.15  |  15.61   |  22.35   |  20.54   |  21.49   |  27.5    |  26.68   |  20.81   |  23.98   |  21.97   |   6.37   |  20.67   |  20.72   |  13.37   |  23.67   |  21.11   |  18.85   |  22.02   |
|   0.04   |   0.06  |   0.07   |   0.03   |   0.03   |   0.04   |   0.06   |   0.05   |   0.06   |   0.03   |   0.1    |   0.07   |   0.15  |   0.09   |   0.19   |   0.04   |   0.04   |   0.07   |   0.08   |   0.04   |   0.05   |   0.05   |   0.58   |   0.05   |   0.05   |   0.09   |   0.05   |   0.07   |   0.05   |   0.03   |
| nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models

 ********** Supervised learning of blocks [3] **********
SAVING FOLDER FOR SUP:  C10_2C_CL
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([0, 0, 9, 9, 0, 9, 0, 9, 9, 9, 0, 9, 9, 9, 0, 0, 9, 9, 0, 0])
[0, 9]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 9, 9, 9, 0, 0, 9, 0, 0, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9])
[0, 9]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 9, 9, 9, 0, 0, 9, 0, 0, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9])
[0, 9]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Epoch: [1/50]	lr: 1.00e-03	time: 00:01:13	Loss_train 0.18101	Acc_train 86.83	/	Loss_test 0.00285	Acc_test 91.70
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [10/50]	lr: 1.00e-03	time: 00:01:17	Loss_train 0.05442	Acc_train 93.59	/	Loss_test 0.00503	Acc_test 93.35
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [20/50]	lr: 2.50e-04	time: 00:01:22	Loss_train 0.03185	Acc_train 96.47	/	Loss_test 0.00456	Acc_test 94.45
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [30/50]	lr: 1.25e-04	time: 00:01:26	Loss_train 0.02132	Acc_train 97.29	/	Loss_test 0.00414	Acc_test 94.80
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [40/50]	lr: 3.13e-05	time: 00:01:31	Loss_train 0.01669	Acc_train 97.67	/	Loss_test 0.00423	Acc_test 94.55
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [50/50]	lr: 7.81e-06	time: 00:01:35	Loss_train 0.01459	Acc_train 97.86	/	Loss_test 0.00418	Acc_test 94.75
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
RESULT:  {'train_loss': 0.014591929502785206, 'train_acc': 97.86199927330017, 'test_loss': 0.004178447648882866, 'test_acc': 94.75, 'convergence': 20.554641723632812, 'R1': 0, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [0, 9]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [0, 9]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}
IN R1:  {'R1': {'train_loss': 0.014591929502785206, 'train_acc': 97.86199927330017, 'test_loss': 0.004178447648882866, 'test_acc': 94.75, 'convergence': 20.554641723632812, 'R1': 0, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [0, 9]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [0, 9]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}

 Model C10_2C_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=2, bias=True)
[Sequential(
  (0): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=0.7)
  )
  (1): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=1.4)
  )
  (2): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (activation): Triangle(power=1.0)
  )
  (3): BasicBlock(
    (operations): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
    )
    (layer): Linear(in_features=24576, out_features=2, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
)]
LAYER NAME:  Sequential(
  (0): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=0.7)
  )
  (1): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=1.4)
  )
  (2): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (activation): Triangle(power=1.0)
  )
  (3): BasicBlock(
    (operations): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
    )
    (layer): Linear(in_features=24576, out_features=2, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
)
LAYER CHILDREN:  [BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
  (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
  (activation): Triangle(power=0.7)
), BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
  (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
  (activation): Triangle(power=1.4)
), BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (activation): Triangle(power=1.0)
), BasicBlock(
  (operations): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
  )
  (layer): Linear(in_features=24576, out_features=2, bias=True)
  (dropout): Dropout(p=0.5, inplace=False)
)]
subsubl NAME:  Sequential(
  (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
subsubl NAME:  Triangle(power=0.7)
subsubl NAME:  Sequential(
  (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
subsubl NAME:  Triangle(power=1.4)
subsubl NAME:  Sequential(
  (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  AvgPool2d(kernel_size=2, stride=2, padding=0)
subsubl NAME:  Triangle(power=1.0)
subsubl NAME:  Sequential(
  (0): Flatten(start_dim=1, end_dim=-1)
)
subsubl NAME:  Linear(in_features=24576, out_features=2, bias=True)
subsubl NAME:  Dropout(p=0.5, inplace=False)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([1, 1, 4, 4, 4, 4, 1, 4, 4, 1, 1, 1, 4, 4, 1, 1, 4, 1, 4, 1])
[1, 4]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([4, 1, 1, 4, 4, 4, 1, 4, 1, 1, 1, 4, 1, 1, 1, 1, 4, 1, 1, 4])
[1, 4]
TARGETS AFTER CLEANER:  tensor([1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([4, 1, 1, 4, 4, 4, 1, 4, 1, 1, 1, 4, 1, 1, 1, 1, 4, 1, 1, 4])
[1, 4]
TARGETS AFTER CLEANER:  tensor([1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_2C_CL
DEPTH:  3
ACTIVATIONS SHAPE:  tensor([[ 7.8008e+02, -4.3230e+01,  1.6820e+01, -5.6488e+02, -7.1223e+02,
         -8.3492e+02, -8.5542e+02, -8.5274e+02, -9.8192e+02, -1.2252e+03,
         -1.3881e+03, -1.4351e+03, -1.2945e+03, -9.3247e+02, -7.4671e+02,
          3.9242e+02],
        [ 1.5169e+03,  9.4923e+02,  8.2981e+02, -2.2443e+01, -1.8526e+01,
         -6.4048e+01, -2.0967e+02, -3.3478e+02, -4.3168e+02, -5.3458e+02,
         -9.0661e+02, -1.0227e+03, -9.1921e+02, -5.6134e+02, -4.5410e+02,
          1.0184e+03],
        [ 1.5940e+03,  6.4551e+02,  4.6653e+02, -2.7408e+02, -5.7181e+01,
         -6.2005e+01, -9.1847e+01, -3.7663e+02, -5.0051e+02, -7.0384e+02,
         -1.2327e+03, -1.2132e+03, -1.0343e+03, -6.9360e+02, -8.3617e+02,
          1.0220e+03],
        [ 1.8245e+03,  3.7745e+02,  6.4579e+02, -1.0180e+02,  1.2790e+02,
          2.1839e+02,  1.3795e+02,  1.5825e+00, -1.1813e+02, -4.5628e+02,
         -1.0251e+03, -1.1013e+03, -9.0491e+02, -1.0924e+03, -1.2996e+03,
          8.1824e+02],
        [ 2.0738e+03,  4.9841e+02,  1.1081e+03,  1.7722e+02,  1.2311e+02,
          1.6874e+02,  1.2951e+02,  2.8390e+02,  2.1603e+02, -3.3049e+02,
         -8.7945e+02, -9.8613e+02, -9.5366e+02, -1.4507e+03, -1.8281e+03,
          7.5137e+02],
        [ 1.9845e+03,  3.7465e+02,  8.1025e+02,  2.0443e+02, -8.7621e+01,
         -2.3318e+00,  3.6764e+01,  2.4197e+02,  1.1878e+02, -2.0451e+02,
         -6.5861e+02, -1.0531e+03, -1.3266e+03, -1.6271e+03, -1.8274e+03,
          5.2047e+02],
        [ 2.0755e+03,  4.0882e+02,  8.8169e+02, -9.7683e+01, -3.5403e+02,
         -2.4219e+02,  1.0242e+02,  3.6425e+02,  8.5681e+01, -4.3210e+02,
         -7.3478e+02, -8.2035e+02, -1.2459e+03, -1.5638e+03, -1.8186e+03,
          5.0882e+02],
        [ 2.7740e+03,  9.2045e+02,  1.3663e+03,  2.3041e+02, -2.3322e+02,
         -2.4539e+01,  2.3210e+02,  1.6696e+02, -9.1941e+00, -5.6649e+02,
         -8.5722e+02, -1.0954e+03, -1.3749e+03, -1.4114e+03, -1.6499e+03,
          5.1530e+02],
        [ 3.4953e+03,  1.4251e+03,  2.1740e+03,  5.7443e+02, -3.7889e+00,
         -1.1450e+02,  1.5207e+02,  1.2727e+02, -2.8079e+02, -9.9866e+02,
         -9.8926e+02, -1.3419e+03, -1.4229e+03, -1.4622e+03, -1.7370e+03,
          5.6280e+02],
        [ 3.2505e+03,  1.0402e+03,  1.9277e+03,  7.8620e+02, -2.5160e+01,
         -6.7776e+02, -6.4043e+02, -5.9240e+02, -6.8432e+02, -9.0469e+02,
         -1.0327e+03, -1.2367e+03, -1.2091e+03, -1.2996e+03, -1.9164e+03,
          8.8401e+02],
        [ 3.1627e+03,  1.1306e+03,  2.0582e+03,  9.8054e+02,  5.7024e+01,
         -6.3357e+02, -4.6858e+02, -6.3341e+02, -7.4016e+02, -9.4230e+02,
         -9.5009e+02, -1.0044e+03, -7.8694e+02, -1.1782e+03, -1.8973e+03,
          8.8137e+02],
        [ 3.1841e+03,  1.1442e+03,  2.4298e+03,  1.8157e+03,  1.0572e+03,
          4.1151e+02,  9.4385e+01,  1.9395e+02,  3.1040e+02, -2.1140e+00,
         -3.0727e+02, -5.2889e+02, -6.2996e+02, -1.0025e+03, -1.5722e+03,
          5.2997e+02],
        [ 3.0032e+03,  1.5901e+03,  2.8065e+03,  2.4585e+03,  1.7239e+03,
          1.2199e+03,  7.9570e+02,  9.4242e+02,  9.1605e+02,  6.6290e+02,
          2.8995e+02,  2.7279e+02,  6.6101e+01, -4.3258e+02, -9.9117e+02,
          7.3398e+02],
        [ 2.9682e+03,  1.6773e+03,  2.9362e+03,  2.6917e+03,  1.7000e+03,
          1.5503e+03,  1.2737e+03,  1.1633e+03,  1.2354e+03,  9.7064e+02,
          8.1172e+02,  7.6608e+02,  7.0125e+02,  3.4014e+02, -3.8111e+02,
          1.2200e+03],
        [ 2.9161e+03,  2.0414e+03,  3.0974e+03,  2.7098e+03,  2.3583e+03,
          2.0043e+03,  1.7745e+03,  1.6744e+03,  1.5465e+03,  1.3761e+03,
          1.2264e+03,  1.4322e+03,  1.4382e+03,  1.3303e+03,  8.8691e+02,
          2.0316e+03],
        [ 6.9401e+02, -3.6415e+00,  7.0217e+02,  2.6046e+02, -2.9614e+02,
         -4.8120e+02, -8.3041e+02, -1.0090e+03, -1.1650e+03, -1.5390e+03,
         -1.4909e+03, -1.1890e+03, -1.0938e+03, -1.1602e+03, -1.4661e+03,
         -9.3198e+01]], device='cuda:0')
LAYER_NUM:  0
FINAL_SUM:  [29, 43, 25, 66, 67, 26, 75, 87, 84, 77]
acts len:  3
acts keys:  ['conv0', 'conv1', 'conv2']
acts:  {'conv0': [29, 43, 25, 66, 67, 26, 75, 87, 84, 77, 55, 91, 46, 15, 10, 41, 4, 92, 74, 5, 19], 'conv1': [8, 61, 59, 247, 78, 63, 204, 147, 175, 116, 351, 49, 19, 324, 46, 66, 254, 71, 243, 120, 115], 'conv2': [268, 1323, 737, 660, 108, 1371, 1005, 451, 1412, 128, 196, 888, 205, 870, 75, 1039, 1174, 730, 325, 301, 272]}
final_sum len:  96
delta_weights INFO: 
NUM OF TRACKED COV LAYERS:  1
NUM OF TRACKED WEIGHTS CHANGES PER LAYER:  10
avg_deltas INFO:  <class 'dict'>
avg_deltas keys:  ['blocks.0.layer.weight', 'blocks.1.layer.weight', 'blocks.2.layer.weight']
avg_deltas size:  3
num of averages for 0 layer:  torch.Size([96])
################################################
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.33e-01	time: 00:00:18	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.023e-02/SW:4.983e-01/MR:4.086e+00/SR:1.397e+00/MeD:1.062e+00/MaD:3.214e+00/MW:0.585/MAW:0.415
|      0 |       1 |      2 |       3 |       4 |       5 |       6 |      7 |       8 |       9 |        10 |      11 |      12 |      13 |      14 |      15 |         16 |      17 |      18 |      19 |      20 |      21 |      22 |      23 |      24 |         25 |      26 |      27 |      28 |      29 |
|--------+---------+--------+---------+---------+---------+---------+--------+---------+---------+-----------+---------+---------+---------+---------+---------+------------+---------+---------+---------+---------+---------+---------+---------+---------+------------+---------+---------+---------+---------|
|   0.06 |   0.113 |   0.13 |   0.155 |   0.134 |   0.112 |   0.137 |   0.15 |   0.135 |   0.166 |   0.00266 |   0.135 |   0.122 |   0.112 |   0.153 |   0.156 |   0.000296 |   0.157 |   0.153 |   0.163 |   0.188 |   0.145 |   0.153 |   0.171 |   0.167 |   0.000317 |   0.153 |   0.188 |   0.134 |   0.167 |
|   1.56 |   3     |   3.63 |   4.78  |   3.82  |   2.97  |   3.94  |   4.53 |   3.87  |   5.33  |   1       |   3.85  |   3.33  |   2.96  |   4.67  |   4.83  |   1        |   4.87  |   4.64  |   5.16  |   6.5   |   4.29  |   4.65  |   5.57  |   5.36  |   1        |   4.64  |   6.51  |   3.79  |   5.37  |
|   0.56 |   0.52  |   0.59 |   0.61  |   0.58  |   0.57  |   0.38  |   0.52 |   0.61  |   0.47  |   1.96    |   0.56  |   0.58  |   0.58  |   0.54  |   0.48  |  18.46     |   0.6   |   0.48  |   0.52  |   0.61  |   0.48  |   0.52  |   0.55  |   0.52  |  24.84     |   0.37  |   0.4   |   0.53  |   0.57  |
| nan    | nan     | nan    | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan       | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     |
| nan    | nan     | nan    | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan       | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     |
| nan    | nan     | nan    | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan       | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([1, 1, 4, 4, 4, 4, 1, 4, 4, 1, 1, 1, 4, 4, 1, 1, 4, 1, 4, 1])
[1, 4]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([4, 1, 1, 4, 4, 4, 1, 4, 1, 1, 1, 4, 1, 1, 1, 1, 4, 1, 1, 4])
[1, 4]
TARGETS AFTER CLEANER:  tensor([1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([4, 1, 1, 4, 4, 4, 1, 4, 1, 1, 1, 4, 1, 1, 1, 1, 4, 1, 1, 4])
[1, 4]
TARGETS AFTER CLEANER:  tensor([1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_2C_CL
DEPTH:  3
ACTIVATIONS SHAPE:  tensor([[ 33.5590,  10.2417,  16.9860,  -0.2765,  -0.9065,  -8.1747,  11.6162,
         -13.6948, -28.4454, -28.4010,  -2.5313,  18.7743,   7.7422,   0.4699,
          -9.6111,  21.6427],
        [ 33.5824,  13.1570,  37.4680,   8.4617,  -9.5757, -33.0034, -23.7525,
         -35.8823, -37.0792, -37.3245, -23.6429,  -1.5439,  -5.3000,   8.0686,
           3.6553,  29.5757],
        [ 39.3418,  33.5661,  39.9738,  31.4213,   3.0713,  -6.8909,  -7.8321,
         -27.7854, -43.0089, -33.5251, -26.1197, -28.4996, -20.0609, -14.9326,
         -19.5543,  21.5892],
        [ 34.7306,  29.0707,  29.4798,  18.5313,  18.5030,   7.2177,  -3.8438,
         -28.4061, -32.4614, -26.3162, -52.5391, -44.4088, -35.6337, -30.6633,
         -29.0726,   9.8677],
        [ 21.1953,  20.4074,  11.7987, -29.8330,  -4.3886,   9.8276,   2.3397,
         -13.9635, -30.1822, -28.1870, -50.5655, -44.7864, -30.5151, -39.1718,
         -28.7315,   3.7382],
        [ 27.1971,  33.4239,  14.4674, -30.0230, -21.4588,  -0.1247,  15.4052,
           6.3596, -14.2831, -30.9162, -37.1116, -26.0297,  -7.2246, -16.9989,
         -20.8235,   4.7740],
        [ 24.6955,  39.7445,  34.5464,  -2.8020, -13.2899,  -7.4269,   6.1294,
         -13.1984, -48.2187, -41.1714, -19.2963, -17.2213, -10.0964, -14.9439,
         -27.2493,   6.6989],
        [  8.7121,  31.2032,  34.4245, -13.2491, -49.8768, -32.3702, -12.8396,
         -36.0434, -61.8437, -33.7191, -29.7843, -26.9396, -14.7309, -32.6280,
         -45.6409,   4.2769],
        [ -5.8814,  15.8741, -14.0270, -54.7665, -68.9631, -66.5073, -20.9286,
         -32.6094, -24.3043, -25.9258, -14.6321, -18.8501, -14.7771, -29.6450,
         -64.1615, -12.6666],
        [ 15.8155,  -3.0690, -38.4246, -70.9228, -67.7936, -40.5705,   2.7002,
          -6.0052, -19.3318,   4.1939,  -0.4395,  12.9794,  -2.4987, -17.8737,
         -64.8796,  -8.4001],
        [ 26.8082,  39.1090,  12.1570, -41.8013, -30.0707,   8.8226,  27.2694,
          14.5835, -13.3778,  -2.0917, -16.4516, -23.4935,  -7.7328, -22.4869,
         -47.1757, -15.2862],
        [ 28.0635,  31.5807,   3.9598, -30.9099,  -6.9892,  -4.7777,   4.7199,
          -1.1097, -18.8342,  -3.8296, -16.6176, -38.3772, -37.0198, -50.3677,
         -61.5655, -56.8748],
        [ 16.2929,  16.3666,   2.5343, -21.3889,  -5.3804, -22.2362,  -8.1923,
           3.7058,  -5.0861,   1.6835,   6.0100, -15.1485, -25.6396, -39.3379,
         -36.7764, -30.0815],
        [  1.2844,   3.6946, -18.1654, -36.7715, -22.7116, -22.1254, -34.5940,
         -47.6591, -32.6397, -21.6322, -12.1664, -35.9802, -41.0601, -39.5094,
         -25.1464, -15.9303],
        [ -6.4971,  -1.1232,   6.7536, -19.8308, -12.8745, -20.5510, -36.5550,
         -71.5191, -49.0286, -35.2198, -27.0478, -34.0969, -25.4339, -18.6470,
         -29.8159,  -9.3878],
        [-34.3529, -35.2538, -18.5962, -46.6679, -59.1303, -48.7143, -76.5349,
         -73.5800, -58.2705, -53.1927, -59.4733, -66.1104, -65.4463, -49.0589,
         -37.4467, -34.7280]], device='cuda:0')
LAYER_NUM:  1
FINAL_SUM:  [359, 78, 115, 61, 98, 249, 245, 77, 66, 330]
acts len:  3
acts keys:  ['conv0', 'conv1', 'conv2']
acts:  {'conv0': [66, 43, 26, 91, 46, 4, 92, 29, 25, 75, 77, 16, 67, 56, 84, 34, 11, 87, 69, 53, 80], 'conv1': [359, 78, 115, 61, 98, 249, 245, 77, 66, 330, 151, 53, 64, 300, 63, 32, 46, 266, 157, 243, 291], 'conv2': [268, 1323, 737, 660, 108, 1371, 1005, 451, 1412, 128, 196, 888, 205, 870, 75, 1039, 1174, 730, 325, 301, 272]}
final_sum len:  384
delta_weights INFO: 
NUM OF TRACKED COV LAYERS:  1
NUM OF TRACKED WEIGHTS CHANGES PER LAYER:  10
avg_deltas INFO:  <class 'dict'>
avg_deltas keys:  ['blocks.0.layer.weight', 'blocks.1.layer.weight', 'blocks.2.layer.weight']
avg_deltas size:  3
num of averages for 1 layer:  torch.Size([96])
################################################
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.33e-01	time: 00:00:41	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:7.020e-03/SW:1.889e-01/MR:5.400e+00/SR:1.313e+00/MeD:1.041e+00/MaD:4.400e+00/MW:0.540/MAW:0.460
|         0 |        1 |         2 |         3 |          4 |        5 |        6 |         7 |        8 |         9 |      10 |       11 |        12 |       13 |        14 |       15 |       16 |       17 |        18 |       19 |        20 |        21 |       22 |       23 |       24 |       25 |       26 |       27 |        28 |       29 |
|-----------+----------+-----------+-----------+------------+----------+----------+-----------+----------+-----------+---------+----------+-----------+----------+-----------+----------+----------+----------+-----------+----------+-----------+-----------+----------+----------+----------+----------+----------+----------+-----------+----------|
|   0.00963 |   0.0115 |   0.00827 |   0.00686 |   4.06e-05 |   0.0102 |   0.0109 |   0.00969 |   0.0106 |   0.00908 |   0.011 |   0.0103 |   0.00761 |   0.0119 |   0.00988 |   0.0111 |   0.0111 |   0.0117 |   0.00948 |   0.0113 |   0.00611 |   0.00992 |   0.0103 |   0.0115 |   0.0106 |   0.0122 |   0.0108 |   0.0108 |   0.00937 |   0.0087 |
|   4.71    |   6.27   |   3.74    |   2.88    |   1        |   5.13   |   5.74   |   4.76    |   5.53   |   4.3     |   5.85  |   5.24   |   3.32    |   6.7    |   4.91    |   5.94   |   5.96   |   6.52   |   4.6     |   6.11   |   2.49    |   4.94    |   5.24   |   6.33   |   5.49   |   6.92   |   5.65   |   5.65   |   4.51    |   4.03   |
|   0.2     |   0.16   |   0.21    |   0.19    |  10.7      |   0.15   |   0.16   |   0.23    |   0.28   |   0.19    |   0.16  |   0.22   |   0.29    |   0.26   |   0.16    |   0.2    |   0.15   |   0.27   |   0.24    |   0.41   |   0.15    |   0.2     |   0.31   |   0.23   |   0.31   |   0.28   |   0.13   |   0.18   |   0.15    |   0.26   |
| nan       | nan      | nan       | nan       | nan        | nan      | nan      | nan       | nan      | nan       | nan     | nan      | nan       | nan      | nan       | nan      | nan      | nan      | nan       | nan      | nan       | nan       | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan      |
| nan       | nan      | nan       | nan       | nan        | nan      | nan      | nan       | nan      | nan       | nan     | nan      | nan       | nan      | nan       | nan      | nan      | nan      | nan       | nan      | nan       | nan       | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan      |
| nan       | nan      | nan       | nan       | nan        | nan      | nan      | nan       | nan      | nan       | nan     | nan      | nan       | nan      | nan       | nan      | nan      | nan      | nan       | nan      | nan       | nan       | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([1, 1, 4, 4, 4, 4, 1, 4, 4, 1, 1, 1, 4, 4, 1, 1, 4, 1, 4, 1])
[1, 4]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([4, 1, 1, 4, 4, 4, 1, 4, 1, 1, 1, 4, 1, 1, 1, 1, 4, 1, 1, 4])
[1, 4]
TARGETS AFTER CLEANER:  tensor([1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([4, 1, 1, 4, 4, 4, 1, 4, 1, 1, 1, 4, 1, 1, 1, 1, 4, 1, 1, 4])
[1, 4]
TARGETS AFTER CLEANER:  tensor([1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_2C_CL
DEPTH:  3
ACTIVATIONS SHAPE:  tensor([[ 2.5047e+01,  1.3362e+01,  1.2192e+01, -7.1133e+00, -6.1433e+00,
         -7.7509e+00,  5.9733e+00, -1.0037e+01, -2.1570e+01, -1.8815e+01,
          5.5841e+00,  2.2033e+01,  1.4440e+01,  4.0641e+00, -9.1122e+00,
          7.2022e+00],
        [ 2.4774e+01,  1.4110e+01,  2.2289e+01, -1.4661e+00, -9.5338e+00,
         -1.7839e+01, -1.2396e+01, -2.0642e+01, -2.4487e+01, -2.0821e+01,
         -4.1160e+00,  1.2493e+01,  9.2638e+00,  1.0488e+01,  5.6630e-01,
          1.5111e+01],
        [ 2.9664e+01,  2.6578e+01,  2.4880e+01,  1.0359e+01,  1.5302e+00,
         -2.0231e-01, -1.3536e+00, -1.4034e+01, -2.3015e+01, -1.5068e+01,
         -4.0388e+00, -1.1922e+00,  2.1317e+00,  1.4815e+00, -3.7492e+00,
          1.8154e+01],
        [ 2.6662e+01,  2.2073e+01,  1.7028e+01,  2.6614e+00,  9.1234e+00,
          6.6228e+00,  2.0250e+00, -1.4501e+01, -1.7925e+01, -1.0815e+01,
         -1.9624e+01, -1.5801e+01, -1.0076e+01, -6.3425e+00, -5.7973e+00,
          1.5239e+01],
        [ 1.9727e+01,  1.6424e+01,  1.0956e+01, -2.0345e+01, -3.4688e+00,
          8.6896e+00,  6.2500e+00, -3.4660e+00, -1.4414e+01, -1.2655e+01,
         -2.0765e+01, -1.9294e+01, -1.1505e+01, -1.1018e+01, -9.4234e-01,
          1.5045e+01],
        [ 2.4587e+01,  2.4902e+01,  1.6743e+01, -1.6864e+01, -1.2670e+01,
          9.5205e-01,  1.0456e+01,  3.7951e+00, -6.4647e+00, -1.0837e+01,
         -1.1603e+01, -6.3623e+00,  5.8250e+00,  4.5071e+00,  7.2388e+00,
          1.8978e+01],
        [ 2.9103e+01,  3.3778e+01,  3.6425e+01,  5.9254e+00, -7.1554e+00,
         -1.4857e+00,  4.8376e+00, -4.0226e+00, -2.1784e+01, -1.3257e+01,
          3.1376e+00,  1.3838e+00,  6.2011e+00,  7.4501e+00,  6.2302e+00,
          2.1718e+01],
        [ 2.2442e+01,  3.2289e+01,  3.7210e+01,  1.2829e+00, -2.2381e+01,
         -1.0034e+01, -2.4414e+00, -1.2790e+01, -2.6138e+01, -6.7994e+00,
          1.2294e+00, -1.1900e+00,  4.2824e+00, -3.0960e+00, -5.1356e+00,
          1.8383e+01],
        [ 1.5064e+01,  2.3181e+01,  1.1786e+01, -2.1049e+01, -3.2141e+01,
         -2.4973e+01, -1.3343e+00, -7.4476e+00, -3.1557e+00, -2.5926e+00,
          6.8127e+00,  4.0841e+00,  4.1628e+00, -6.4268e-03, -1.5284e+01,
          9.5764e+00],
        [ 2.7335e+01,  1.1549e+01, -2.6475e+00, -2.8912e+01, -2.4865e+01,
         -5.9730e+00,  1.7888e+01,  1.6609e+01,  8.7055e+00,  1.6653e+01,
          1.1002e+01,  1.7411e+01,  6.8090e+00,  2.5685e+00, -1.6058e+01,
          7.0970e+00],
        [ 3.0431e+01,  3.0959e+01,  2.0299e+01, -1.3871e+01, -5.8395e+00,
          2.3174e+01,  3.8460e+01,  3.6535e+01,  1.9716e+01,  1.6961e+01,
          1.8561e+00, -5.7993e+00, -2.8179e-01, -4.0695e+00, -1.4806e+01,
         -3.7074e+00],
        [ 3.3201e+01,  2.8983e+01,  1.8081e+01, -6.2804e+00,  7.3067e+00,
          1.5221e+01,  2.8109e+01,  3.0763e+01,  2.1720e+01,  2.1689e+01,
          6.0135e+00, -1.4614e+01, -1.5983e+01, -2.2218e+01, -2.6674e+01,
         -3.1736e+01],
        [ 2.5842e+01,  1.9458e+01,  1.6155e+01, -2.9005e+00,  5.2956e+00,
          1.0810e+00,  1.7248e+01,  2.8549e+01,  2.2534e+01,  2.5031e+01,
          1.7526e+01, -2.3764e+00, -9.3126e+00, -1.3732e+01, -1.3335e+01,
         -1.8838e+01],
        [ 1.4424e+01,  1.0532e+01,  3.7295e+00, -1.2111e+01, -7.8897e+00,
         -8.0750e+00, -2.1173e+00, -7.8249e+00, -6.5573e-01,  7.3156e+00,
          7.7951e+00, -1.0024e+01, -1.2877e+01, -1.3033e+01, -7.8663e+00,
         -9.8020e+00],
        [ 2.8071e+00,  2.2857e+00,  1.0195e+01, -8.4646e+00, -7.5157e+00,
         -1.2071e+01, -1.4636e+01, -3.1573e+01, -2.0140e+01, -8.6322e+00,
         -8.1103e+00, -2.0369e+01, -1.2341e+01, -6.6944e+00, -1.6918e+01,
         -1.2815e+01],
        [-1.3064e+01, -1.6512e+01, -4.0449e+00, -2.3122e+01, -3.2564e+01,
         -3.0081e+01, -3.8202e+01, -3.6509e+01, -2.9268e+01, -2.1646e+01,
         -2.8148e+01, -3.7579e+01, -3.2493e+01, -2.3771e+01, -2.4145e+01,
         -2.7286e+01]], device='cuda:0')
LAYER_NUM:  2
FINAL_SUM:  [1458, 1323, 1149, 108, 660, 1505, 1412, 1213, 1005, 205]
acts len:  3
acts keys:  ['conv0', 'conv1', 'conv2']
acts:  {'conv0': [66, 43, 26, 91, 46, 4, 92, 29, 25, 75, 77, 16, 67, 56, 84, 34, 11, 87, 69, 53, 80], 'conv1': [61, 78, 19, 66, 247, 63, 116, 46, 8, 243, 359, 59, 49, 175, 291, 204, 293, 324, 290, 125, 259], 'conv2': [1458, 1323, 1149, 108, 660, 1505, 1412, 1213, 1005, 205, 1141, 1082, 964, 226, 903, 350, 870, 1221, 843, 931, 726]}
final_sum len:  1536
delta_weights INFO: 
NUM OF TRACKED COV LAYERS:  1
NUM OF TRACKED WEIGHTS CHANGES PER LAYER:  10
avg_deltas INFO:  <class 'dict'>
avg_deltas keys:  ['blocks.0.layer.weight', 'blocks.1.layer.weight', 'blocks.2.layer.weight']
avg_deltas size:  3
num of averages for 2 layer:  torch.Size([96])
################################################
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.19e-02	time: 00:01:23	Acc_train 0.00	Acc_test 0.00	convergence: 1.77e+01	R1: 1	Info MB:0.000e+00/SB:0.000e+00/MW:4.616e-03/SW:3.199e-01/MR:1.865e+01/SR:2.437e+00/MeD:1.921e+00/MaD:1.765e+01/MW:0.422/MAW:0.578
|        0 |       1 |        2 |        3 |        4 |       5 |        6 |        7 |        8 |        9 |       10 |       11 |       12 |       13 |       14 |       15 |       16 |       17 |       18 |       19 |       20 |       21 |       22 |       23 |       24 |       25 |       26 |       27 |       28 |       29 |
|----------+---------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------|
|   0.0437 |   0.042 |   0.0407 |   0.0377 |   0.0419 |   0.039 |   0.0426 |   0.0369 |   0.0394 |   0.0445 |   0.0391 |   0.0434 |   0.0374 |   0.0368 |   0.0424 |   0.0414 |   0.0456 |   0.0465 |   0.0417 |   0.0416 |   0.0356 |   0.0422 |   0.0283 |   0.0421 |   0.0399 |   0.0368 |   0.0449 |   0.0445 |   0.0367 |   0.0418 |
|  20.11   |  18.68  |  17.53   |  15.18   |  18.57   |  16.2   |  19.14   |  14.64   |  16.49   |  20.8    |  16.28   |  19.84   |  14.99   |  14.51   |  18.94   |  18.11   |  21.77   |  22.6    |  18.38   |  18.32   |  13.64   |  18.83   |   9.03   |  18.69   |  16.96   |  14.53   |  21.13   |  20.79   |  14.5    |  18.49   |
|   0.04   |   0.02  |   0.06   |   0.11   |   0.04   |   0.05  |   0.06   |   0.02   |   0.09   |   0.04   |   0.07   |   0.09   |   0.21   |   0.02   |   0.1    |   0.04   |   0.05   |   0.11   |   0.04   |   0.04   |   0.1    |   0.06   |   0.03   |   0.04   |   0.06   |   0.06   |   0.08   |   0.04   |   0.06   |   0.05   |
| nan      | nan     | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan     | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan     | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models

 ********** Supervised learning of blocks [3] **********
SAVING FOLDER FOR SUP:  C10_2C_CL
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([1, 1, 4, 4, 4, 4, 1, 4, 4, 1, 1, 1, 4, 4, 1, 1, 4, 1, 4, 1])
[1, 4]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([4, 1, 1, 4, 4, 4, 1, 4, 1, 1, 1, 4, 1, 1, 1, 1, 4, 1, 1, 4])
[1, 4]
TARGETS AFTER CLEANER:  tensor([1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([4, 1, 1, 4, 4, 4, 1, 4, 1, 1, 1, 4, 1, 1, 1, 1, 4, 1, 1, 4])
[1, 4]
TARGETS AFTER CLEANER:  tensor([1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Epoch: [1/50]	lr: 1.00e-03	time: 00:01:38	Loss_train 0.17345	Acc_train 91.07	/	Loss_test 0.00281	Acc_test 96.80
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [10/50]	lr: 1.00e-03	time: 00:01:42	Loss_train 0.02605	Acc_train 98.02	/	Loss_test 0.00181	Acc_test 98.65
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [20/50]	lr: 2.50e-04	time: 00:01:47	Loss_train 0.00538	Acc_train 99.39	/	Loss_test 0.00138	Acc_test 98.95
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [30/50]	lr: 1.25e-04	time: 00:01:51	Loss_train 0.00290	Acc_train 99.63	/	Loss_test 0.00118	Acc_test 98.95
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [40/50]	lr: 3.13e-05	time: 00:01:56	Loss_train 0.00178	Acc_train 99.73	/	Loss_test 0.00122	Acc_test 99.10
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [50/50]	lr: 7.81e-06	time: 00:02:01	Loss_train 0.00129	Acc_train 99.80	/	Loss_test 0.00120	Acc_test 99.10
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
RESULT:  {'train_loss': 0.0012913706013932824, 'train_acc': 99.80000257492065, 'test_loss': 0.0011988967889919877, 'test_acc': 99.0999984741211, 'convergence': 17.651851654052734, 'R1': 1, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [1, 4]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [1, 4]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}
IN R2:  {'R1': {'train_loss': 0.014591929502785206, 'train_acc': 97.86199927330017, 'test_loss': 0.004178447648882866, 'test_acc': 94.75, 'convergence': 20.554641723632812, 'R1': 0, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [0, 9]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [0, 9]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}, 'R2': {'train_loss': 0.0012913706013932824, 'train_acc': 99.80000257492065, 'test_loss': 0.0011988967889919877, 'test_acc': 99.0999984741211, 'convergence': 17.651851654052734, 'R1': 1, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [1, 4]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [1, 4]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}

 Model C10_2C_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=2, bias=True)
[Sequential(
  (0): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=0.7)
  )
  (1): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=1.4)
  )
  (2): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (activation): Triangle(power=1.0)
  )
  (3): BasicBlock(
    (operations): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
    )
    (layer): Linear(in_features=24576, out_features=2, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
)]
LAYER NAME:  Sequential(
  (0): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=0.7)
  )
  (1): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=1.4)
  )
  (2): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (activation): Triangle(power=1.0)
  )
  (3): BasicBlock(
    (operations): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
    )
    (layer): Linear(in_features=24576, out_features=2, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
)
LAYER CHILDREN:  [BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
  (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
  (activation): Triangle(power=0.7)
), BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
  (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
  (activation): Triangle(power=1.4)
), BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (activation): Triangle(power=1.0)
), BasicBlock(
  (operations): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
  )
  (layer): Linear(in_features=24576, out_features=2, bias=True)
  (dropout): Dropout(p=0.5, inplace=False)
)]
subsubl NAME:  Sequential(
  (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
subsubl NAME:  Triangle(power=0.7)
subsubl NAME:  Sequential(
  (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
subsubl NAME:  Triangle(power=1.4)
subsubl NAME:  Sequential(
  (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  AvgPool2d(kernel_size=2, stride=2, padding=0)
subsubl NAME:  Triangle(power=1.0)
subsubl NAME:  Sequential(
  (0): Flatten(start_dim=1, end_dim=-1)
)
subsubl NAME:  Linear(in_features=24576, out_features=2, bias=True)
subsubl NAME:  Dropout(p=0.5, inplace=False)
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([0, 0, 9, 9, 0, 9, 0, 9, 9, 9, 0, 9, 9, 9, 0, 0, 9, 9, 0, 0])
[0, 9]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 9, 9, 9, 0, 0, 9, 0, 0, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9])
[0, 9]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([9, 9, 9, 9, 9, 0, 0, 9, 0, 0, 9, 9, 9, 9, 9, 0, 9, 0, 9, 9])
[0, 9]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Accuracy of the network on the 1st dataset: 29.700 %
Test loss on the 1st dataset: 0.273

The device used will be: 
True
cuda:0
BLOCKS:  {'b0': {'arch': 'CNN', 'preset': 'softkrotov-c96-k5-p2-s1-d1-b0-t1-lr0.08-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 0, 'batch_norm': False, 'pool': {'type': 'max', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 0.7}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5}}, 'b1': {'arch': 'CNN', 'preset': 'softkrotov-c384-k3-p1-s1-d1-b0-t0.65-lr0.005-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 1, 'batch_norm': False, 'pool': {'type': 'max', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 1.4}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3}}, 'b2': {'arch': 'CNN', 'preset': 'softkrotov-c1536-k3-p1-s1-d1-b0-t0.25-lr0.01-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 2, 'batch_norm': False, 'pool': {'type': 'avg', 'kernel_size': 2, 'stride': 2, 'padding': 0}, 'activation': {'function': 'triangle', 'param': 1.0}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3}}, 'b3': {'arch': 'MLP', 'preset': 'BP-c10', 'operation': 'flatten', 'num': 3, 'att_dropout': None, 'dropout': 0.5, 'layer': {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.25, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10}, 'pool': None, 'activation': None}}
CL:  True
{'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True}
CL:  True
{'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}

 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=2, bias=True)
[Sequential(
  (0): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=0.7)
  )
  (1): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=1.4)
  )
  (2): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (activation): Triangle(power=1.0)
  )
  (3): BasicBlock(
    (operations): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
    )
    (layer): Linear(in_features=24576, out_features=2, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
)]
LAYER NAME:  Sequential(
  (0): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=0.7)
  )
  (1): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=1.4)
  )
  (2): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (activation): Triangle(power=1.0)
  )
  (3): BasicBlock(
    (operations): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
    )
    (layer): Linear(in_features=24576, out_features=2, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
)
LAYER CHILDREN:  [BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
  (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
  (activation): Triangle(power=0.7)
), BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
  (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
  (activation): Triangle(power=1.4)
), BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (activation): Triangle(power=1.0)
), BasicBlock(
  (operations): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
  )
  (layer): Linear(in_features=24576, out_features=2, bias=True)
  (dropout): Dropout(p=0.5, inplace=False)
)]
subsubl NAME:  Sequential(
  (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
subsubl NAME:  Triangle(power=0.7)
subsubl NAME:  Sequential(
  (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
subsubl NAME:  Triangle(power=1.4)
subsubl NAME:  Sequential(
  (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  AvgPool2d(kernel_size=2, stride=2, padding=0)
subsubl NAME:  Triangle(power=1.0)
subsubl NAME:  Sequential(
  (0): Flatten(start_dim=1, end_dim=-1)
)
subsubl NAME:  Linear(in_features=24576, out_features=2, bias=True)
subsubl NAME:  Dropout(p=0.5, inplace=False)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([0, 6, 6, 6, 0, 6, 0, 0, 6, 6, 6, 6, 0, 6, 0, 6, 6, 6, 6, 0])
[0, 6]
TARGETS AFTER CLEANER:  tensor([0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 6, 6, 6, 6, 0, 0, 0, 0, 6, 0, 0, 6, 6, 6, 0, 0, 6, 6, 6])
[0, 6]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 6, 6, 6, 6, 0, 0, 0, 0, 6, 0, 0, 6, 6, 6, 0, 0, 6, 6, 6])
[0, 6]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_2C_CL
DEPTH:  3
WTA IN delta_weight:  tensor([[[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         ...,
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -1.4013e-45],
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -3.3771e-43],
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -1.9618e-44]],

        [[-7.0159e-41, -1.1457e-41, -6.5979e-40,  ..., -1.6288e-40,
          -5.0447e-44, -2.8026e-45],
         [-3.1954e-38, -4.0151e-39, -3.1788e-38,  ..., -8.3798e-43,
          -1.8637e-43, -3.9657e-43],
         [-5.5287e-39, -5.3283e-41, -1.9683e-41,  ..., -2.2421e-44,
          -6.7823e-43, -1.4377e-42],
         ...,
         [-2.6220e-39, -7.7262e-36, -4.7013e-36,  ..., -5.0083e-37,
          -1.3186e-35, -8.4036e-33],
         [-1.5921e-36, -8.1185e-38, -3.0149e-39,  ..., -4.8957e-34,
          -9.6895e-33, -1.4239e-32],
         [-3.6573e-36, -7.5922e-38, -2.8282e-39,  ..., -5.3883e-36,
          -6.3211e-34, -1.1897e-33]],

        [[-8.4078e-44, -1.9618e-44, -9.3807e-41,  ..., -1.1210e-44,
          -0.0000e+00, -0.0000e+00],
         [-5.0628e-41, -1.0047e-42, -3.9103e-41,  ..., -0.0000e+00,
          -1.4013e-45, -4.2039e-45],
         [-8.2342e-41, -5.2689e-43, -8.6881e-44,  ..., -0.0000e+00,
          -1.1210e-44, -7.7071e-44],
         ...,
         [-1.2874e-40, -6.7370e-39, -5.1468e-39,  ..., -2.2499e-37,
          -2.0046e-37, -1.7820e-34],
         [-1.4026e-39, -1.1124e-39, -6.0157e-40,  ..., -6.8188e-34,
          -5.1454e-33, -4.3652e-34],
         [-5.4581e-42, -4.4895e-41, -6.6755e-40,  ..., -4.0170e-36,
          -1.1133e-34, -1.5445e-34]],

        ...,

        [[-2.9707e-11, -5.9221e-13, -3.4300e-09,  ..., -1.0430e-11,
          -8.8291e-14, -6.1371e-15],
         [-3.7614e-10, -2.7181e-11, -2.8379e-09,  ..., -2.0718e-12,
          -3.1815e-12, -4.8787e-13],
         [-1.5871e-10, -4.4207e-11, -4.1032e-11,  ..., -2.6631e-12,
          -1.0335e-12, -3.6643e-14],
         ...,
         [-1.7227e-10, -5.6032e-11, -1.7342e-10,  ..., -4.9891e-11,
          -1.3475e-09, -1.0140e-06],
         [-5.5221e-12, -1.9646e-10, -8.7966e-09,  ..., -3.0151e-10,
          -4.4409e-09, -6.5015e-07],
         [-6.4643e-14, -5.3904e-12, -1.4931e-09,  ..., -2.1083e-10,
          -1.0296e-08, -3.2643e-07]],

        [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,
          -0.0000e+00, -0.0000e+00],
         ...,
         [-4.6243e-44, -8.5479e-44, -2.2659e-42,  ..., -1.1435e-42,
          -5.2969e-43, -5.1358e-41],
         [-9.8091e-45, -2.8026e-45, -7.1466e-44,  ..., -1.9924e-40,
          -5.4047e-40, -4.2162e-41],
         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -2.0788e-40,
          -8.8837e-40, -4.2534e-40]],

        [[-1.3551e-34, -1.4307e-35, -3.1095e-32,  ..., -4.2178e-35,
          -1.5619e-37, -1.0263e-38],
         [-1.2523e-33, -2.1123e-33, -1.0872e-31,  ..., -6.5308e-37,
          -5.7793e-37, -7.1613e-38],
         [-7.2854e-35, -2.7040e-33, -1.0279e-34,  ..., -1.0212e-37,
          -1.7574e-37, -6.7848e-38],
         ...,
         [-5.7231e-31, -5.2048e-31, -3.2261e-30,  ..., -6.0040e-32,
          -1.6692e-30, -7.6048e-29],
         [-3.9068e-32, -1.2647e-33, -1.5729e-31,  ..., -1.3219e-29,
          -2.5557e-28, -2.1988e-28],
         [-1.4765e-33, -2.5088e-34, -8.6691e-33,  ..., -3.1924e-30,
          -2.9184e-29, -1.0113e-28]]], device='cuda:0')
LAYER_NUM:  0
FINAL_SUM:  [26, 43, 87, 46, 91, 34, 55, 77, 35, 66]
acts len:  1
acts keys:  ['conv0']
acts:  {'conv0': [26, 43, 87, 46, 91, 34, 55, 77, 35, 66, 4, 67, 84, 53, 15, 30, 29, 11, 39, 92, 56]}
final_sum len:  96
delta_weights INFO: 
NUM OF TRACKED COV LAYERS:  1
NUM OF TRACKED WEIGHTS CHANGES PER LAYER:  10
avg_deltas INFO:  <class 'dict'>
avg_deltas keys:  ['blocks.0.layer.weight']
avg_deltas size:  1
num of averages for 0 layer:  torch.Size([96])
################################################
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.44e-01	time: 00:00:22	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.107e-02/SW:5.659e-01/MR:4.601e+00/SR:1.699e+00/MeD:1.381e+00/MaD:4.230e+00/MW:0.605/MAW:0.395
|       0 |       1 |       2 |       3 |       4 |       5 |       6 |       7 |       8 |       9 |      10 |      11 |     12 |      13 |      14 |      15 |        16 |     17 |      18 |      19 |      20 |     21 |      22 |      23 |      24 |         25 |      26 |      27 |      28 |      29 |
|---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+--------+---------+---------+---------+-----------+--------+---------+---------+---------+--------+---------+---------+---------+------------+---------+---------+---------+---------|
|   0.112 |   0.144 |   0.137 |   0.169 |   0.101 |   0.108 |   0.168 |   0.191 |   0.161 |   0.194 |   0.194 |   0.123 |   0.19 |   0.154 |   0.154 |   0.176 |   0.00031 |   0.13 |   0.164 |   0.184 |   0.202 |   0.17 |   0.144 |   0.186 |   0.164 |   0.000269 |   0.188 |   0.126 |   0.133 |   0.196 |
|   2.95  |   4.25  |   3.94  |   5.45  |   2.58  |   2.84  |   5.42  |   6.71  |   5.03  |   6.86  |   6.88  |   3.38  |   6.66 |   4.69  |   4.7   |   5.82  |   1       |   3.65 |   5.2   |   6.31  |   7.38  |   5.54 |   4.22  |   6.42  |   5.18  |   1        |   6.52  |   3.49  |   3.78  |   7.01  |
|   0.55  |   0.52  |   0.45  |   0.56  |   0.84  |   1.11  |   0.72  |   0.47  |   0.75  |   0.49  |   1.08  |   0.49  |   0.62 |   0.43  |   0.76  |   0.5   |  13.44    |   0.54 |   0.57  |   0.74  |   0.66  |   0.78 |   0.5   |   0.48  |   0.49  |  15.78     |   0.61  |   1.07  |   0.49  |   0.56  |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan       | nan    | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan       | nan    | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan       | nan    | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([0, 6, 6, 6, 0, 6, 0, 0, 6, 6, 6, 6, 0, 6, 0, 6, 6, 6, 6, 0])
[0, 6]
TARGETS AFTER CLEANER:  tensor([0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 6, 6, 6, 6, 0, 0, 0, 0, 6, 0, 0, 6, 6, 6, 0, 0, 6, 6, 6])
[0, 6]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 6, 6, 6, 6, 0, 0, 0, 0, 6, 0, 0, 6, 6, 6, 0, 0, 6, 6, 6])
[0, 6]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_2C_CL
DEPTH:  3
ACTIVATIONS SHAPE:  tensor([[-1.6518e+01, -3.7167e+01, -5.6070e+01, -9.8666e+01, -1.1376e+02,
         -1.1371e+02, -1.0058e+02, -8.0302e+01, -4.3301e+01, -1.7155e+01,
         -1.1161e+01, -1.0254e+01,  1.3969e+01, -2.0704e+01, -2.6076e+01,
         -3.2337e+01],
        [-3.8672e+01, -3.3515e+01, -4.9831e+01, -3.2924e+01, -8.7834e+01,
         -9.6486e+01, -1.0245e+02, -6.7940e+01, -4.6511e+01, -4.0804e+01,
         -3.5868e+01, -2.9137e+01, -5.0841e+01, -4.3637e+01, -4.8515e+01,
         -6.7002e+00],
        [ 1.3136e+01, -7.1617e+00,  9.6036e+00, -2.0242e+01, -7.6107e+01,
         -5.3678e+01, -5.7118e+01, -1.2636e+02, -6.9506e+01, -6.5784e+01,
         -2.2294e+01, -2.1272e+00,  6.9771e+00, -2.4546e+01, -7.9147e+01,
         -2.9082e+00],
        [-4.7316e+01, -4.8564e+01, -1.8743e+01, -3.0671e+01, -4.5575e+01,
         -6.2581e+01, -4.5472e+01, -8.0446e+01, -8.7442e+01, -6.8499e+01,
         -4.0386e+01, -2.3066e-01,  4.0728e+01,  5.0545e+00, -6.9168e+01,
         -2.4977e+01],
        [ 2.2370e+00,  1.9720e+01,  5.3597e+01,  8.0238e+00,  1.0485e+01,
         -1.3560e+01, -2.4077e+01, -4.4499e+01, -2.3442e+01, -1.4843e+01,
          2.9057e+01,  5.3815e+01,  2.3873e+01, -6.9255e+01, -1.1402e+02,
         -7.0365e+01],
        [ 5.5051e+01,  7.3852e+01,  8.8567e+01,  6.6248e-01,  8.5168e+00,
         -6.7539e+01,  6.6716e+01,  7.0519e+01,  5.6942e+01,  4.2413e+01,
         -3.9959e+00, -1.8609e+01, -4.5604e+01, -3.4923e+01, -1.2322e+02,
         -8.5832e+01],
        [ 1.3975e+02,  9.4824e+01,  1.2584e+02, -1.6964e+01, -3.2203e+01,
         -3.1550e+01,  6.4751e+01,  1.1376e+02,  6.9709e+01,  2.8631e+01,
         -4.7943e+01, -6.8625e+01, -7.7992e+01, -5.9637e+01, -8.4588e+01,
         -6.0037e+01],
        [ 9.0152e+01,  8.3963e+01,  1.5623e+02,  6.1089e+00, -2.3481e+00,
          8.0071e-01, -2.2763e+01, -2.5846e+01, -2.3823e+01, -1.7928e+01,
         -4.6971e+01, -4.9930e+01, -5.7774e+01, -6.2913e+01, -5.4204e+01,
         -6.7059e+01],
        [-9.7506e+00,  6.6000e+01,  9.6876e+01,  3.3823e+01, -1.3555e+01,
          1.6633e+01,  8.6123e+00,  4.6163e+00, -9.7284e+00, -6.8794e+00,
         -1.1337e+01, -3.4421e+01, -3.4547e+01, -3.1222e+01, -4.5650e+01,
         -2.4530e+01],
        [ 3.8535e+01,  8.4319e+01,  9.1485e+01,  7.1374e+01,  2.5949e+01,
          6.9480e+01,  7.2861e+01,  3.0869e+01,  4.5325e+01,  6.7159e+01,
          4.6999e+01, -4.0554e+01, -8.2130e+01, -5.2395e+01,  9.1745e+00,
          3.2106e+01],
        [ 7.9233e+01,  5.8380e+01,  7.1371e+01,  5.6340e+01,  4.4994e+01,
          1.0351e+01,  1.5607e+01,  8.5261e-01,  4.5841e+01,  3.4833e+01,
          4.6860e+01, -2.9165e+01, -6.0940e+01, -6.7286e+01,  4.5140e+00,
          2.3804e+01],
        [ 6.1533e+01, -6.1121e+00,  2.8735e+01, -2.3528e+01, -3.6123e+01,
         -3.5489e+01, -3.4577e+01, -8.4351e-02,  8.7775e+00, -7.7863e+01,
         -4.5228e+01, -7.0016e+01, -1.1241e+02, -1.2423e+02, -8.5641e+01,
         -8.1867e+01],
        [ 8.0031e+01,  6.9156e+01,  7.2135e+01,  2.4561e+01,  1.5269e+01,
         -9.2948e+00,  3.2961e+01,  2.0508e+01, -3.6748e+01, -1.4190e+02,
         -1.3613e+02, -1.0280e+02, -9.1505e+01, -1.2486e+02, -1.3531e+02,
         -9.7951e+01],
        [ 7.9411e+01,  7.2715e+01,  7.4195e+01,  7.1661e+01,  3.9708e+01,
          4.8097e+01,  9.4167e+01,  3.4501e+01, -1.4144e+01, -6.0022e+01,
         -1.1433e+02, -1.3280e+02, -9.3988e+01, -3.4903e+01, -4.6605e+01,
         -5.1134e+01],
        [-2.4427e+01, -1.8592e+01,  1.8386e+01,  6.3957e+01,  7.3649e+01,
          5.1521e+01,  8.3272e+01,  7.9581e+01,  4.7391e+01,  1.3365e+01,
          6.0654e+00, -4.8605e+01, -2.6986e+01,  3.1583e+01,  2.1801e+01,
         -8.3765e+00],
        [-3.4817e+01,  1.6578e+00, -5.8674e+00,  1.0156e+01,  6.3617e+00,
         -3.1030e+01, -9.4415e+00, -1.9479e+01, -2.7529e+01, -5.8113e+01,
         -7.7503e+01, -9.1832e+01, -9.6526e+01, -6.9109e+01, -8.6112e+01,
         -4.9284e+01]], device='cuda:0')
LAYER_NUM:  1
FINAL_SUM:  [8, 61, 59, 247, 78, 63, 204, 147, 175, 116]
acts len:  2
acts keys:  ['conv0', 'conv1']
acts:  {'conv0': [26, 43, 87, 46, 91, 34, 55, 77, 35, 66, 4, 67, 84, 53, 15, 30, 29, 11, 39, 92, 56], 'conv1': [8, 61, 59, 247, 78, 63, 204, 147, 175, 116, 351, 49, 19, 324, 46, 66, 254, 71, 243, 120, 115]}
final_sum len:  384
delta_weights INFO: 
NUM OF TRACKED COV LAYERS:  1
NUM OF TRACKED WEIGHTS CHANGES PER LAYER:  10
avg_deltas INFO:  <class 'dict'>
avg_deltas keys:  ['blocks.0.layer.weight', 'blocks.1.layer.weight']
avg_deltas size:  2
num of averages for 1 layer:  torch.Size([96])
################################################
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.44e-01	time: 00:00:40	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.178e-03/SW:3.481e-01/MR:1.006e+01/SR:1.852e+00/MeD:1.430e+00/MaD:8.408e+00/MW:0.572/MAW:0.428
|        0 |        1 |        2 |        3 |        4 |        5 |        6 |        7 |        8 |        9 |       10 |      11 |       12 |       13 |       14 |       15 |       16 |       17 |      18 |       19 |       20 |       21 |       22 |       23 |       24 |       25 |       26 |       27 |       28 |       29 |
|----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------|
|   0.0153 |   0.0145 |   0.0162 |   0.0134 |   0.0124 |   0.0139 |   0.0151 |   0.0135 |   0.0151 |   0.0151 |   0.0141 |   0.016 |   0.0142 |   0.0173 |   0.0162 |   0.0155 |   0.0159 |   0.0153 |   0.012 |   0.0129 |   0.0159 |   0.0168 |   0.0139 |   0.0172 |   0.0137 |   0.0179 |   0.0152 |   0.0126 |   0.0151 |   0.0153 |
|  10.32   |   9.43   |  11.53   |   8.18   |   7.17   |   8.74   |  10.15   |   8.27   |  10.15   |  10.09   |   8.91   |  11.21  |   9.1    |  13.02   |  11.49   |  10.6    |  11.15   |  10.35   |   6.75  |   7.63   |  11.05   |  12.27   |   8.78   |  12.78   |   8.5    |  13.83   |  10.27   |   7.38   |  10.11   |  10.38   |
|   0.27   |   0.19   |   0.19   |   0.22   |   0.97   |   0.28   |   0.27   |   0.26   |   0.18   |   0.19   |   0.24   |   0.27  |   0.28   |   0.14   |   0.17   |   0.21   |   0.18   |   0.24   |   0.38  |   0.29   |   0.16   |   0.27   |   0.56   |   0.2    |   0.92   |   0.4    |   0.2    |   0.28   |   0.19   |   0.31   |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([0, 6, 6, 6, 0, 6, 0, 0, 6, 6, 6, 6, 0, 6, 0, 6, 6, 6, 6, 0])
[0, 6]
TARGETS AFTER CLEANER:  tensor([0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 6, 6, 6, 6, 0, 0, 0, 0, 6, 0, 0, 6, 6, 6, 0, 0, 6, 6, 6])
[0, 6]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 6, 6, 6, 6, 0, 0, 0, 0, 6, 0, 0, 6, 6, 6, 0, 0, 6, 6, 6])
[0, 6]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_2C_CL
DEPTH:  3
ACTIVATIONS SHAPE:  tensor([[ 1.9494e+01,  8.2180e+00,  7.6352e-01, -1.6022e+01, -1.9995e+01,
         -1.6638e+01, -1.2021e+01, -4.7961e+00,  8.1155e+00,  1.6533e+01,
          1.5705e+01,  1.1931e+01,  1.7172e+01,  1.2889e+00, -8.4469e-01,
         -4.7660e+00],
        [ 1.0840e+01,  1.0752e+01,  3.5120e+00,  9.1738e+00, -1.1829e+01,
         -1.2337e+01, -1.8704e+01, -7.9458e+00,  7.8131e-02,  3.8617e+00,
          3.0007e+00, -2.4031e-01, -1.2446e+01, -9.5431e+00, -1.1373e+01,
          5.5427e+00],
        [ 3.6541e+01,  2.3329e+01,  2.9085e+01,  1.2955e+01, -1.2557e+01,
         -7.6104e-01, -2.9340e+00, -3.5438e+01, -1.4508e+01, -1.1998e+01,
          3.9225e+00,  9.7484e+00,  9.7904e+00, -5.2473e+00, -2.5540e+01,
          6.9477e+00],
        [ 1.5025e+01,  1.0520e+01,  2.0057e+01,  8.9478e+00,  2.2406e+00,
         -1.3127e+01, -7.3098e+00, -2.0963e+01, -2.6036e+01, -1.7287e+01,
         -7.0428e+00,  6.6732e+00,  1.9776e+01,  4.6192e+00, -2.4994e+01,
         -3.6757e+00],
        [ 3.5964e+01,  4.1339e+01,  4.7749e+01,  2.5845e+01,  2.1210e+01,
          4.6205e+00, -1.1175e+00, -1.2194e+01, -5.2700e-01,  3.2464e+00,
          1.9163e+01,  2.5955e+01,  1.0658e+01, -2.9285e+01, -4.4364e+01,
         -2.3714e+01],
        [ 5.8928e+01,  5.8931e+01,  5.8599e+01,  1.4412e+01,  1.4971e+01,
         -2.0054e+01,  3.1282e+01,  3.2353e+01,  2.8217e+01,  2.1154e+01,
          7.0343e-01, -6.4918e+00, -1.7049e+01, -1.3999e+01, -4.7362e+01,
         -3.1387e+01],
        [ 8.3725e+01,  6.2535e+01,  6.7052e+01, -4.4536e-01, -9.5570e+00,
         -9.6505e+00,  2.9042e+01,  4.5147e+01,  2.4211e+01,  9.0637e+00,
         -2.4110e+01, -2.9303e+01, -2.9347e+01, -2.0364e+01, -2.9270e+01,
         -1.8997e+01],
        [ 5.0637e+01,  5.1134e+01,  7.2145e+01,  4.6331e+00, -5.9433e-03,
          2.4325e+00, -9.6369e+00, -2.0205e+01, -2.3751e+01, -2.2433e+01,
         -2.8142e+01, -2.2426e+01, -2.2005e+01, -2.1724e+01, -1.7818e+01,
         -1.9865e+01],
        [ 5.5812e+00,  3.4291e+01,  4.7545e+01,  1.3244e+01, -3.8432e+00,
          6.7186e+00,  1.6844e-01, -6.8723e+00, -2.1639e+01, -1.6169e+01,
         -1.2196e+01, -1.2220e+01, -9.7270e+00, -6.9210e+00, -1.0454e+01,
         -3.0610e+00],
        [ 2.0865e+01,  3.5628e+01,  3.9553e+01,  3.1519e+01,  1.4277e+01,
          3.1568e+01,  2.5159e+01,  5.2450e+00,  4.8185e+00,  1.9594e+01,
          1.9932e+01, -1.0818e+01, -2.7035e+01, -2.0127e+01,  9.0278e+00,
          1.5952e+01],
        [ 3.5038e+01,  2.2422e+01,  2.6109e+01,  1.8060e+01,  1.6795e+01,
          3.4963e+00,  3.8365e+00, -1.5514e+00,  1.1902e+01,  8.7543e+00,
          1.9227e+01, -8.2590e+00, -2.2506e+01, -2.7658e+01,  3.2822e+00,
          9.3204e+00],
        [ 2.2584e+01, -5.7233e+00,  6.2615e+00, -1.8694e+01, -2.4009e+01,
         -2.4190e+01, -1.9859e+01, -3.5440e+00, -1.6081e+00, -3.5178e+01,
         -1.5239e+01, -2.3574e+01, -4.2206e+01, -5.1801e+01, -3.3718e+01,
         -3.4227e+01],
        [ 2.8855e+01,  2.1845e+01,  2.0788e+01, -4.8519e+00, -8.3124e+00,
         -1.4448e+01,  5.1845e+00, -4.9681e-01, -2.3243e+01, -6.3624e+01,
         -5.6926e+01, -4.2551e+01, -4.0911e+01, -5.5193e+01, -5.6107e+01,
         -4.1596e+01],
        [ 2.9043e+01,  2.3412e+01,  1.9437e+01,  1.2142e+01, -2.5084e+00,
          4.9309e+00,  2.7172e+01, -9.8939e-01, -2.1714e+01, -3.5255e+01,
         -5.5990e+01, -6.2888e+01, -4.3776e+01, -1.5858e+01, -1.8135e+01,
         -2.0423e+01],
        [-1.3733e+01, -1.2250e+01,  2.1680e+00,  1.6206e+01,  2.0025e+01,
          1.2289e+01,  2.8016e+01,  2.1258e+01,  1.0059e+01, -8.9451e-01,
         -3.2509e+00, -2.5193e+01, -1.4930e+01,  1.1976e+01,  1.0231e+01,
         -2.3483e+00],
        [-1.6071e+01,  1.2990e+00, -3.7494e+00, -2.8952e+00, -8.9366e+00,
         -2.1955e+01, -1.0897e+01, -1.7754e+01, -2.0841e+01, -2.8442e+01,
         -3.7070e+01, -4.1563e+01, -4.2034e+01, -2.9489e+01, -3.5767e+01,
         -1.9814e+01]], device='cuda:0')
LAYER_NUM:  2
FINAL_SUM:  [268, 1323, 737, 660, 108, 1371, 1005, 451, 1412, 128]
acts len:  3
acts keys:  ['conv0', 'conv1', 'conv2']
acts:  {'conv0': [26, 43, 87, 46, 91, 34, 55, 77, 35, 66, 4, 67, 84, 53, 15, 30, 29, 11, 39, 92, 56], 'conv1': [8, 61, 59, 247, 78, 63, 204, 147, 175, 116, 351, 49, 19, 324, 46, 66, 254, 71, 243, 120, 115], 'conv2': [268, 1323, 737, 660, 108, 1371, 1005, 451, 1412, 128, 196, 888, 205, 870, 75, 1039, 1174, 730, 325, 301, 272]}
final_sum len:  1536
delta_weights INFO: 
NUM OF TRACKED COV LAYERS:  1
NUM OF TRACKED WEIGHTS CHANGES PER LAYER:  10
avg_deltas INFO:  <class 'dict'>
avg_deltas keys:  ['blocks.0.layer.weight', 'blocks.1.layer.weight', 'blocks.2.layer.weight']
avg_deltas size:  3
num of averages for 2 layer:  torch.Size([96])
################################################
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.52e-02	time: 00:00:58	Acc_train 0.00	Acc_test 0.00	convergence: 2.06e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.243e-03/SW:3.714e-01/MR:2.160e+01/SR:3.181e+00/MeD:2.531e+00/MaD:1.927e+01/MW:0.434/MAW:0.566
|        0 |        1 |        2 |        3 |        4 |        5 |        6 |        7 |        8 |        9 |       10 |       11 |       12 |       13 |       14 |       15 |       16 |       17 |       18 |       19 |      20 |       21 |       22 |       23 |       24 |       25 |       26 |       27 |       28 |       29 |
|----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------|
|   0.0471 |   0.0452 |   0.0473 |   0.0468 |   0.0449 |   0.0427 |   0.0501 |   0.0389 |   0.0474 |   0.0494 |   0.0473 |   0.0493 |   0.0467 |   0.0371 |   0.0441 |   0.0426 |   0.0482 |   0.0505 |   0.0401 |   0.0427 |   0.049 |   0.0452 |   0.0127 |   0.0458 |   0.0461 |   0.0396 |   0.0467 |   0.0426 |   0.0429 |   0.0452 |
|  23.23   |  21.44   |  23.35   |  22.93   |  21.19   |  19.24   |  26.14   |  16.1    |  23.44   |  25.36   |  23.34   |  25.35   |  22.77   |  14.78   |  20.41   |  19.16   |  24.28   |  26.46   |  17.11   |  19.21   |  25.04  |  21.45   |   2.61   |  21.94   |  22.21   |  16.69   |  22.83   |  19.18   |  19.42   |  21.47   |
|   0.04   |   0.04   |   0.06   |   0.03   |   0.03   |   0.04   |   0.05   |   0.05   |   0.09   |   0.03   |   0.11   |   0.07   |   0.16   |   0.09   |   0.16   |   0.04   |   0.05   |   0.05   |   0.06   |   0.04   |   0.04  |   0.05   |   0.6    |   0.05   |   0.05   |   0.09   |   0.05   |   0.06   |   0.05   |   0.05   |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models

 ********** Supervised learning of blocks [3] **********
SAVING FOLDER FOR SUP:  C10_2C_CL
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([0, 6, 6, 6, 0, 6, 0, 0, 6, 6, 6, 6, 0, 6, 0, 6, 6, 6, 6, 0])
[0, 6]
TARGETS AFTER CLEANER:  tensor([0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 6, 6, 6, 6, 0, 0, 0, 0, 6, 0, 0, 6, 6, 6, 0, 0, 6, 6, 6])
[0, 6]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 6, 6, 6, 6, 0, 0, 0, 0, 6, 0, 0, 6, 6, 6, 0, 0, 6, 6, 6])
[0, 6]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Epoch: [1/50]	lr: 1.00e-03	time: 00:01:13	Loss_train 0.15342	Acc_train 92.01	/	Loss_test 0.00195	Acc_test 96.65
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [10/50]	lr: 1.00e-03	time: 00:01:17	Loss_train 0.02626	Acc_train 97.26	/	Loss_test 0.00374	Acc_test 96.60
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [20/50]	lr: 2.50e-04	time: 00:01:22	Loss_train 0.01284	Acc_train 98.76	/	Loss_test 0.00318	Acc_test 97.40
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [30/50]	lr: 1.25e-04	time: 00:01:26	Loss_train 0.00712	Acc_train 99.16	/	Loss_test 0.00368	Acc_test 97.10
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [40/50]	lr: 3.13e-05	time: 00:01:31	Loss_train 0.00471	Acc_train 99.39	/	Loss_test 0.00301	Acc_test 97.65
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [50/50]	lr: 7.81e-06	time: 00:01:36	Loss_train 0.00408	Acc_train 99.44	/	Loss_test 0.00295	Acc_test 97.40
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
RESULT:  {'train_loss': 0.004077428486198187, 'train_acc': 99.44199919700623, 'test_loss': 0.0029496969655156136, 'test_acc': 97.4000015258789, 'convergence': 20.599519729614258, 'R1': 0, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [0, 6]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [0, 6]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}
IN R1:  {'R1': {'train_loss': 0.004077428486198187, 'train_acc': 99.44199919700623, 'test_loss': 0.0029496969655156136, 'test_acc': 97.4000015258789, 'convergence': 20.599519729614258, 'R1': 0, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [0, 6]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [0, 6]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}

 Model C10_2C_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=2, bias=True)
[Sequential(
  (0): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=0.7)
  )
  (1): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=1.4)
  )
  (2): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (activation): Triangle(power=1.0)
  )
  (3): BasicBlock(
    (operations): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
    )
    (layer): Linear(in_features=24576, out_features=2, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
)]
LAYER NAME:  Sequential(
  (0): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=0.7)
  )
  (1): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=1.4)
  )
  (2): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (activation): Triangle(power=1.0)
  )
  (3): BasicBlock(
    (operations): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
    )
    (layer): Linear(in_features=24576, out_features=2, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
)
LAYER CHILDREN:  [BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
  (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
  (activation): Triangle(power=0.7)
), BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
  (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
  (activation): Triangle(power=1.4)
), BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (activation): Triangle(power=1.0)
), BasicBlock(
  (operations): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
  )
  (layer): Linear(in_features=24576, out_features=2, bias=True)
  (dropout): Dropout(p=0.5, inplace=False)
)]
subsubl NAME:  Sequential(
  (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
subsubl NAME:  Triangle(power=0.7)
subsubl NAME:  Sequential(
  (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
subsubl NAME:  Triangle(power=1.4)
subsubl NAME:  Sequential(
  (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  AvgPool2d(kernel_size=2, stride=2, padding=0)
subsubl NAME:  Triangle(power=1.0)
subsubl NAME:  Sequential(
  (0): Flatten(start_dim=1, end_dim=-1)
)
subsubl NAME:  Linear(in_features=24576, out_features=2, bias=True)
subsubl NAME:  Dropout(p=0.5, inplace=False)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([8, 8, 5, 8, 5, 8, 5, 5, 5, 5, 5, 8, 8, 8, 8, 8, 8, 8, 5, 8])
[5, 8]
TARGETS AFTER CLEANER:  tensor([1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([8, 5, 5, 5, 5, 8, 8, 5, 5, 5, 8, 8, 8, 5, 8, 5, 8, 8, 5, 8])
[5, 8]
TARGETS AFTER CLEANER:  tensor([1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([8, 5, 5, 5, 5, 8, 8, 5, 5, 5, 8, 8, 8, 5, 8, 5, 8, 8, 5, 8])
[5, 8]
TARGETS AFTER CLEANER:  tensor([1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_2C_CL
DEPTH:  3
ACTIVATIONS SHAPE:  tensor([[ 6.5183e+02,  4.6686e+01,  2.3316e+02, -4.1313e+02, -5.9480e+02,
         -9.1073e+02, -9.1624e+02, -7.6924e+02, -6.6941e+02, -4.9722e+02,
         -3.8962e+02, -3.0075e+02, -2.9584e+02, -3.2559e+01,  1.9496e+01,
          4.4078e+02],
        [ 1.1743e+03,  5.7451e+02,  8.1305e+02,  3.4184e+01, -2.1026e+02,
         -5.3310e+02, -4.8136e+02, -6.3521e+02, -6.8723e+02, -5.8675e+02,
         -5.0708e+02, -3.6859e+02, -1.6187e+02,  2.2267e+00,  5.4442e+01,
          8.2283e+02],
        [ 1.3978e+03,  6.7509e+02,  9.3208e+02,  2.8310e+02,  6.9493e+01,
         -2.6060e+02, -4.3228e+02, -4.0930e+02, -5.3460e+02, -4.4338e+02,
         -5.1886e+02, -3.9116e+02, -3.3648e+02, -9.4791e+01, -6.0055e+01,
          6.5742e+02],
        [ 1.5163e+03,  5.5886e+02,  1.0034e+03,  2.9667e+02,  2.9044e+01,
         -3.7772e+02, -4.6993e+02, -6.7163e+02, -8.0102e+02, -7.7229e+02,
         -8.4283e+02, -7.3839e+02, -6.6982e+02, -7.4854e+02, -7.8169e+02,
          6.5433e+01],
        [ 1.8479e+03,  7.5523e+02,  1.2500e+03,  4.9747e+02, -1.2979e+02,
         -2.5913e+02, -5.8119e+02, -8.8835e+02, -1.0323e+03, -1.2292e+03,
         -1.0674e+03, -8.5432e+02, -8.6753e+02, -1.1689e+03, -1.3980e+03,
         -2.6674e+02],
        [ 1.8925e+03,  5.7568e+02,  1.1725e+03,  5.9643e+02, -4.2055e+02,
         -5.1943e+02, -6.6631e+02, -1.0681e+03, -1.0718e+03, -1.1466e+03,
         -1.1212e+03, -1.3117e+03, -1.1507e+03, -1.2401e+03, -1.5802e+03,
         -3.7306e+02],
        [ 2.1842e+03,  5.9286e+02,  1.5042e+03,  1.0241e+03,  1.3955e+02,
         -4.3805e+02, -7.1356e+02, -1.2776e+03, -1.2422e+03, -1.5944e+03,
         -1.7176e+03, -1.5763e+03, -1.2553e+03, -1.4608e+03, -1.7222e+03,
         -5.5589e+02],
        [ 2.6084e+03,  7.6943e+02,  1.7961e+03,  1.7030e+03,  8.1730e+02,
         -1.0612e+02, -5.4088e+02, -1.1912e+03, -1.4062e+03, -1.5815e+03,
         -1.9244e+03, -1.8709e+03, -1.6753e+03, -1.7406e+03, -1.9825e+03,
         -6.1727e+02],
        [ 2.8267e+03,  8.8058e+02,  2.0372e+03,  1.6321e+03,  7.7483e+02,
          6.6967e+01, -5.2383e+02, -1.2038e+03, -1.4947e+03, -1.4983e+03,
         -1.3825e+03, -1.5369e+03, -1.2561e+03, -1.4329e+03, -1.4414e+03,
         -1.8588e+02],
        [ 2.7721e+03,  1.0590e+03,  1.8871e+03,  1.5214e+03,  9.0395e+02,
          9.6727e+01, -3.2304e+02, -9.5740e+02, -1.4747e+03, -1.0676e+03,
         -7.9231e+02, -8.0711e+02, -6.7920e+02, -8.9032e+02, -7.6600e+02,
          3.4722e+02],
        [ 2.3526e+03,  1.0371e+03,  1.7609e+03,  1.3974e+03,  7.8843e+02,
          1.9100e+02, -1.0940e+02, -3.9450e+02, -1.0338e+03, -8.4378e+02,
         -5.2761e+02, -4.2586e+02, -2.0357e+02, -4.0282e+02, -5.3433e+02,
          5.3867e+02],
        [ 1.9612e+03,  9.3147e+02,  1.5768e+03,  1.2571e+03,  9.5636e+02,
          3.2272e+02, -7.1379e+01,  1.8873e+01, -2.3592e+02, -4.2276e+02,
         -2.1051e+02, -4.8115e+01, -3.5647e+01,  4.6158e+00, -2.7766e+02,
          6.3469e+02],
        [ 1.6806e+03,  8.8744e+02,  1.2933e+03,  8.5759e+02,  6.5007e+02,
          2.6870e+02,  9.1045e+01,  2.1562e+02,  2.9895e+02,  1.6768e+02,
          3.3755e+01,  1.9270e+02,  2.5915e+02, -5.6118e+00, -1.0070e+02,
          5.4367e+02],
        [ 1.6945e+03,  1.0514e+03,  1.3853e+03,  9.6444e+02,  7.0313e+02,
          6.2151e+02,  4.9401e+02,  7.7506e+02,  7.8443e+02,  4.3283e+02,
          3.4869e+02,  3.9765e+02,  3.7998e+02,  3.6589e+02,  4.0042e+02,
          9.1688e+02],
        [ 1.3949e+03,  4.9150e+02,  9.9032e+02,  6.4767e+02,  4.3556e+02,
          4.8840e+02,  4.8577e+02,  5.6847e+02,  6.5939e+02,  5.4061e+02,
          5.1380e+02,  4.0442e+02,  4.0328e+02,  3.9544e+02,  4.4603e+02,
          8.3216e+02],
        [ 3.9146e+02, -4.2963e+02, -2.7129e+02, -8.2996e+02, -1.3128e+03,
         -1.5585e+03, -1.4993e+03, -1.4981e+03, -1.6165e+03, -1.6725e+03,
         -1.7822e+03, -1.5942e+03, -1.2954e+03, -1.4370e+03, -1.0890e+03,
         -4.5839e+02]], device='cuda:0')
LAYER_NUM:  0
FINAL_SUM:  [66, 43, 26, 91, 46, 4, 92, 29, 25, 75]
acts len:  3
acts keys:  ['conv0', 'conv1', 'conv2']
acts:  {'conv0': [66, 43, 26, 91, 46, 4, 92, 29, 25, 75, 77, 16, 67, 56, 84, 34, 11, 87, 69, 53, 80], 'conv1': [8, 61, 59, 247, 78, 63, 204, 147, 175, 116, 351, 49, 19, 324, 46, 66, 254, 71, 243, 120, 115], 'conv2': [268, 1323, 737, 660, 108, 1371, 1005, 451, 1412, 128, 196, 888, 205, 870, 75, 1039, 1174, 730, 325, 301, 272]}
final_sum len:  96
delta_weights INFO: 
NUM OF TRACKED COV LAYERS:  1
NUM OF TRACKED WEIGHTS CHANGES PER LAYER:  10
avg_deltas INFO:  <class 'dict'>
avg_deltas keys:  ['blocks.0.layer.weight', 'blocks.1.layer.weight', 'blocks.2.layer.weight']
avg_deltas size:  3
num of averages for 0 layer:  torch.Size([96])
################################################
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.45e-01	time: 00:00:18	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:3.406e-03/SW:5.882e-01/MR:4.749e+00/SR:1.851e+00/MeD:1.440e+00/MaD:4.287e+00/MW:0.601/MAW:0.399
|      0 |       1 |      2 |       3 |      4 |        5 |       6 |       7 |       8 |       9 |      10 |      11 |      12 |      13 |      14 |      15 |         16 |      17 |      18 |      19 |      20 |      21 |      22 |     23 |      24 |         25 |      26 |     27 |        28 |      29 |
|--------+---------+--------+---------+--------+----------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+------------+---------+---------+---------+---------+---------+---------+--------+---------+------------+---------+--------+-----------+---------|
|   0.16 |   0.112 |   0.13 |   0.139 |   0.14 |   0.0915 |   0.192 |   0.179 |   0.138 |   0.187 |   0.161 |   0.166 |   0.158 |   0.156 |   0.146 |   0.184 |   0.000327 |   0.165 |   0.169 |   0.181 |   0.191 |   0.187 |   0.143 |   0.2  |   0.197 |   0.000273 |   0.156 |   0.09 |   0.00154 |   0.199 |
|   4.99 |   2.96  |   3.64 |   4.01  |   4.05 |   2.31   |   6.77  |   6.02  |   3.98  |   6.46  |   5.04  |   5.32  |   4.92  |   4.82  |   4.33  |   6.26  |   1        |   5.25  |   5.46  |   6.1   |   6.68  |   6.45  |   4.19  |   7.22 |   7.07  |   1        |   4.81  |   2.27 |   1       |   7.18  |
|   0.53 |   0.47  |   0.48 |   0.52  |   0.53 |   0.51   |   0.56  |   0.45  |   0.5   |   0.51  |   0.42  |   0.54  |   0.4   |   0.42  |   0.41  |   0.64  |  22.65     |   0.53  |   0.46  |   0.47  |   0.55  |   0.54  |   0.46  |   0.53 |   0.52  |  24.03     |   0.37  |   0.4  |   0.93    |   0.64  |
| nan    | nan     | nan    | nan     | nan    | nan      | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan        | nan     | nan    | nan       | nan     |
| nan    | nan     | nan    | nan     | nan    | nan      | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan        | nan     | nan    | nan       | nan     |
| nan    | nan     | nan    | nan     | nan    | nan      | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan        | nan     | nan    | nan       | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([8, 8, 5, 8, 5, 8, 5, 5, 5, 5, 5, 8, 8, 8, 8, 8, 8, 8, 5, 8])
[5, 8]
TARGETS AFTER CLEANER:  tensor([1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([8, 5, 5, 5, 5, 8, 8, 5, 5, 5, 8, 8, 8, 5, 8, 5, 8, 8, 5, 8])
[5, 8]
TARGETS AFTER CLEANER:  tensor([1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([8, 5, 5, 5, 5, 8, 8, 5, 5, 5, 8, 8, 8, 5, 8, 5, 8, 8, 5, 8])
[5, 8]
TARGETS AFTER CLEANER:  tensor([1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_2C_CL
DEPTH:  3
ACTIVATIONS SHAPE:  tensor([[   0.7013,    7.0375,  -12.4448,  -40.1122,  -45.2690,  -39.8933,
          -40.6070,  -40.1434,  -47.5026,  -38.3792,  -26.7964,  -25.7825,
           -5.8262,   14.5358,    8.1903,   12.5222],
        [   5.1185,   -2.4660,   -9.3896,  -40.4319,  -37.2855,  -26.6543,
          -37.9776,  -52.7764,  -50.0571,  -30.3892,  -16.9386,  -38.9938,
          -19.9349,    2.1074,    2.6548,    8.3715],
        [  23.5807,   22.1243,   -6.8713,  -26.5503,  -22.5159,  -28.1393,
          -60.4006,  -67.7951,  -55.4446,  -38.3152,  -30.3433,  -18.0223,
            1.4711,    2.4975,    4.0010,   18.8147],
        [  27.7180,    4.0651,   -3.4871,    1.5031,   -4.9830,  -33.0443,
          -52.0668,  -62.1042,  -72.9748,  -71.1340,  -56.4650,  -45.6565,
          -11.9178,  -10.8329,    5.5198,   14.0209],
        [  11.3443,  -11.5908,  -25.3929,  -23.6566,  -38.3470,  -60.2236,
          -66.0772,  -86.4675,  -73.5551,  -65.6591,  -56.6977,  -63.6856,
          -38.4259,  -12.3108,   -0.3294,   13.4123],
        [  -1.0479,  -10.0494,  -15.4444,  -28.3598,  -55.1743,  -65.4804,
          -86.1975,  -79.5163,  -72.7395,  -65.6840,  -58.3535,  -81.3817,
          -51.5818,  -26.2452,   13.2673,   31.5999],
        [  12.1337,   30.9761,   -4.8433,  -41.1526,  -53.9514,  -69.9290,
          -70.9382,  -61.4469,  -47.9255,  -47.3619,  -73.7225, -106.1577,
          -59.1377,  -15.0730,   26.8433,   47.5040],
        [  31.0138,   31.6278,   13.0789,  -31.6283,  -63.9997,  -61.8592,
          -70.2114,  -95.7207,  -67.7843,  -60.4489,  -88.2214, -115.0095,
          -71.1317,  -40.7396,   11.3585,   34.6705],
        [   6.6953,   20.5867,  -10.8398,  -38.1258,  -66.2054,  -65.3196,
          -77.0879,  -81.0802,  -59.7271,  -55.9386,  -95.6868, -109.5653,
          -80.9763,  -60.2850,  -10.3189,   12.4384],
        [  18.2437,    6.6046,   -7.3437,  -32.3398,  -57.0806,  -58.8745,
          -62.3381,  -76.8265,  -74.6625,  -81.0889, -110.2735, -120.0962,
          -87.4989,  -85.1151,  -24.3510,  -18.0933],
        [  17.8022,   13.3154,   21.5664,  -11.5614,  -24.8938,  -39.7235,
          -57.0110,  -76.1687,  -89.9301,  -97.5199, -135.8005, -100.9479,
          -60.3581,  -50.3194,  -32.8428,  -19.4047],
        [   6.9951,   22.8785,   20.0281,    2.2877,    4.7480,  -18.4078,
          -38.5126,  -51.5557,  -37.2092,  -45.9068,  -56.3702,  -38.3593,
          -15.9143,  -14.8722,  -13.7402,   10.7488],
        [  19.9346,   25.9054,   10.0277,  -18.2094,    2.1679,   -2.4603,
          -36.5472,  -28.5716,  -17.5994,   -9.0920,   13.2793,    4.5393,
           -0.5832,    9.6632,   22.6418,   37.5729],
        [  28.9860,   18.5961,    9.9986,  -21.6150,  -30.6171,  -22.3482,
          -49.6097,  -60.6155,  -44.7217,   -2.7043,  -17.0856,   -4.5701,
            0.2450,   -1.4413,    0.6282,   16.8487],
        [  23.3615,    9.4080,   11.9315,  -17.2857,  -23.3940,  -29.6651,
          -32.6928,  -29.5299,  -32.6761,   -3.1603,   -6.8371,   15.4504,
           22.6235,   21.5919,  -13.7394,    8.0217],
        [  19.2134,    7.2116,   -8.9471,  -20.2975,  -40.6331,  -35.7638,
          -55.0260,  -58.7811,  -36.0840,  -11.8058,  -11.3305,  -22.2692,
          -19.3510,   -0.3128,   -6.5420,   -7.9572]], device='cuda:0')
LAYER_NUM:  1
FINAL_SUM:  [61, 78, 19, 66, 247, 63, 116, 46, 8, 243]
acts len:  3
acts keys:  ['conv0', 'conv1', 'conv2']
acts:  {'conv0': [66, 43, 26, 91, 46, 4, 92, 29, 25, 75, 77, 16, 67, 56, 84, 34, 11, 87, 69, 53, 80], 'conv1': [61, 78, 19, 66, 247, 63, 116, 46, 8, 243, 359, 59, 49, 175, 291, 204, 293, 324, 290, 125, 259], 'conv2': [268, 1323, 737, 660, 108, 1371, 1005, 451, 1412, 128, 196, 888, 205, 870, 75, 1039, 1174, 730, 325, 301, 272]}
final_sum len:  384
delta_weights INFO: 
NUM OF TRACKED COV LAYERS:  1
NUM OF TRACKED WEIGHTS CHANGES PER LAYER:  10
avg_deltas INFO:  <class 'dict'>
avg_deltas keys:  ['blocks.0.layer.weight', 'blocks.1.layer.weight', 'blocks.2.layer.weight']
avg_deltas size:  3
num of averages for 1 layer:  torch.Size([96])
################################################
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.45e-01	time: 00:00:41	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:5.711e-03/SW:2.087e-01/MR:5.981e+00/SR:1.376e+00/MeD:1.049e+00/MaD:4.981e+00/MW:0.570/MAW:0.430
|        0 |        1 |         2 |         3 |       4 |        5 |        6 |         7 |        8 |        9 |       10 |       11 |       12 |       13 |       14 |       15 |       16 |       17 |        18 |       19 |       20 |       21 |       22 |       23 |        24 |       25 |       26 |        27 |       28 |       29 |
|----------+----------+-----------+-----------+---------+----------+----------+-----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+-----------+----------+----------+----------+----------+----------+-----------+----------+----------+-----------+----------+----------|
|   0.0111 |   0.0102 |   0.00966 |   0.00691 |   0.008 |   0.0117 |   0.0104 |   0.00715 |   0.0118 |   0.0103 |   0.0113 |   0.0118 |   0.0111 |   0.0131 |   0.0118 |   0.0119 |   0.0106 |   0.0121 |   0.00836 |   0.0118 |   0.0116 |   0.0131 |   0.0116 |   0.0142 |   0.00928 |   0.0133 |   0.0127 |   0.00909 |   0.0136 |   0.0101 |
|   5.97   |   5.12   |   4.73    |   2.91    |   3.56  |   6.52   |   5.32   |   3.05    |   6.53   |   5.26   |   6.1    |   6.56   |   5.96   |   7.87   |   6.52   |   6.67   |   5.5    |   6.88   |   3.79    |   6.54   |   6.43   |   7.92   |   6.34   |   9.07   |   4.45    |   8.03   |   7.47   |   4.3     |   8.44   |   5.11   |
|   0.22   |   0.12   |   0.17    |   0.18    |   0.32  |   0.15   |   0.17   |   0.23    |   0.25   |   0.14   |   0.19   |   0.24   |   0.22   |   0.21   |   0.15   |   0.17   |   0.13   |   0.21   |   0.2     |   0.33   |   0.2    |   0.21   |   0.33   |   0.16   |   0.3     |   0.28   |   0.13   |   0.23    |   0.12   |   0.27   |
| nan      | nan      | nan       | nan       | nan     | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan       | nan      | nan      |
| nan      | nan      | nan       | nan       | nan     | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan       | nan      | nan      |
| nan      | nan      | nan       | nan       | nan     | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan       | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([8, 8, 5, 8, 5, 8, 5, 5, 5, 5, 5, 8, 8, 8, 8, 8, 8, 8, 5, 8])
[5, 8]
TARGETS AFTER CLEANER:  tensor([1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([8, 5, 5, 5, 5, 8, 8, 5, 5, 5, 8, 8, 8, 5, 8, 5, 8, 8, 5, 8])
[5, 8]
TARGETS AFTER CLEANER:  tensor([1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([8, 5, 5, 5, 5, 8, 8, 5, 5, 5, 8, 8, 8, 5, 8, 5, 8, 8, 5, 8])
[5, 8]
TARGETS AFTER CLEANER:  tensor([1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_2C_CL
DEPTH:  3
ACTIVATIONS SHAPE:  tensor([[ -8.2955,  -3.1788, -12.4067, -25.1162, -20.7716, -19.3917, -19.8167,
         -20.3882, -22.3541, -16.0536,  -7.8715,  -5.2098,   4.9293,  11.6019,
           4.9632,   2.8294],
        [ -4.0575,  -7.8753,  -8.0105, -20.9785, -16.4690,  -6.9836, -14.1747,
         -21.2898, -17.9308,  -5.9095,   3.5492,  -8.2102,   0.4784,   8.5570,
           4.8266,   2.6646],
        [  8.2465,   8.7284,  -4.8381, -11.4021,  -4.7447,  -6.9331, -19.4693,
         -17.3081,  -7.8371,   1.5298,   7.2133,  16.3495,  25.6212,  16.4289,
           9.2772,  10.5769],
        [ 11.7022,  -2.7977,  -1.3466,   8.9809,   6.1962,  -4.8736,  -5.8942,
          -3.1136,  -5.1940,  -4.0458,   1.3820,   7.4821,  24.0799,  17.1116,
          15.4733,  13.6989],
        [  6.2328,  -9.6907, -10.5503,  -4.7621, -11.5491, -17.1527, -10.7320,
         -12.7526,  -0.5769,   6.3461,  11.1722,   4.4549,  13.1976,  22.5724,
          22.3769,  23.5324],
        [  3.1520,  -2.2539,   0.7003,  -3.1091, -15.6381, -14.8245, -18.2996,
          -8.9814,   1.2237,   7.5269,  11.8065,  -4.6398,  11.7708,  23.6924,
          36.1088,  40.5655],
        [ 12.2315,  20.2053,   7.3448,  -7.5631, -12.0898, -15.3240,  -9.6970,
           0.2160,  13.2354,  16.8723,  -2.6073, -24.9372,   1.0694,  29.9224,
          45.0526,  52.1745],
        [ 22.0751,  19.4742,  19.5969,   2.5839, -13.6508,  -7.1325,  -7.2856,
         -19.5351,  -0.5307,   5.0837, -13.8169, -32.5366,  -8.6732,  12.9904,
          37.0806,  43.6181],
        [  6.6728,  12.3474,   2.4587,  -5.5433, -14.0201,  -7.9378, -12.3946,
         -13.4989,   1.9879,   5.7290, -18.8072, -26.0191, -11.6225,   0.7010,
          22.4357,  29.3423],
        [ 10.5184,   4.5237,   5.0847,  -5.4102, -10.6329,  -6.9746,  -8.5976,
         -16.4431, -12.0254, -14.6853, -27.2792, -33.1186, -16.8138, -18.9069,
          12.7813,   9.1089],
        [  5.5843,   4.5342,  14.4820,   5.0032,   6.8062,   3.3748,  -4.7503,
         -15.0081, -21.4638, -27.8723, -43.9792, -23.8056,  -4.9567,  -3.6785,
           3.3664,   6.9035],
        [ -4.1919,   3.4654,  10.9379,   8.0718,  19.6542,  11.5900,  -0.2201,
          -6.1967,   4.9374,  -0.1284,  -2.1419,   7.8971,  12.6806,  12.2858,
           7.3152,  18.6779],
        [ -1.1759,   0.5888,   1.3750,  -5.7084,  15.2798,  17.0042,  -0.3792,
           5.0532,  14.8066,  20.0834,  31.4867,  24.8016,  13.8930,  15.0445,
          20.8119,  26.5802],
        [  0.7023,  -6.7442,  -3.8831, -14.5758, -11.6835,  -3.6127, -15.6954,
         -19.0369,  -7.4807,  14.5970,   4.1173,  10.8553,   8.1621,   3.5444,
           2.1797,   8.6710],
        [ -5.6393, -14.7624,  -7.2784, -15.7121, -13.9714, -13.5824, -10.6893,
          -7.7560,  -7.6952,   8.1253,   2.9152,  13.6752,  13.8257,   9.2283,
         -11.6127,   0.0731],
        [ -8.0254, -16.4041, -18.1722, -20.2160, -27.5925, -23.1914, -25.2670,
         -25.8917, -12.4424,   1.2358,  -1.1413,  -9.3674, -10.3694,  -2.9369,
          -9.8890, -11.0311]], device='cuda:0')
LAYER_NUM:  2
FINAL_SUM:  [1323, 870, 128, 1174, 1141, 660, 117, 268, 1490, 1154]
acts len:  3
acts keys:  ['conv0', 'conv1', 'conv2']
acts:  {'conv0': [66, 43, 26, 91, 46, 4, 92, 29, 25, 75, 77, 16, 67, 56, 84, 34, 11, 87, 69, 53, 80], 'conv1': [61, 78, 19, 66, 247, 63, 116, 46, 8, 243, 359, 59, 49, 175, 291, 204, 293, 324, 290, 125, 259], 'conv2': [1323, 870, 128, 1174, 1141, 660, 117, 268, 1490, 1154, 605, 1383, 1483, 832, 519, 627, 301, 1458, 1530, 97, 1412]}
final_sum len:  1536
delta_weights INFO: 
NUM OF TRACKED COV LAYERS:  1
NUM OF TRACKED WEIGHTS CHANGES PER LAYER:  10
avg_deltas INFO:  <class 'dict'>
avg_deltas keys:  ['blocks.0.layer.weight', 'blocks.1.layer.weight', 'blocks.2.layer.weight']
avg_deltas size:  3
num of averages for 2 layer:  torch.Size([96])
################################################
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.20e-02	time: 00:01:24	Acc_train 0.00	Acc_test 0.00	convergence: 1.77e+01	R1: 1	Info MB:0.000e+00/SB:0.000e+00/MW:4.084e-03/SW:3.209e-01/MR:1.872e+01/SR:2.367e+00/MeD:1.820e+00/MaD:1.772e+01/MW:0.436/MAW:0.564
|        0 |       1 |        2 |        3 |        4 |        5 |        6 |        7 |        8 |       9 |       10 |       11 |       12 |       13 |       14 |       15 |       16 |       17 |      18 |      19 |       20 |       21 |       22 |       23 |       24 |       25 |       26 |       27 |       28 |      29 |
|----------+---------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+---------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------|
|   0.0421 |   0.041 |   0.0433 |   0.0378 |   0.0418 |   0.0447 |   0.0429 |   0.0386 |   0.0422 |   0.045 |   0.0418 |   0.0421 |   0.0429 |   0.0396 |   0.0422 |   0.0391 |   0.0415 |   0.0433 |   0.044 |   0.039 |   0.0401 |   0.0385 |   0.0153 |   0.0472 |   0.0434 |   0.0362 |   0.0419 |   0.0408 |   0.0405 |   0.043 |
|  18.71   |  17.84  |  19.76   |  15.26   |  18.43   |  21      |  19.4    |  15.86   |  18.77   |  21.27  |  18.45   |  18.7    |  19.42   |  16.64   |  18.83   |  16.27   |  18.24   |  19.75   |  20.36  |  16.24  |  17.06   |  15.86   |   3.34   |  23.24   |  19.84   |  14.1    |  18.58   |  17.64   |  17.39   |  19.51  |
|   0.06   |   0.05  |   0.07   |   0.09   |   0.04   |   0.03   |   0.11   |   0.03   |   0.08   |   0.06  |   0.08   |   0.1    |   0.15   |   0.02   |   0.11   |   0.05   |   0.05   |   0.12   |   0.02  |   0.04  |   0.06   |   0.06   |   0.04   |   0.05   |   0.05   |   0.05   |   0.08   |   0.04   |   0.05   |   0.04  |
| nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     |
| nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     |
| nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models

 ********** Supervised learning of blocks [3] **********
SAVING FOLDER FOR SUP:  C10_2C_CL
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([8, 8, 5, 8, 5, 8, 5, 5, 5, 5, 5, 8, 8, 8, 8, 8, 8, 8, 5, 8])
[5, 8]
TARGETS AFTER CLEANER:  tensor([1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([8, 5, 5, 5, 5, 8, 8, 5, 5, 5, 8, 8, 8, 5, 8, 5, 8, 8, 5, 8])
[5, 8]
TARGETS AFTER CLEANER:  tensor([1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([8, 5, 5, 5, 5, 8, 8, 5, 5, 5, 8, 8, 8, 5, 8, 5, 8, 8, 5, 8])
[5, 8]
TARGETS AFTER CLEANER:  tensor([1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Epoch: [1/50]	lr: 1.00e-03	time: 00:01:38	Loss_train 0.22834	Acc_train 91.31	/	Loss_test 0.00482	Acc_test 95.40
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [10/50]	lr: 1.00e-03	time: 00:01:43	Loss_train 0.03444	Acc_train 97.63	/	Loss_test 0.00317	Acc_test 97.40
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [20/50]	lr: 2.50e-04	time: 00:01:47	Loss_train 0.00981	Acc_train 99.10	/	Loss_test 0.00222	Acc_test 98.05
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [30/50]	lr: 1.25e-04	time: 00:01:52	Loss_train 0.00567	Acc_train 99.38	/	Loss_test 0.00208	Acc_test 97.95
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [40/50]	lr: 3.13e-05	time: 00:01:57	Loss_train 0.00339	Acc_train 99.56	/	Loss_test 0.00188	Acc_test 98.20
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
Epoch: [50/50]	lr: 7.81e-06	time: 00:02:01	Loss_train 0.00293	Acc_train 99.63	/	Loss_test 0.00191	Acc_test 98.15
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_2C_CL/models
RESULT:  {'train_loss': 0.002930729417130351, 'train_acc': 99.62700009346008, 'test_loss': 0.0019144368125125766, 'test_acc': 98.1500015258789, 'convergence': 17.719533920288086, 'R1': 1, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [5, 8]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [5, 8]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}
IN R2:  {'R1': {'train_loss': 0.004077428486198187, 'train_acc': 99.44199919700623, 'test_loss': 0.0029496969655156136, 'test_acc': 97.4000015258789, 'convergence': 20.599519729614258, 'R1': 0, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [0, 6]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [0, 6]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}, 'R2': {'train_loss': 0.002930729417130351, 'train_acc': 99.62700009346008, 'test_loss': 0.0019144368125125766, 'test_acc': 98.1500015258789, 'convergence': 17.719533920288086, 'R1': 1, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [5, 8]}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [5, 8]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}

 Model C10_2C_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=2, bias=True)
[Sequential(
  (0): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=0.7)
  )
  (1): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=1.4)
  )
  (2): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (activation): Triangle(power=1.0)
  )
  (3): BasicBlock(
    (operations): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
    )
    (layer): Linear(in_features=24576, out_features=2, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
)]
LAYER NAME:  Sequential(
  (0): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=0.7)
  )
  (1): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=1.4)
  )
  (2): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (activation): Triangle(power=1.0)
  )
  (3): BasicBlock(
    (operations): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
    )
    (layer): Linear(in_features=24576, out_features=2, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
)
LAYER CHILDREN:  [BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
  (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
  (activation): Triangle(power=0.7)
), BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
  (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
  (activation): Triangle(power=1.4)
), BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (activation): Triangle(power=1.0)
), BasicBlock(
  (operations): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
  )
  (layer): Linear(in_features=24576, out_features=2, bias=True)
  (dropout): Dropout(p=0.5, inplace=False)
)]
subsubl NAME:  Sequential(
  (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
subsubl NAME:  Triangle(power=0.7)
subsubl NAME:  Sequential(
  (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
subsubl NAME:  Triangle(power=1.4)
subsubl NAME:  Sequential(
  (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  AvgPool2d(kernel_size=2, stride=2, padding=0)
subsubl NAME:  Triangle(power=1.0)
subsubl NAME:  Sequential(
  (0): Flatten(start_dim=1, end_dim=-1)
)
subsubl NAME:  Linear(in_features=24576, out_features=2, bias=True)
subsubl NAME:  Dropout(p=0.5, inplace=False)
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([0, 6, 6, 6, 0, 6, 0, 0, 6, 6, 6, 6, 0, 6, 0, 6, 6, 6, 6, 0])
[0, 6]
TARGETS AFTER CLEANER:  tensor([0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0])
2000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 2000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 6, 6, 6, 6, 0, 0, 0, 0, 6, 0, 0, 6, 6, 6, 0, 0, 6, 6, 6])
[0, 6]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               ToTensor()
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)
           )
------------------------
TARGETS BEFORE SUB:  tensor([6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6],
       device='cuda:0')
TARGETS AFTER SUB:  tensor([6, 6, 6, 6, 6, 0, 0, 0, 0, 6, 0, 0, 6, 6, 6, 0, 0, 6, 6, 6])
[0, 6]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1])
10000
<class 'dataset.FastCIFAR10'>
Dataset FastCIFAR10
    Number of datapoints: 10000
    Root location: /leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: ToTensor()
------------------------
INDICES:  10000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Accuracy of the network on the 1st dataset: 17.700 %
Test loss on the 1st dataset: 0.316

