BLOCKS:  {'b0': {'arch': 'CNN', 'preset': 'softkrotov-c96-k5-p2-s1-d1-b0-t1-lr0.08-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 0, 'batch_norm': False, 'pool': {'type': 'max', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 0.7}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5}}, 'b1': {'arch': 'CNN', 'preset': 'softkrotov-c384-k3-p1-s1-d1-b0-t0.65-lr0.005-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 1, 'batch_norm': False, 'pool': {'type': 'max', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 1.4}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3}}, 'b2': {'arch': 'CNN', 'preset': 'softkrotov-c1536-k3-p1-s1-d1-b0-t0.25-lr0.01-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 2, 'batch_norm': False, 'pool': {'type': 'avg', 'kernel_size': 2, 'stride': 2, 'padding': 0}, 'activation': {'function': 'triangle', 'param': 1.0}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3}}, 'b3': {'arch': 'MLP', 'preset': 'BP-c10', 'operation': 'flatten', 'num': 3, 'att_dropout': None, 'dropout': 0.5, 'layer': {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.25, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10}, 'pool': None, 'activation': None}}
CL:  True
{'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 100, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True}
CL:  True
{'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 100, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 50, 'validation': False, 'continual_learning': True}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.11048543456039805, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 2, 'in_channels': 24576, 'old_channels': 1536, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=2, bias=True)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([73, 73, 73, 73, 79, 79, 79, 73, 79, 79, 73, 73, 73, 79, 73, 79, 79, 79,
        73, 79])
[73, 79]
TARGETS AFTER CLEANER:  tensor([0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1])
200
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 200
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([73, 73, 79, 79, 79, 73, 79, 79, 73, 73, 79, 79, 73, 79, 73, 79, 79, 73,
        79, 73])
[73, 79]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([73, 73, 79, 79, 79, 73, 79, 79, 73, 73, 79, 79, 73, 79, 73, 79, 79, 73,
        79, 73])
[73, 79]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  1000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_2C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 2.86e-01	time: 00:00:12	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:-1.315e-02/SW:1.664e+00/MR:1.401e+01/SR:3.410e+00/MeD:2.719e+00/MaD:9.094e+00/MW:0.610/MAW:0.390
|       0 |       1 |       2 |       3 |       4 |       5 |       6 |       7 |       8 |       9 |      10 |      11 |     12 |      13 |      14 |      15 |     16 |      17 |      18 |      19 |      20 |      21 |      22 |      23 |      24 |      25 |      26 |      27 |     28 |      29 |
|---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+--------+---------+---------+---------+--------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+--------+---------|
|   0.278 |   0.355 |   0.337 |   0.336 |   0.248 |   0.225 |   0.283 |   0.344 |   0.257 |   0.376 |   0.257 |   0.285 |   0.31 |   0.339 |   0.277 |   0.336 |   0.21 |   0.297 |   0.293 |   0.267 |   0.317 |   0.281 |   0.308 |   0.356 |   0.346 |   0.225 |   0.319 |   0.269 |   0.31 |   0.354 |
|  13.12  |  20.72  |  18.73  |  18.69  |  10.64  |   8.88  |  13.54  |  19.5   |  11.32  |  23.1   |  11.3   |  13.68  |  16.02 |  18.97  |  12.97  |  18.64  |   7.86 |  14.77  |  14.39  |  12.12  |  16.7   |  13.3   |  15.82  |  20.86  |  19.66  |   8.92  |  16.95  |  12.29  |  16.01 |  20.59  |
|   0.73  |   0.11  |   0.05  |   0.17  |   1.74  |   2.66  |   1.1   |   0.25  |   1.46  |   0.05  |   1.78  |   0.61  |   0.58 |   0.19  |   1.73  |   0.12  |   3.35 |   0.53  |   0.63  |   1.36  |   0.49  |   0.88  |   0.55  |   0.2   |   0.28  |   2.27  |   0.41  |   1.03  |   0.27 |   0.09  |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([73, 73, 73, 73, 79, 79, 79, 73, 79, 79, 73, 73, 73, 79, 73, 79, 79, 79,
        73, 79])
[73, 79]
TARGETS AFTER CLEANER:  tensor([0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1])
200
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 200
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([73, 73, 79, 79, 79, 73, 79, 79, 73, 73, 79, 79, 73, 79, 73, 79, 79, 73,
        79, 73])
[73, 79]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([73, 73, 79, 79, 79, 73, 79, 79, 73, 73, 79, 79, 73, 79, 73, 79, 79, 73,
        79, 73])
[73, 79]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  1000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_2C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 2.86e-01	time: 00:00:22	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:-3.235e-03/SW:8.292e-01/MR:2.433e+01/SR:1.422e+00/MeD:9.210e-01/MaD:6.968e+00/MW:0.786/MAW:0.214
|        0 |        1 |        2 |        3 |       4 |        5 |        6 |        7 |        8 |        9 |       10 |       11 |       12 |       13 |       14 |       15 |       16 |      17 |       18 |       19 |       20 |       21 |       22 |       23 |       24 |      25 |       26 |       27 |       28 |       29 |
|----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------|
|   0.0247 |   0.0246 |   0.0242 |   0.0242 |   0.022 |   0.0251 |   0.0245 |   0.0251 |   0.0244 |   0.0242 |   0.0248 |   0.0242 |   0.0248 |   0.0246 |   0.0242 |   0.0243 |   0.0241 |   0.024 |   0.0243 |   0.0247 |   0.0239 |   0.0248 |   0.0245 |   0.0247 |   0.0242 |   0.024 |   0.0241 |   0.0242 |   0.0244 |   0.0251 |
|  25.39   |  25.12   |  24.49   |  24.35   |  20.38  |  26.18   |  24.92   |  26.19   |  24.87   |  24.35   |  25.62   |  24.34   |  25.55   |  25.18   |  24.48   |  24.55   |  24.19   |  24     |  24.57   |  25.31   |  23.84   |  25.69   |  25.1    |  25.42   |  24.5    |  23.99  |  24.24   |  24.44   |  24.73   |  26.13   |
|   0.02   |   0      |   0      |   0      |   2.21  |   0.08   |   0.01   |   0.03   |   0      |   0.08   |   0      |   0.01   |   0.03   |   0.02   |   0.01   |   0.03   |   0.01   |   0.38  |   0.07   |   0.12   |   0.04   |   0      |   0.06   |   0.04   |   0.03   |   0.06  |   0.47   |   0.03   |   0.12   |   0.01   |
| nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([73, 73, 73, 73, 79, 79, 79, 73, 79, 79, 73, 73, 73, 79, 73, 79, 79, 79,
        73, 79])
[73, 79]
TARGETS AFTER CLEANER:  tensor([0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1])
200
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 200
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([73, 73, 79, 79, 79, 73, 79, 79, 73, 73, 79, 79, 73, 79, 73, 79, 79, 73,
        79, 73])
[73, 79]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([73, 73, 79, 79, 79, 73, 79, 79, 73, 73, 79, 79, 73, 79, 73, 79, 79, 73,
        79, 73])
[73, 79]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  1000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_2C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.86e-02	time: 00:00:32	Acc_train 0.00	Acc_test 0.00	convergence: 2.36e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.129e-04/SW:4.194e-01/MR:2.463e+01/SR:1.243e+00/MeD:7.668e-01/MaD:8.694e+00/MW:0.486/MAW:0.514
|        0 |        1 |        2 |        3 |        4 |        5 |        6 |       7 |        8 |       9 |       10 |       11 |       12 |       13 |       14 |       15 |       16 |       17 |       18 |       19 |       20 |      21 |       22 |       23 |       24 |       25 |       26 |       27 |       28 |       29 |
|----------+----------+----------+----------+----------+----------+----------+---------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------|
|   0.0491 |   0.0492 |   0.0489 |   0.0489 |   0.0485 |   0.0487 |   0.0494 |   0.047 |   0.0489 |   0.049 |   0.0494 |   0.0494 |   0.0487 |   0.0453 |   0.0496 |   0.0496 |   0.0464 |   0.0497 |   0.0485 |   0.0493 |   0.0472 |   0.049 |   0.0494 |   0.0493 |   0.0481 |   0.0492 |   0.0491 |   0.0499 |   0.0489 |   0.0489 |
|  25.06   |  25.17   |  24.88   |  24.9    |  24.5    |  24.72   |  25.43   |  23.06  |  24.9    |  25.02  |  25.43   |  25.39   |  24.69   |  21.53   |  25.62   |  25.59   |  22.49   |  25.66   |  24.52   |  25.27   |  23.28   |  25.04  |  25.44   |  25.26   |  24.12   |  25.17   |  25.08   |  25.92   |  24.87   |  24.88   |
|   0      |   0.01   |   0.02   |   0.06   |   0.03   |   0.01   |   0      |   0.07  |   0.04   |   0     |   0.01   |   0.04   |   0.07   |   0.15   |   0.09   |   0.03   |   0.53   |   0      |   0.04   |   0      |   0.2    |   0.05  |   0.12   |   0.03   |   0.07   |   0.01   |   0.01   |   0.03   |   0.06   |   0.01   |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models

 ********** Supervised learning of blocks [3] **********
SAVING FOLDER FOR SUP:  C100_2C_CL
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([73, 73, 73, 73, 79, 79, 79, 73, 79, 79, 73, 73, 73, 79, 73, 79, 79, 79,
        73, 79])
[73, 79]
TARGETS AFTER CLEANER:  tensor([0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1])
200
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 200
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([73, 73, 79, 79, 79, 73, 79, 79, 73, 73, 79, 79, 73, 79, 73, 79, 79, 73,
        79, 73])
[73, 79]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([73, 73, 79, 79, 79, 73, 79, 79, 73, 73, 79, 79, 73, 79, 73, 79, 79, 73,
        79, 73])
[73, 79]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  1000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Epoch: [1/50]	lr: 1.00e-03	time: 00:00:41	Loss_train 0.64905	Acc_train 78.70	/	Loss_test 0.13764	Acc_test 86.50
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models
Epoch: [10/50]	lr: 1.00e-03	time: 00:00:42	Loss_train 0.07493	Acc_train 94.97	/	Loss_test 0.03356	Acc_test 92.50
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models
Epoch: [20/50]	lr: 2.50e-04	time: 00:00:43	Loss_train 0.00392	Acc_train 99.05	/	Loss_test 0.02979	Acc_test 91.50
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models
Epoch: [30/50]	lr: 1.25e-04	time: 00:00:43	Loss_train 0.00080	Acc_train 99.67	/	Loss_test 0.02871	Acc_test 92.00
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models
Epoch: [40/50]	lr: 3.13e-05	time: 00:00:44	Loss_train 0.00055	Acc_train 99.74	/	Loss_test 0.02640	Acc_test 93.00
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models
Epoch: [50/50]	lr: 7.81e-06	time: 00:00:45	Loss_train 0.00067	Acc_train 99.73	/	Loss_test 0.02637	Acc_test 92.50
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models
RESULT:  {'train_loss': 0.000665066996589303, 'train_acc': 99.73000288009644, 'test_loss': 0.02636909671127796, 'test_acc': 92.5, 'convergence': 23.626317977905273, 'R1': 0, 'dataset_sup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [73, 79]}, 'dataset_unsup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 50, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [73, 79]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}
IN R1:  {'R1': {'train_loss': 0.000665066996589303, 'train_acc': 99.73000288009644, 'test_loss': 0.02636909671127796, 'test_acc': 92.5, 'convergence': 23.626317977905273, 'R1': 0, 'dataset_sup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [73, 79]}, 'dataset_unsup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 50, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [73, 79]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.11048543456039805, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 2, 'in_channels': 24576, 'old_channels': 1536, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 Model C100_2C_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=2, bias=True)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 8,  8, 20, 20,  8, 20, 20,  8,  8,  8,  8,  8,  8, 20, 20,  8,  8, 20,
        20,  8])
[8, 20]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0])
200
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 200
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 8,  8, 20, 20,  8, 20,  8,  8, 20, 20, 20, 20,  8, 20,  8, 20, 20,  8,
         8,  8])
[8, 20]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 8,  8, 20, 20,  8, 20,  8,  8, 20, 20, 20, 20,  8, 20,  8, 20, 20,  8,
         8,  8])
[8, 20]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  1000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_2C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 2.26e-01	time: 00:00:09	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:-2.131e-03/SW:1.074e+00/MR:9.099e+00/SR:1.950e+00/MeD:1.551e+00/MaD:5.077e+00/MW:0.506/MAW:0.494
|      0 |       1 |       2 |       3 |       4 |       5 |       6 |       7 |       8 |       9 |      10 |      11 |      12 |      13 |     14 |     15 |      16 |     17 |      18 |      19 |      20 |      21 |      22 |      23 |      24 |      25 |     26 |      27 |      28 |      29 |
|--------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+--------+--------+---------+--------+---------+---------+---------+---------+---------+---------+---------+---------+--------+---------+---------+---------|
|   0.2  |   0.266 |   0.246 |   0.254 |   0.212 |   0.213 |   0.222 |   0.285 |   0.215 |   0.285 |   0.209 |   0.211 |   0.241 |   0.236 |   0.2  |   0.25 |   0.182 |   0.22 |   0.238 |   0.228 |   0.252 |   0.213 |   0.222 |   0.254 |   0.246 |   0.168 |   0.25 |   0.243 |   0.212 |   0.267 |
|   7.22 |  12.04  |  10.44  |  11.11  |   8.05  |   8.08  |   8.71  |  13.73  |   8.25  |  13.66  |   7.85  |   7.95  |  10.05  |   9.69  |   7.22 |  10.74 |   6.2   |   8.55 |   9.85  |   9.09  |  10.93  |   8.11  |   8.71  |  11.12  |  10.43  |   5.44  |  10.78 |  10.23  |   8.03  |  12.14  |
|   0.56 |   0.44  |   0.45  |   0.45  |   0.82  |   4.85  |   0.56  |   0.34  |   0.95  |   0.44  |   0.79  |   0.59  |   0.51  |   0.55  |   1.48 |   0.45 |   3.15  |   0.56 |   0.62  |   0.71  |   0.58  |   1.1   |   0.45  |   0.5   |   0.54  |   2.79  |   0.37 |   0.29  |   0.56  |   0.45  |
| nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan    | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     |
| nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan    | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     |
| nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan    | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 8,  8, 20, 20,  8, 20, 20,  8,  8,  8,  8,  8,  8, 20, 20,  8,  8, 20,
        20,  8])
[8, 20]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0])
200
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 200
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 8,  8, 20, 20,  8, 20,  8,  8, 20, 20, 20, 20,  8, 20,  8, 20, 20,  8,
         8,  8])
[8, 20]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 8,  8, 20, 20,  8, 20,  8,  8, 20, 20, 20, 20,  8, 20,  8, 20, 20,  8,
         8,  8])
[8, 20]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  1000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_2C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 2.26e-01	time: 00:00:19	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:-3.180e-03/SW:7.866e-01/MR:2.299e+01/SR:2.414e+00/MeD:1.888e+00/MaD:9.022e+00/MW:0.743/MAW:0.257
|        0 |        1 |        2 |        3 |      4 |        5 |        6 |        7 |        8 |        9 |       10 |       11 |       12 |       13 |       14 |       15 |      16 |       17 |       18 |       19 |       20 |       21 |       22 |       23 |       24 |       25 |       26 |       27 |       28 |       29 |
|----------+----------+----------+----------+--------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------|
|   0.0241 |   0.0245 |   0.0242 |   0.0241 |   0.02 |   0.0239 |   0.0238 |   0.0246 |   0.0242 |   0.0235 |   0.0248 |   0.0238 |   0.0246 |   0.0243 |   0.0242 |   0.0241 |   0.024 |   0.0221 |   0.0237 |   0.0239 |   0.0234 |   0.0248 |   0.0241 |   0.0236 |   0.0239 |   0.0238 |   0.0225 |   0.0236 |   0.0236 |   0.0249 |
|  24.24   |  25.01   |  24.45   |  24.33   |  17.05 |  23.89   |  23.72   |  25.14   |  24.39   |  23.13   |  25.6    |  23.63   |  25.29   |  24.59   |  24.47   |  24.31   |  24.04  |  20.46   |  23.51   |  23.89   |  22.94   |  25.64   |  24.27   |  23.24   |  23.8    |  23.57   |  21.16   |  23.32   |  23.21   |  25.82   |
|   0.17   |   0.02   |   0.03   |   0.01   |   1.01 |   0.27   |   0.22   |   0.15   |   0.07   |   0.21   |   0      |   0.11   |   0.07   |   0.16   |   0.02   |   0.05   |   0.03  |   0.75   |   0.13   |   0.25   |   0.16   |   0.01   |   0.27   |   0.43   |   0.15   |   0.14   |   0.65   |   0.16   |   0.2    |   0.08   |
| nan      | nan      | nan      | nan      | nan    | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan    | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan    | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 8,  8, 20, 20,  8, 20, 20,  8,  8,  8,  8,  8,  8, 20, 20,  8,  8, 20,
        20,  8])
[8, 20]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0])
200
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 200
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 8,  8, 20, 20,  8, 20,  8,  8, 20, 20, 20, 20,  8, 20,  8, 20, 20,  8,
         8,  8])
[8, 20]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 8,  8, 20, 20,  8, 20,  8,  8, 20, 20, 20, 20,  8, 20,  8, 20, 20,  8,
         8,  8])
[8, 20]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  1000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_2C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.82e-02	time: 00:00:29	Acc_train 0.00	Acc_test 0.00	convergence: 2.33e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.310e-04/SW:4.144e-01/MR:2.429e+01/SR:1.857e+00/MeD:1.337e+00/MaD:1.018e+01/MW:0.469/MAW:0.531
|        0 |        1 |        2 |        3 |        4 |        5 |        6 |       7 |        8 |        9 |       10 |      11 |       12 |       13 |       14 |       15 |       16 |       17 |       18 |       19 |      20 |       21 |      22 |       23 |       24 |       25 |       26 |       27 |       28 |       29 |
|----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+---------+----------+----------+----------+----------+----------+----------+----------|
|   0.0492 |   0.0482 |   0.0497 |   0.0472 |   0.0476 |   0.0487 |   0.0496 |   0.046 |   0.0496 |   0.0491 |   0.0496 |   0.048 |   0.0484 |   0.0429 |   0.0493 |   0.0487 |   0.0466 |   0.0499 |   0.0477 |   0.0495 |   0.045 |   0.0491 |   0.049 |   0.0496 |   0.0481 |   0.0495 |   0.0492 |   0.0489 |   0.0472 |   0.0486 |
|  25.17   |  24.21   |  25.73   |  23.31   |  23.68   |  24.76   |  25.56   |  22.14  |  25.61   |  25.1    |  25.6    |  24.06  |  24.47   |  19.43   |  25.35   |  24.69   |  22.75   |  25.87   |  23.74   |  25.53   |  21.26  |  25.07   |  25.05  |  25.56   |  24.18   |  25.47   |  25.18   |  24.88   |  23.27   |  24.66   |
|   0      |   0.03   |   0.06   |   0.23   |   0.05   |   0.03   |   0.02   |   0.05  |   0.06   |   0      |   0.04   |   0.11  |   0.05   |   0.13   |   0.1    |   0.05   |   0.17   |   0.01   |   0.08   |   0.01   |   0.17  |   0.01   |   0.25  |   0.01   |   0.02   |   0.02   |   0.02   |   0.06   |   0.12   |   0.01   |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models

 ********** Supervised learning of blocks [3] **********
SAVING FOLDER FOR SUP:  C100_2C_CL
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 8,  8, 20, 20,  8, 20, 20,  8,  8,  8,  8,  8,  8, 20, 20,  8,  8, 20,
        20,  8])
[8, 20]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0])
200
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 200
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 8,  8, 20, 20,  8, 20,  8,  8, 20, 20, 20, 20,  8, 20,  8, 20, 20,  8,
         8,  8])
[8, 20]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([ 8,  8, 20, 20,  8, 20,  8,  8, 20, 20, 20, 20,  8, 20,  8, 20, 20,  8,
         8,  8])
[8, 20]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  1000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Epoch: [1/50]	lr: 1.00e-03	time: 00:00:39	Loss_train 0.61975	Acc_train 73.90	/	Loss_test 0.08029	Acc_test 87.00
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models
Epoch: [10/50]	lr: 1.00e-03	time: 00:00:40	Loss_train 0.04521	Acc_train 95.69	/	Loss_test 0.01787	Acc_test 95.00
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models
Epoch: [20/50]	lr: 2.50e-04	time: 00:00:40	Loss_train 0.00332	Acc_train 99.27	/	Loss_test 0.02362	Acc_test 93.50
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models
Epoch: [30/50]	lr: 1.25e-04	time: 00:00:41	Loss_train 0.00141	Acc_train 99.66	/	Loss_test 0.01883	Acc_test 95.00
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models
Epoch: [40/50]	lr: 3.13e-05	time: 00:00:42	Loss_train 0.00060	Acc_train 99.82	/	Loss_test 0.01905	Acc_test 95.00
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models
Epoch: [50/50]	lr: 7.81e-06	time: 00:00:43	Loss_train 0.00090	Acc_train 99.66	/	Loss_test 0.01897	Acc_test 95.00
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models
RESULT:  {'train_loss': 0.0008970832568593323, 'train_acc': 99.65999722480774, 'test_loss': 0.018973398953676224, 'test_acc': 95.0, 'convergence': 23.290390014648438, 'R1': 0, 'dataset_sup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [8, 20]}, 'dataset_unsup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 50, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [8, 20]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}
IN R2:  {'R1': {'train_loss': 0.000665066996589303, 'train_acc': 99.73000288009644, 'test_loss': 0.02636909671127796, 'test_acc': 92.5, 'convergence': 23.626317977905273, 'R1': 0, 'dataset_sup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [73, 79]}, 'dataset_unsup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 50, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [73, 79]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}, 'R2': {'train_loss': 0.0008970832568593323, 'train_acc': 99.65999722480774, 'test_loss': 0.018973398953676224, 'test_acc': 95.0, 'convergence': 23.290390014648438, 'R1': 0, 'dataset_sup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [8, 20]}, 'dataset_unsup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 50, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [8, 20]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.11048543456039805, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 2, 'in_channels': 24576, 'old_channels': 1536, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 Model C100_2C_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=2, bias=True)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([73, 73, 73, 73, 79, 79, 79, 73, 79, 79, 73, 73, 73, 79, 73, 79, 79, 79,
        73, 79])
[73, 79]
TARGETS AFTER CLEANER:  tensor([0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1])
200
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 200
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([73, 73, 79, 79, 79, 73, 79, 79, 73, 73, 79, 79, 73, 79, 73, 79, 79, 73,
        79, 73])
[73, 79]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([73, 73, 79, 79, 79, 73, 79, 79, 73, 73, 79, 79, 73, 79, 73, 79, 79, 73,
        79, 73])
[73, 79]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  1000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_2C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 2.00e-01	time: 00:00:09	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:-8.364e-03/SW:8.742e-01/MR:7.374e+00/SR:1.723e+00/MeD:1.405e+00/MaD:4.901e+00/MW:0.444/MAW:0.556
|       0 |       1 |       2 |       3 |       4 |       5 |       6 |       7 |       8 |       9 |      10 |     11 |      12 |      13 |      14 |      15 |      16 |      17 |      18 |      19 |     20 |      21 |     22 |      23 |      24 |      25 |      26 |      27 |      28 |      29 |
|---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+--------+---------+---------+---------+---------+---------+---------+---------+---------+--------+---------+--------+---------+---------+---------+---------+---------+---------+---------|
|   0.185 |   0.246 |   0.232 |   0.229 |   0.169 |   0.167 |   0.199 |   0.238 |   0.182 |   0.269 |   0.174 |   0.19 |   0.209 |   0.224 |   0.223 |   0.225 |   0.124 |   0.195 |   0.202 |   0.197 |   0.22 |   0.206 |   0.21 |   0.247 |   0.232 |   0.144 |   0.222 |   0.182 |   0.201 |   0.244 |
|   6.36  |  10.46  |   9.42  |   9.22  |   5.47  |   5.38  |   7.19  |   9.89  |   6.16  |  12.28  |   5.7   |   6.61 |   7.83  |   8.83  |   8.8   |   8.92  |   3.39  |   6.94  |   7.4   |   7.04  |   8.55 |   7.64  |   7.92 |  10.51  |   9.39  |   4.22  |   8.73  |   6.15  |   7.32  |  10.31  |
|   0.35  |   0.25  |   0.17  |   0.33  |   1.24  |   1.98  |   0.75  |   0.55  |   1.16  |   0.2   |   1.34  |   0.38 |   0.41  |   0.19  |   2.39  |   0.28  |   2.65  |   0.36  |   0.55  |   1.66  |   0.61 |   0.82  |   0.39 |   0.29  |   0.22  |   2.5   |   0.67  |   1.23  |   0.18  |   0.23  |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([73, 73, 73, 73, 79, 79, 79, 73, 79, 79, 73, 73, 73, 79, 73, 79, 79, 79,
        73, 79])
[73, 79]
TARGETS AFTER CLEANER:  tensor([0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1])
200
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 200
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([73, 73, 79, 79, 79, 73, 79, 79, 73, 73, 79, 79, 73, 79, 73, 79, 79, 73,
        79, 73])
[73, 79]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([73, 73, 79, 79, 79, 73, 79, 79, 73, 73, 79, 79, 73, 79, 73, 79, 79, 73,
        79, 73])
[73, 79]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  1000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_2C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 2.00e-01	time: 00:00:19	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:-3.073e-03/SW:7.604e-01/MR:2.216e+01/SR:2.910e+00/MeD:2.371e+00/MaD:9.761e+00/MW:0.722/MAW:0.278
|       0 |        1 |        2 |        3 |       4 |        5 |        6 |        7 |        8 |       9 |       10 |       11 |       12 |      13 |       14 |       15 |       16 |       17 |      18 |       19 |       20 |       21 |       22 |      23 |       24 |       25 |       26 |       27 |       28 |       29 |
|---------+----------+----------+----------+---------+----------+----------+----------+----------+---------+----------+----------+----------+---------+----------+----------+----------+----------+---------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------|
|   0.024 |   0.0245 |   0.0242 |   0.0241 |   0.019 |   0.0234 |   0.0237 |   0.0243 |   0.0241 |   0.023 |   0.0248 |   0.0237 |   0.0245 |   0.024 |   0.0241 |   0.0239 |   0.0236 |   0.0216 |   0.023 |   0.0232 |   0.0231 |   0.0248 |   0.0235 |   0.023 |   0.0237 |   0.0235 |   0.0212 |   0.0233 |   0.0226 |   0.0249 |
|  23.96  |  24.97   |  24.45   |  24.27   |  15.4   |  22.9    |  23.53   |  24.53   |  24.24   |  22.21  |  25.59   |  23.52   |  25.03   |  24.08  |  24.27   |  23.94   |  23.25   |  19.63   |  22.23  |  22.61   |  22.27   |  25.63   |  23.04   |  22.2   |  23.54   |  23.08   |  18.93   |  22.78   |  21.47   |  25.72   |
|   0.06  |   0.01   |   0.01   |   0.02   |   0.91  |   0.18   |   0.06   |   0.12   |   0.03   |   0.21  |   0      |   0.05   |   0.09   |   0.19  |   0.06   |   0.09   |   0.26   |   0.36   |   0.19  |   0.25   |   0.14   |   0.04   |   0.59   |   0.45  |   0.13   |   0.18   |   0.81   |   0.1    |   0.3    |   0.04   |
| nan     | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      |
| nan     | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      |
| nan     | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([73, 73, 73, 73, 79, 79, 79, 73, 79, 79, 73, 73, 73, 79, 73, 79, 79, 79,
        73, 79])
[73, 79]
TARGETS AFTER CLEANER:  tensor([0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1])
200
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 200
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([73, 73, 79, 79, 79, 73, 79, 79, 73, 73, 79, 79, 73, 79, 73, 79, 79, 73,
        79, 73])
[73, 79]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([73, 73, 79, 79, 79, 73, 79, 79, 73, 73, 79, 79, 73, 79, 73, 79, 79, 73,
        79, 73])
[73, 79]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  1000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_2C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.80e-02	time: 00:00:29	Acc_train 0.00	Acc_test 0.00	convergence: 2.31e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.638e-04/SW:4.122e-01/MR:2.413e+01/SR:2.254e+00/MeD:1.683e+00/MaD:9.847e+00/MW:0.454/MAW:0.546
|        0 |       1 |        2 |        3 |        4 |        5 |        6 |        7 |        8 |        9 |       10 |       11 |       12 |       13 |       14 |       15 |       16 |     17 |       18 |       19 |       20 |       21 |       22 |       23 |       24 |       25 |       26 |       27 |       28 |       29 |
|----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+--------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------|
|   0.0494 |   0.048 |   0.0501 |   0.0468 |   0.0466 |   0.0487 |   0.0497 |   0.0435 |   0.0491 |   0.0493 |   0.0498 |   0.0486 |   0.0477 |   0.0426 |   0.0502 |   0.0485 |   0.0443 |   0.05 |   0.0475 |   0.0497 |   0.0452 |   0.0486 |   0.0494 |   0.0484 |   0.0472 |   0.0499 |   0.0493 |   0.0489 |   0.0467 |   0.0488 |
|  25.37   |  24.07  |  26.12   |  22.91   |  22.71   |  24.7    |  25.67   |  19.96   |  25.08   |  25.27   |  25.75   |  24.61   |  23.77   |  19.11   |  26.15   |  24.48   |  20.65   |  26.02 |  23.6    |  25.74   |  21.41   |  24.65   |  25.38   |  24.46   |  23.25   |  25.89   |  25.31   |  24.91   |  22.77   |  24.81   |
|   0.01   |   0.01  |   0.05   |   0.07   |   0.05   |   0.02   |   0      |   0.06   |   0.06   |   0      |   0.02   |   0.04   |   0.07   |   0.05   |   0.18   |   0.06   |   0.45   |   0    |   0.04   |   0      |   0.11   |   0.08   |   0.18   |   0.06   |   0.08   |   0.05   |   0.01   |   0.06   |   0.05   |   0.01   |
| nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan    | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan    | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan    | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([73, 73, 73, 73, 79, 79, 79, 73, 79, 79, 73, 73, 73, 79, 73, 79, 79, 79,
        73, 79])
[73, 79]
TARGETS AFTER CLEANER:  tensor([0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1])
200
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 200
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([73, 73, 79, 79, 79, 73, 79, 79, 73, 73, 79, 79, 73, 79, 73, 79, 79, 73,
        79, 73])
[73, 79]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([73, 73, 79, 79, 79, 73, 79, 79, 73, 73, 79, 79, 73, 79, 73, 79, 79, 73,
        79, 73])
[73, 79]
TARGETS AFTER CLEANER:  tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  1000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Accuracy of the network on the 1st dataset: 49.000 %
Test loss on the 1st dataset: 0.337

