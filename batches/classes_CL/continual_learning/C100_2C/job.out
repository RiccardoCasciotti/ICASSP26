BLOCKS:  {'b0': {'arch': 'CNN', 'preset': 'softkrotov-c96-k5-p2-s1-d1-b0-t1-lr0.08-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 0, 'batch_norm': False, 'pool': {'type': 'max', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 0.7}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5}}, 'b1': {'arch': 'CNN', 'preset': 'softkrotov-c384-k3-p1-s1-d1-b0-t0.65-lr0.005-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 1, 'batch_norm': False, 'pool': {'type': 'max', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 1.4}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3}}, 'b2': {'arch': 'CNN', 'preset': 'softkrotov-c1536-k3-p1-s1-d1-b0-t0.25-lr0.01-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 2, 'batch_norm': False, 'pool': {'type': 'avg', 'kernel_size': 2, 'stride': 2, 'padding': 0}, 'activation': {'function': 'triangle', 'param': 1.0}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3}}, 'b3': {'arch': 'MLP', 'preset': 'BP-c10', 'operation': 'flatten', 'num': 3, 'att_dropout': None, 'dropout': 0.5, 'layer': {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.25, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10}, 'pool': None, 'activation': None}}
CL:  True
{'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 100, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True}
CL:  True
{'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 100, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 50, 'validation': False, 'continual_learning': True}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.11048543456039805, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 2, 'in_channels': 24576, 'old_channels': 1536, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=2, bias=True)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([91, 91, 91, 91, 96, 96, 96, 91, 91, 96, 91, 96, 96, 96, 91, 96, 91, 96,
        96, 96])
[91, 96]
TARGETS AFTER CLEANER:  tensor([0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1])
200
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 200
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([96, 96, 96, 91, 96, 96, 91, 96, 91, 96, 91, 96, 96, 91, 91, 96, 91, 91,
        91, 96])
[91, 96]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([96, 96, 96, 91, 96, 96, 91, 96, 91, 96, 91, 96, 96, 91, 91, 96, 91, 91,
        91, 96])
[91, 96]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  1000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_2C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 2.84e-01	time: 00:00:14	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:-1.083e-02/SW:1.639e+00/MR:1.381e+01/SR:3.311e+00/MeD:2.705e+00/MaD:8.321e+00/MW:0.591/MAW:0.409
|       0 |       1 |       2 |       3 |       4 |       5 |       6 |       7 |       8 |       9 |      10 |      11 |      12 |      13 |      14 |      15 |      16 |      17 |     18 |     19 |      20 |      21 |      22 |      23 |      24 |      25 |      26 |      27 |      28 |      29 |
|---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+--------+--------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------|
|   0.267 |   0.347 |   0.324 |   0.322 |   0.243 |   0.223 |   0.298 |   0.354 |   0.249 |   0.368 |   0.273 |   0.274 |   0.307 |   0.328 |   0.263 |   0.319 |   0.203 |   0.298 |   0.29 |   0.27 |   0.321 |   0.275 |   0.306 |   0.352 |   0.325 |   0.228 |   0.327 |   0.288 |   0.301 |   0.347 |
|  12.11  |  19.85  |  17.37  |  17.2   |  10.23  |   8.77  |  14.91  |  20.56  |  10.7   |  22.13  |  12.65  |  12.71  |  15.7   |  17.82  |  11.82  |  16.94  |   7.42  |  14.9   |  14.13 |  12.36 |  17.06  |  12.84  |  15.66  |  20.38  |  17.47  |   9.09  |  17.75  |  13.95  |  15.15  |  19.78  |
|   0.74  |   0.16  |   0.13  |   0.26  |   1.5   |   3.29  |   0.87  |   0.3   |   1.13  |   0.1   |   1.31  |   0.7   |   0.6   |   0.27  |   1.79  |   0.19  |   3.17  |   0.53  |   0.65 |   0.85 |   0.49  |   1.09  |   0.44  |   0.24  |   0.46  |   2.86  |   0.34  |   0.49  |   0.34  |   0.14  |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([91, 91, 91, 91, 96, 96, 96, 91, 91, 96, 91, 96, 96, 96, 91, 96, 91, 96,
        96, 96])
[91, 96]
TARGETS AFTER CLEANER:  tensor([0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1])
200
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 200
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([96, 96, 96, 91, 96, 96, 91, 96, 91, 96, 91, 96, 96, 91, 91, 96, 91, 91,
        91, 96])
[91, 96]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([96, 96, 96, 91, 96, 96, 91, 96, 91, 96, 91, 96, 96, 91, 91, 96, 91, 91,
        91, 96])
[91, 96]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  1000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_2C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 2.84e-01	time: 00:00:24	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:-3.228e-03/SW:8.232e-01/MR:2.415e+01/SR:1.573e+00/MeD:1.046e+00/MaD:8.749e+00/MW:0.784/MAW:0.216
|        0 |        1 |        2 |        3 |        4 |        5 |        6 |       7 |        8 |       9 |       10 |       11 |       12 |       13 |       14 |       15 |       16 |       17 |       18 |       19 |       20 |       21 |       22 |       23 |       24 |       25 |       26 |       27 |       28 |       29 |
|----------+----------+----------+----------+----------+----------+----------+---------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------|
|   0.0247 |   0.0246 |   0.0242 |   0.0241 |   0.0215 |   0.0249 |   0.0244 |   0.025 |   0.0244 |   0.024 |   0.0248 |   0.0241 |   0.0247 |   0.0245 |   0.0242 |   0.0242 |   0.0241 |   0.0236 |   0.0243 |   0.0243 |   0.0238 |   0.0248 |   0.0245 |   0.0246 |   0.0242 |   0.0239 |   0.0241 |   0.0242 |   0.0241 |   0.0251 |
|  25.36   |  25.11   |  24.49   |  24.33   |  19.56   |  25.89   |  24.84   |  26.07  |  24.83   |  24.06  |  25.62   |  24.26   |  25.47   |  25.08   |  24.48   |  24.51   |  24.19   |  23.34   |  24.53   |  24.59   |  23.66   |  25.67   |  25.05   |  25.2    |  24.46   |  23.87   |  24.14   |  24.35   |  24.17   |  26.12   |
|   0.04   |   0.01   |   0      |   0.01   |   2.27   |   0.14   |   0.03   |   0.06  |   0.01   |   0.15  |   0      |   0.05   |   0.05   |   0.06   |   0.01   |   0.04   |   0.01   |   0.55   |   0.06   |   0.29   |   0.08   |   0.01   |   0.12   |   0.14   |   0.05   |   0.15   |   0.43   |   0.04   |   0.22   |   0.01   |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([91, 91, 91, 91, 96, 96, 96, 91, 91, 96, 91, 96, 96, 96, 91, 96, 91, 96,
        96, 96])
[91, 96]
TARGETS AFTER CLEANER:  tensor([0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1])
200
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 200
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([96, 96, 96, 91, 96, 96, 91, 96, 91, 96, 91, 96, 96, 91, 91, 96, 91, 91,
        91, 96])
[91, 96]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([96, 96, 96, 91, 96, 96, 91, 96, 91, 96, 91, 96, 96, 91, 91, 96, 91, 91,
        91, 96])
[91, 96]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  1000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_2C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.85e-02	time: 00:00:34	Acc_train 0.00	Acc_test 0.00	convergence: 2.35e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.182e-04/SW:4.178e-01/MR:2.453e+01/SR:1.381e+00/MeD:8.806e-01/MaD:8.827e+00/MW:0.493/MAW:0.507
|       0 |       1 |        2 |        3 |        4 |        5 |        6 |        7 |        8 |       9 |       10 |       11 |      12 |       13 |      14 |       15 |       16 |       17 |       18 |       19 |       20 |       21 |       22 |       23 |       24 |       25 |       26 |       27 |       28 |       29 |
|---------+---------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+---------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------|
|   0.049 |   0.049 |   0.0492 |   0.0478 |   0.0485 |   0.0487 |   0.0494 |   0.0469 |   0.0492 |   0.049 |   0.0496 |   0.0478 |   0.049 |   0.0438 |   0.048 |   0.0493 |   0.0472 |   0.0497 |   0.0486 |   0.0493 |   0.0467 |   0.0494 |   0.0502 |   0.0494 |   0.0482 |   0.0491 |   0.0492 |   0.0485 |   0.0475 |   0.0489 |
|  25.06  |  24.99  |  25.18   |  23.84   |  24.55   |  24.67   |  25.44   |  22.98   |  25.25   |  25.01  |  25.58   |  23.87   |  25.03  |  20.18   |  24.05  |  25.26   |  23.32   |  25.67   |  24.66   |  25.29   |  22.77   |  25.4    |  26.2    |  25.37   |  24.21   |  25.08   |  25.17   |  24.55   |  23.56   |  24.87   |
|   0     |   0.01  |   0.05   |   0.15   |   0.05   |   0.02   |   0.01   |   0.08   |   0.03   |   0     |   0.02   |   0.16   |   0.06  |   0.21   |   0.12  |   0.02   |   0.2    |   0      |   0.04   |   0      |   0.22   |   0.01   |   0.21   |   0.02   |   0.02   |   0.01   |   0.01   |   0.04   |   0.11   |   0.01   |
| nan     | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan     | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan     | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models

 ********** Supervised learning of blocks [3] **********
SAVING FOLDER FOR SUP:  C100_2C_CL
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([91, 91, 91, 91, 96, 96, 96, 91, 91, 96, 91, 96, 96, 96, 91, 96, 91, 96,
        96, 96])
[91, 96]
TARGETS AFTER CLEANER:  tensor([0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1])
200
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 200
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([96, 96, 96, 91, 96, 96, 91, 96, 91, 96, 91, 96, 96, 91, 91, 96, 91, 91,
        91, 96])
[91, 96]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([96, 96, 96, 91, 96, 96, 91, 96, 91, 96, 91, 96, 96, 91, 91, 96, 91, 91,
        91, 96])
[91, 96]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  1000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Epoch: [1/50]	lr: 1.00e-03	time: 00:00:44	Loss_train 0.76506	Acc_train 72.60	/	Loss_test 0.08537	Acc_test 86.00
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models
Epoch: [10/50]	lr: 1.00e-03	time: 00:00:44	Loss_train 0.05163	Acc_train 96.06	/	Loss_test 0.00388	Acc_test 97.50
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models
Epoch: [20/50]	lr: 2.50e-04	time: 00:00:45	Loss_train 0.00084	Acc_train 99.64	/	Loss_test 0.00367	Acc_test 97.50
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models
Epoch: [30/50]	lr: 1.25e-04	time: 00:00:46	Loss_train 0.00041	Acc_train 99.81	/	Loss_test 0.00216	Acc_test 98.00
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models
Epoch: [40/50]	lr: 3.13e-05	time: 00:00:46	Loss_train 0.00014	Acc_train 99.93	/	Loss_test 0.00204	Acc_test 98.50
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models
Epoch: [50/50]	lr: 7.81e-06	time: 00:00:47	Loss_train 0.00018	Acc_train 99.89	/	Loss_test 0.00194	Acc_test 98.50
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models
RESULT:  {'train_loss': 0.0001824830105761066, 'train_acc': 99.88999962806702, 'test_loss': 0.0019405329367145896, 'test_acc': 98.5, 'convergence': 23.525100708007812, 'R1': 0, 'dataset_sup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [91, 96]}, 'dataset_unsup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 50, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [91, 96]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}
IN R1:  {'R1': {'train_loss': 0.0001824830105761066, 'train_acc': 99.88999962806702, 'test_loss': 0.0019405329367145896, 'test_acc': 98.5, 'convergence': 23.525100708007812, 'R1': 0, 'dataset_sup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [91, 96]}, 'dataset_unsup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 50, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [91, 96]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.11048543456039805, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 2, 'in_channels': 24576, 'old_channels': 1536, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 Model C100_2C_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=2, bias=True)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([95, 95, 95, 95, 31, 31, 31, 31, 31, 95, 95, 31, 31, 95, 31, 95, 95, 31,
        31, 95])
[31, 95]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1])
200
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 200
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([31, 95, 95, 31, 95, 31, 31, 95, 31, 31, 95, 95, 95, 31, 31, 31, 31, 95,
        95, 31])
[31, 95]
TARGETS AFTER CLEANER:  tensor([0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([31, 95, 95, 31, 95, 31, 31, 95, 31, 31, 95, 95, 95, 31, 31, 31, 31, 95,
        95, 31])
[31, 95]
TARGETS AFTER CLEANER:  tensor([0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  1000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_2C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.97e-01	time: 00:00:09	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:-6.156e-03/SW:8.518e-01/MR:7.199e+00/SR:1.618e+00/MeD:1.333e+00/MaD:4.190e+00/MW:0.466/MAW:0.534
|       0 |       1 |       2 |       3 |       4 |       5 |       6 |      7 |      8 |       9 |      10 |      11 |      12 |      13 |      14 |      15 |      16 |      17 |      18 |      19 |      20 |      21 |      22 |      23 |      24 |      25 |      26 |      27 |      28 |      29 |
|---------+---------+---------+---------+---------+---------+---------+--------+--------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------|
|   0.177 |   0.242 |   0.219 |   0.213 |   0.173 |   0.163 |   0.198 |   0.25 |   0.17 |   0.258 |   0.183 |   0.182 |   0.199 |   0.217 |   0.202 |   0.225 |   0.129 |   0.185 |   0.206 |   0.192 |   0.214 |   0.191 |   0.208 |   0.241 |   0.221 |   0.161 |   0.227 |   0.195 |   0.184 |   0.241 |
|   5.91  |  10.14  |   8.49  |   8.11  |   5.67  |   5.15  |   7.12  |  10.74 |   5.51 |  11.39  |   6.24  |   6.15  |   7.19  |   8.37  |   7.4   |   8.94  |   3.62  |   6.36  |   7.62  |   6.74  |   8.13  |   6.7   |   7.76  |  10.1   |   8.62  |   5.07  |   9.07  |   6.94  |   6.32  |  10.1   |
|   0.49  |   0.41  |   0.36  |   0.43  |   1.29  |   2.24  |   0.8   |   0.43 |   0.84 |   0.36  |   1.31  |   0.46  |   0.58  |   0.42  |   1.69  |   0.37  |   1.97  |   0.58  |   0.61  |   1.18  |   0.73  |   0.91  |   0.55  |   0.45  |   0.41  |   2.67  |   0.78  |   1.11  |   0.42  |   0.38  |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([95, 95, 95, 95, 31, 31, 31, 31, 31, 95, 95, 31, 31, 95, 31, 95, 95, 31,
        31, 95])
[31, 95]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1])
200
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 200
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([31, 95, 95, 31, 95, 31, 31, 95, 31, 31, 95, 95, 95, 31, 31, 31, 31, 95,
        95, 31])
[31, 95]
TARGETS AFTER CLEANER:  tensor([0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([31, 95, 95, 31, 95, 31, 31, 95, 31, 31, 95, 95, 95, 31, 31, 31, 31, 95,
        95, 31])
[31, 95]
TARGETS AFTER CLEANER:  tensor([0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  1000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_2C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.97e-01	time: 00:00:19	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:-3.129e-03/SW:7.873e-01/MR:2.302e+01/SR:2.395e+00/MeD:1.876e+00/MaD:8.856e+00/MW:0.758/MAW:0.242
|        0 |        1 |        2 |        3 |        4 |       5 |        6 |        7 |        8 |        9 |       10 |      11 |       12 |       13 |       14 |       15 |       16 |      17 |       18 |       19 |       20 |       21 |       22 |       23 |      24 |       25 |       26 |       27 |       28 |      29 |
|----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+---------|
|   0.0243 |   0.0245 |   0.0242 |   0.0241 |   0.0196 |   0.024 |   0.0243 |   0.0246 |   0.0243 |   0.0236 |   0.0248 |   0.024 |   0.0247 |   0.0244 |   0.0242 |   0.0241 |   0.0239 |   0.022 |   0.0236 |   0.0239 |   0.0232 |   0.0248 |   0.0237 |   0.0239 |   0.024 |   0.0238 |   0.0226 |   0.0238 |   0.0235 |   0.025 |
|  24.67   |  25.08   |  24.48   |  24.26   |  16.42   |  24.13  |  24.59   |  25.29   |  24.54   |  23.22   |  25.61   |  23.97  |  25.31   |  24.79   |  24.41   |  24.14   |  23.91   |  20.3   |  23.33   |  23.82   |  22.61   |  25.66   |  23.43   |  23.85   |  24.04  |  23.63   |  21.43   |  23.66   |  23.13   |  25.98  |
|   0.13   |   0.01   |   0      |   0.02   |   1.18   |   0.27  |   0.06   |   0.14   |   0.05   |   0.18   |   0.01   |   0.07  |   0.07   |   0.1    |   0.02   |   0.08   |   0.09   |   0.81  |   0.15   |   0.15   |   0.21   |   0.01   |   0.48   |   0.44   |   0.14  |   0.1    |   0.63   |   0.11   |   0.18   |   0.04  |
| nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan     |
| nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan     |
| nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([95, 95, 95, 95, 31, 31, 31, 31, 31, 95, 95, 31, 31, 95, 31, 95, 95, 31,
        31, 95])
[31, 95]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1])
200
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 200
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([31, 95, 95, 31, 95, 31, 31, 95, 31, 31, 95, 95, 95, 31, 31, 31, 31, 95,
        95, 31])
[31, 95]
TARGETS AFTER CLEANER:  tensor([0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([31, 95, 95, 31, 95, 31, 31, 95, 31, 31, 95, 95, 95, 31, 31, 31, 31, 95,
        95, 31])
[31, 95]
TARGETS AFTER CLEANER:  tensor([0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  1000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C100_2C_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.81e-02	time: 00:00:29	Acc_train 0.00	Acc_test 0.00	convergence: 2.31e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.335e-04/SW:4.121e-01/MR:2.414e+01/SR:1.976e+00/MeD:1.450e+00/MaD:1.044e+01/MW:0.484/MAW:0.516
|        0 |        1 |        2 |        3 |       4 |        5 |        6 |        7 |        8 |        9 |       10 |       11 |       12 |       13 |       14 |      15 |       16 |     17 |       18 |      19 |       20 |       21 |       22 |       23 |      24 |       25 |       26 |       27 |       28 |       29 |
|----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+--------+----------+---------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------|
|   0.0491 |   0.0492 |   0.0497 |   0.0476 |   0.047 |   0.0485 |   0.0495 |   0.0442 |   0.0499 |   0.0491 |   0.0497 |   0.0469 |   0.0487 |   0.0428 |   0.0469 |   0.049 |   0.0439 |   0.05 |   0.0474 |   0.049 |   0.0475 |   0.0497 |   0.0498 |   0.0495 |   0.048 |   0.0493 |   0.0493 |   0.0466 |   0.0471 |   0.0491 |
|  25.15   |  25.21   |  25.67   |  23.69   |  23.12  |  24.5    |  25.53   |  20.55   |  25.87   |  25.09   |  25.72   |  22.96   |  24.69   |  19.35   |  22.97   |  24.97  |  20.3    |  25.96 |  23.46   |  25.02  |  23.6    |  25.73   |  25.82   |  25.46   |  24.06  |  25.26   |  25.33   |  22.75   |  23.14   |  25.11   |
|   0      |   0.01   |   0.03   |   0.06   |   0.07  |   0.05   |   0.01   |   0.08   |   0.05   |   0      |   0.02   |   0.1    |   0.05   |   0.08   |   0.14   |   0.04  |   0.29   |   0.01 |   0.08   |   0.02  |   0.09   |   0.02   |   0.18   |   0.03   |   0.02  |   0.03   |   0.02   |   0.08   |   0.08   |   0.01   |
| nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan    | nan      | nan     | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan    | nan      | nan     | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan    | nan      | nan     | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models

 ********** Supervised learning of blocks [3] **********
SAVING FOLDER FOR SUP:  C100_2C_CL
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([95, 95, 95, 95, 31, 31, 31, 31, 31, 95, 95, 31, 31, 95, 31, 95, 95, 31,
        31, 95])
[31, 95]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1])
200
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 200
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([31, 95, 95, 31, 95, 31, 31, 95, 31, 31, 95, 95, 95, 31, 31, 31, 31, 95,
        95, 31])
[31, 95]
TARGETS AFTER CLEANER:  tensor([0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([31, 95, 95, 31, 95, 31, 31, 95, 31, 31, 95, 95, 95, 31, 31, 31, 31, 95,
        95, 31])
[31, 95]
TARGETS AFTER CLEANER:  tensor([0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  1000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Epoch: [1/50]	lr: 1.00e-03	time: 00:00:39	Loss_train 0.62211	Acc_train 77.60	/	Loss_test 0.09981	Acc_test 90.00
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models
Epoch: [10/50]	lr: 1.00e-03	time: 00:00:40	Loss_train 0.05357	Acc_train 96.82	/	Loss_test 0.02733	Acc_test 95.00
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models
Epoch: [20/50]	lr: 2.50e-04	time: 00:00:40	Loss_train 0.00058	Acc_train 99.86	/	Loss_test 0.02482	Acc_test 95.00
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models
Epoch: [30/50]	lr: 1.25e-04	time: 00:00:41	Loss_train 0.00037	Acc_train 99.89	/	Loss_test 0.01982	Acc_test 96.00
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models
Epoch: [40/50]	lr: 3.13e-05	time: 00:00:42	Loss_train 0.00014	Acc_train 99.94	/	Loss_test 0.02055	Acc_test 96.50
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models
Epoch: [50/50]	lr: 7.81e-06	time: 00:00:42	Loss_train 0.00009	Acc_train 99.95	/	Loss_test 0.02041	Acc_test 96.00
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C100_2C_CL/models
RESULT:  {'train_loss': 9.456514089833945e-05, 'train_acc': 99.94999766349792, 'test_loss': 0.02040521427989006, 'test_acc': 96.0, 'convergence': 23.144948959350586, 'R1': 0, 'dataset_sup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [31, 95]}, 'dataset_unsup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 50, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [31, 95]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}
IN R2:  {'R1': {'train_loss': 0.0001824830105761066, 'train_acc': 99.88999962806702, 'test_loss': 0.0019405329367145896, 'test_acc': 98.5, 'convergence': 23.525100708007812, 'R1': 0, 'dataset_sup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [91, 96]}, 'dataset_unsup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 50, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [91, 96]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}, 'R2': {'train_loss': 9.456514089833945e-05, 'train_acc': 99.94999766349792, 'test_loss': 0.02040521427989006, 'test_acc': 96.0, 'convergence': 23.144948959350586, 'R1': 0, 'dataset_sup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [31, 95]}, 'dataset_unsup': {'name': 'CIFAR100', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 2, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 50, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32, 'n_classes': 2, 'selected_classes': [31, 95]}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 50}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.11048543456039805, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 2, 'in_channels': 24576, 'old_channels': 1536, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 Model C100_2C_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=2, bias=True)
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
TARGETS BEFORE SUB:  tensor([49, 33, 72, 51, 71, 92, 15, 14, 23,  0, 71, 75, 81, 69, 40, 43, 92, 97,
        70, 53], device='cuda:0')
TARGETS AFTER SUB:  tensor([91, 91, 91, 91, 96, 96, 96, 91, 91, 96, 91, 96, 96, 96, 91, 96, 91, 96,
        96, 96])
[91, 96]
TARGETS AFTER CLEANER:  tensor([0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1])
200
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 200
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Test
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([96, 96, 96, 91, 96, 96, 91, 96, 91, 96, 91, 96, 96, 91, 91, 96, 91, 91,
        91, 96])
[91, 96]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
    StandardTransform
Transform: Compose(
               None
               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)
           )
------------------------
TARGETS BEFORE SUB:  tensor([19, 29,  0, 11,  1, 86, 90, 28, 23, 31, 39, 96, 82, 17, 71, 39,  8, 97,
        80, 71], device='cuda:0')
TARGETS AFTER SUB:  tensor([96, 96, 96, 91, 96, 96, 91, 96, 91, 96, 91, 96, 96, 91, 91, 96, 91, 91,
        91, 96])
[91, 96]
TARGETS AFTER CLEANER:  tensor([1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1])
1000
<class 'dataset.FastCIFAR100'>
Dataset FastCIFAR100
    Number of datapoints: 1000
    Root location: /g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/data
    Split: Train
------------------------
INDICES:  1000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Accuracy of the network on the 1st dataset: 43.500 %
Test loss on the 1st dataset: 0.983

