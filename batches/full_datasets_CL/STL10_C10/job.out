BLOCKS:  {'b0': {'arch': 'CNN', 'preset': 'softkrotov-c96-k5-p2-s1-d1-b0-t1-lr0.08-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 0, 'batch_norm': False, 'pool': {'type': 'avg', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 0.7}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5}}, 'b1': {'arch': 'CNN', 'preset': 'softkrotov-c384-k3-p1-s1-d1-b0-t0.65-lr0.005-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 1, 'batch_norm': False, 'pool': {'type': 'max', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 0.7}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3}}, 'b2': {'arch': 'CNN', 'preset': 'softkrotov-c1536-k3-p1-s1-d1-b0-t0.45-lr0.01-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 2, 'batch_norm': False, 'pool': {'type': 'avg', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 1.4}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.45, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3}}, 'b3': {'arch': 'CNN', 'preset': 'softkrotov-c6144-k3-p1-s1-d1-b0-t0.25-lr0.01-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 3, 'batch_norm': False, 'pool': {'type': 'avg', 'kernel_size': 2, 'stride': 2, 'padding': 0}, 'activation': {'function': 'triangle', 'param': 1}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 6144, 'kernel_size': 3}}, 'b4': {'arch': 'MLP', 'preset': 'BP-c10', 'operation': 'flatten', 'num': 4, 'att_dropout': None, 'dropout': 0.5, 'layer': {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.25, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10}, 'pool': None, 'activation': None}}
CL:  True
{'name': 'STL10', 'noise_std': 0, 'channels': 3, 'width': 96, 'height': 96, 'validation_split': 0.2, 'training_sample': 5000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': True, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 100, 'print_freq': 10, 'validation': False, 'continual_learning': True}
CL:  False
{'name': 'STL10', 'noise_std': 0, 'channels': 3, 'width': 96, 'height': 96, 'validation_split': 0.2, 'training_sample': 5000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': True, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 100, 'print_freq': 10, 'validation': False, 'continual_learning': False}
CL:  False
{'name': 'STL10', 'noise_std': 0, 'channels': 3, 'width': 96, 'height': 96, 'validation_split': 0.2, 'training_sample': 100000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 32, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'unlabeled', 'nb_epoch': 1, 'print_freq': 25, 'validation': False, 'continual_learning': False}
SEED:  0
block 0, size : 96 48 48
range = 2.886751345948129
block 1, size : 384 24 24
range = 0.8505172717997146
block 2, size : 1536 12 12
range = 0.4252586358998573
block 3, size : 6144 6 6
range = 0.21262931794992865
range = 0.036828478186799345
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.00032, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.00032, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.45, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.00032, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.21262931794992865, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 6144, 'kernel_size': 3, 'in_channels': 1536, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.00032, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.036828478186799345, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10, 'in_channels': 221184, 'old_channels': 6144, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 Model STL10_CIFAR10_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- AvgPool2d(kernel_size=4, stride=2, padding=1)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.44999998807907104reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.44999998807907104, bias=False, lr_bias=0.2222, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- AvgPool2d(kernel_size=4, stride=2, padding=1)

 ----- Architecture Block BatchNorm2dSK153661442(3, 3)0.25reflect, number 3 -----
- BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(1536, 6144, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 4 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=221184, out_features=10, bias=True)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  5000
IMAGE SIZE: torch.Size([32, 3, 96, 96])
SAVING FOLDER FOR UNSUP:  STL10_CIFAR10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.23e-01	time: 00:00:39	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:3.878e-03/SW:4.535e-01/MR:3.683e+00/SR:1.372e+00/MeD:1.038e+00/MaD:3.301e+00/MW:0.617/MAW:0.383
|        0 |        1 |       2 |      3 |       4 |       5 |      6 |       7 |       8 |       9 |        10 |      11 |      12 |      13 |      14 |      15 |         16 |      17 |      18 |      19 |      20 |        21 |       22 |      23 |      24 |         25 |      26 |       27 |        28 |      29 |
|----------+----------+---------+--------+---------+---------+--------+---------+---------+---------+-----------+---------+---------+---------+---------+---------+------------+---------+---------+---------+---------+-----------+----------+---------+---------+------------+---------+----------+-----------+---------|
|   0.0963 |   0.0869 |   0.138 |   0.18 |   0.149 |   0.196 |   0.14 |   0.121 |   0.147 |   0.141 |   0.00132 |   0.144 |   0.187 |   0.119 |   0.107 |   0.115 |   9.16e-05 |   0.175 |   0.106 |   0.137 |   0.141 |   0.00174 |   0.0565 |   0.137 |   0.172 |   7.81e-05 |   0.156 |   0.0801 |   0.00244 |   0.172 |
|   2.45   |   2.18   |   3.98  |   6.05 |   4.48  |   6.98  |   4.08 |   3.29  |   4.38  |   4.12  |   1       |   4.23  |   6.46  |   3.2   |   2.78  |   3.08  |   1        |   5.81  |   2.76  |   3.94  |   4.12  |   1       |   1.5    |   3.91  |   5.61  |   1        |   4.82  |   2      |   1       |   5.64  |
|   0.37   |   0.42   |   0.36  |   0.41 |   0.45  |   0.37  |   0.32 |   0.41  |   0.33  |   0.48  |   3.36    |   0.45  |   0.34  |   0.45  |   0.44  |   0.44  |  24.79     |   0.43  |   0.42  |   0.43  |   0.47  |   1.07    |   0.43   |   0.46  |   0.46  |  27.83     |   0.32  |   0.51   |   1.09    |   0.37  |
| nan      | nan      | nan     | nan    | nan     | nan     | nan    | nan     | nan     | nan     | nan       | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan       | nan      | nan     | nan     | nan        | nan     | nan      | nan       | nan     |
| nan      | nan      | nan     | nan    | nan     | nan     | nan    | nan     | nan     | nan     | nan       | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan       | nan      | nan     | nan     | nan        | nan     | nan      | nan       | nan     |
| nan      | nan      | nan     | nan    | nan     | nan     | nan    | nan     | nan     | nan     | nan       | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan       | nan      | nan     | nan     | nan        | nan     | nan      | nan       | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  5000
IMAGE SIZE: torch.Size([32, 3, 96, 96])
SAVING FOLDER FOR UNSUP:  STL10_CIFAR10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.23e-01	time: 00:01:08	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:9.494e-03/SW:9.167e-02/MR:2.396e+00/SR:1.265e+00/MeD:1.052e+00/MaD:5.124e+00/MW:0.609/MAW:0.391
|          0 |         1 |        2 |         3 |         4 |         5 |         6 |          7 |         8 |        9 |        10 |        11 |        12 |        13 |        14 |        15 |        16 |         17 |       18 |       19 |        20 |        21 |        22 |        23 |         24 |        25 |        26 |         27 |        28 |        29 |
|------------+-----------+----------+-----------+-----------+-----------+-----------+------------+-----------+----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+------------+----------+----------+-----------+-----------+-----------+-----------+------------+-----------+-----------+------------+-----------+-----------|
|   0.000372 |   0.00804 |   0.0076 |   0.00971 |   0.00237 |   0.00933 |   0.00261 |   8.36e-05 |   0.00599 |   0.0002 |   0.00702 |   0.00611 |   0.00218 |   0.00172 |   0.00648 |   0.00495 |   0.00111 |   0.000741 |   0.0104 |   0.0063 |   0.00758 |   0.00237 |   0.00848 |   0.00399 |   0.000425 |   0.00588 |   0.00994 |   0.000336 |   0.00474 |   0.00129 |
|   1.01     |   3.59    |   3.31   |   4.77    |   1.23    |   4.49    |   1.27    |   1        |   2.43    |   1      |   2.97    |   2.49    |   1.19    |   1.12    |   2.68    |   1.98    |   1.05    |   1.02     |   5.32   |   2.59   |   3.3     |   1.23    |   3.88    |   1.64    |   1.01     |   2.38    |   4.95    |   1        |   1.9     |   1.07    |
|   0.49     |   0.07    |   0.09   |   0.08    |   0.15    |   0.07    |   0.18    |   2.02     |   0.06    |   1.21   |   0.08    |   0.05    |   0.17    |   0.15    |   0.08    |   0.09    |   0.17    |   0.45     |   0.1    |   0.08   |   0.07    |   0.19    |   0.11    |   0.1     |   0.34     |   0.09    |   0.11    |   0.51     |   0.08    |   0.25    |
| nan        | nan       | nan      | nan       | nan       | nan       | nan       | nan        | nan       | nan      | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan        | nan      | nan      | nan       | nan       | nan       | nan       | nan        | nan       | nan       | nan        | nan       | nan       |
| nan        | nan       | nan      | nan       | nan       | nan       | nan       | nan        | nan       | nan      | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan        | nan      | nan      | nan       | nan       | nan       | nan       | nan        | nan       | nan       | nan        | nan       | nan       |
| nan        | nan       | nan      | nan       | nan       | nan       | nan       | nan        | nan       | nan      | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan        | nan      | nan      | nan       | nan       | nan       | nan       | nan        | nan       | nan       | nan        | nan       | nan       |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  5000
IMAGE SIZE: torch.Size([32, 3, 96, 96])
SAVING FOLDER FOR UNSUP:  STL10_CIFAR10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.90e-02	time: 00:01:38	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:4.402e-03/SW:1.138e-01/MR:6.051e+00/SR:2.866e+00/MeD:2.345e+00/MaD:6.858e+00/MW:0.633/MAW:0.367
|        0 |        1 |        2 |        3 |        4 |        5 |        6 |        7 |       8 |        9 |      10 |        11 |      12 |       13 |       14 |       15 |       16 |       17 |        18 |       19 |       20 |       21 |         22 |       23 |       24 |       25 |       26 |      27 |       28 |        29 |
|----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+---------+-----------+---------+----------+----------+----------+----------+----------+-----------+----------+----------+----------+------------+----------+----------+----------+----------+---------+----------+-----------|
|   0.0252 |   0.0237 |   0.0252 |   0.0169 |   0.0112 |   0.0269 |   0.0243 |   0.0258 |   0.026 |   0.0283 |   0.023 |   0.00648 |   0.015 |   0.0253 |   0.0155 |   0.0265 |   0.0258 |   0.0209 |   0.00038 |   0.0282 |   0.0102 |   0.0212 |   0.000318 |   0.0257 |   0.0261 |   0.0259 |   0.0177 |   0.016 |   0.0287 |   0.00217 |
|   7.36   |   6.61   |   7.36   |   3.85   |   2.25   |   8.24   |   6.89   |   7.64   |   7.78  |   9.02   |   6.31  |   1.42    |   3.26  |   7.41   |   3.41   |   8.02   |   7.65   |   5.37   |   1       |   8.95   |   2.05   |   5.5    |   1        |   7.59   |   7.82   |   7.7    |   4.15   |   3.56  |   9.26   |   1.05    |
|   0.01   |   0.01   |   0.01   |   0      |   0      |   0.01   |   0.02   |   0.01   |   0.02  |   0.02   |   0.03  |   0.02    |   0.01  |   0.01   |   0.01   |   0.02   |   0.01   |   0.02   |   0.17    |   0.02   |   0.01   |   0.01   |   0.36     |   0.02   |   0.02   |   0.02   |   0      |   0.01  |   0.01   |   0.06    |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan     | nan       | nan     | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan        | nan      | nan      | nan      | nan      | nan     | nan      | nan       |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan     | nan       | nan     | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan        | nan      | nan      | nan      | nan      | nan     | nan      | nan       |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan     | nan       | nan     | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan        | nan      | nan      | nan      | nan      | nan     | nan      | nan       |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models

 ********** Hebbian Unsupervised learning of blocks [3] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  5000
IMAGE SIZE: torch.Size([32, 3, 96, 96])
SAVING FOLDER FOR UNSUP:  STL10_CIFAR10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 2.04e-02	time: 00:02:18	Acc_train 0.00	Acc_test 0.00	convergence: 1.26e+01	R1: 43	Info MB:0.000e+00/SB:0.000e+00/MW:3.981e-03/SW:1.208e-01/MR:1.358e+01/SR:4.180e+00/MeD:3.104e+00/MaD:1.258e+01/MW:0.527/MAW:0.473
|        0 |        1 |        2 |        3 |        4 |        5 |        6 |        7 |       8 |        9 |       10 |       11 |       12 |       13 |      14 |      15 |       16 |       17 |       18 |       19 |       20 |       21 |       22 |       23 |       24 |       25 |       26 |       27 |       28 |       29 |
|----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+---------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------|
|   0.0406 |   0.0364 |   0.0392 |   0.0321 |   0.0377 |   0.0384 |   0.0367 |   0.0088 |   0.041 |   0.0394 |   0.0384 |   0.0392 |   0.0407 |   0.0377 |   0.037 |   0.036 |   0.0271 |   0.0424 |   0.0321 |   0.0132 |   0.0353 |   0.0379 |   0.0407 |   0.0298 |   0.0383 |   0.0403 |   0.0143 |   0.0403 |   0.0416 |   0.0362 |
|  17.51   |  14.25   |  16.36   |  11.3    |  15.22   |  15.74   |  14.45   |   1.77   |  17.79  |  16.52   |  15.78   |  16.37   |  17.53   |  15.2    |  14.72  |  13.98  |   8.37   |  19      |  11.33   |   2.75   |  13.44   |  15.35   |  17.57   |   9.85   |  15.67   |  17.27   |   3.05   |  17.21   |  18.29   |  14.08   |
|   0.01   |   0.01   |   0.01   |   0.01   |   0.01   |   0.01   |   0      |   0.05   |   0.01  |   0.01   |   0.01   |   0.01   |   0.01   |   0.01   |   0.01  |   0.01  |   0      |   0.01   |   0.01   |   0.03   |   0.01   |   0.01   |   0.02   |   0.01   |   0.01   |   0      |   0.05   |   0.01   |   0.01   |   0.01   |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan     | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan     | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan     | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  5000
IMAGE SIZE: torch.Size([64, 3, 96, 96])
Accuracy of the network on the 1st dataset: 74.950 %
Test loss on the 1st dataset: 1.705
CL:  True
{'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True}
CL:  True
{'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
block 3, size : 6144 2 2
range = 0.21262931794992865
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.00032, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.00032, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.45, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.00032, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.21262931794992865, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 6144, 'kernel_size': 3, 'in_channels': 1536, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.00032, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.036828478186799345, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10, 'in_channels': 221184, 'old_channels': 6144, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 Model STL10_CIFAR10_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- AvgPool2d(kernel_size=4, stride=2, padding=1)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.44999998807907104reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.44999998807907104, bias=False, lr_bias=0.2222, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- AvgPool2d(kernel_size=4, stride=2, padding=1)

 ----- Architecture Block BatchNorm2dSK153661442(3, 3)0.25reflect, number 3 -----
- BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(1536, 6144, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 4 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=221184, out_features=10, bias=True)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  50000
IMAGE SIZE: torch.Size([10, 3, 96, 96])
SAVING FOLDER FOR UNSUP:  STL10_CIFAR10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 2.16e-01	time: 00:03:03	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:8.372e-03/SW:1.791e+00/MR:1.124e+01/SR:1.075e+01/MeD:8.513e+00/MaD:3.173e+01/MW:0.638/MAW:0.362
|       0 |       1 |       2 |      3 |       4 |       5 |      6 |       7 |      8 |       9 |         10 |      11 |      12 |      13 |      14 |     15 |         16 |      17 |      18 |      19 |      20 |        21 |       22 |      23 |      24 |         25 |      26 |     27 |        28 |      29 |
|---------+---------+---------+--------+---------+---------+--------+---------+--------+---------+------------+---------+---------+---------+---------+--------+------------+---------+---------+---------+---------+-----------+----------+---------+---------+------------+---------+--------+-----------+---------|
|   0.121 |   0.134 |   0.359 |   0.27 |   0.113 |   0.418 |   0.37 |   0.228 |   0.37 |   0.113 |   0.000448 |   0.108 |   0.189 |   0.272 |   0.238 |   0.22 |   0.000288 |   0.418 |   0.242 |   0.104 |   0.126 |   0.00272 |   0.0662 |   0.105 |   0.501 |   0.000241 |   0.504 |   0.09 |   0.00227 |   0.381 |
|   3.27  |   3.79  |  21.19  |  12.41 |   3     |  28.28  |  22.42 |   9.13  |  22.43 |   2.99  |   1        |   2.84  |   6.6   |  12.58  |   9.88  |   8.59 |   1        |  28.27  |  10.11  |   2.7   |   3.49  |   1       |   1.69   |   2.72  |  40.18  |   1        |  40.65  |   2.27 |   1       |  23.7   |
|   0.29  |   0.29  |   0.55  |   0.57 |   0.28  |   0.4   |   0.52 |   0.37  |   0.4  |   0.28  |   3.73     |   0.28  |   0.28  |   0.47  |   0.42  |   0.4  |  26.05     |   0.45  |   0.43  |   0.28  |   0.28  |   0.66    |   0.29   |   0.28  |   0.57  |  30.8      |   0.4   |   0.59 |   0.7     |   0.42  |
| nan     | nan     | nan     | nan    | nan     | nan     | nan    | nan     | nan    | nan     | nan        | nan     | nan     | nan     | nan     | nan    | nan        | nan     | nan     | nan     | nan     | nan       | nan      | nan     | nan     | nan        | nan     | nan    | nan       | nan     |
| nan     | nan     | nan     | nan    | nan     | nan     | nan    | nan     | nan    | nan     | nan        | nan     | nan     | nan     | nan     | nan    | nan        | nan     | nan     | nan     | nan     | nan       | nan      | nan     | nan     | nan        | nan     | nan    | nan       | nan     |
| nan     | nan     | nan     | nan    | nan     | nan     | nan    | nan     | nan    | nan     | nan        | nan     | nan     | nan     | nan     | nan    | nan        | nan     | nan     | nan     | nan     | nan       | nan      | nan     | nan     | nan        | nan     | nan    | nan       | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  50000
IMAGE SIZE: torch.Size([10, 3, 96, 96])
SAVING FOLDER FOR UNSUP:  STL10_CIFAR10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 2.16e-01	time: 00:06:05	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.482e-02/SW:1.116e-01/MR:2.693e+00/SR:1.925e+00/MeD:1.561e+00/MaD:8.508e+00/MW:0.687/MAW:0.313
|          0 |        1 |         2 |         3 |         4 |          5 |         6 |          7 |         8 |         9 |       10 |       11 |        12 |        13 |       14 |        15 |        16 |         17 |         18 |        19 |        20 |        21 |         22 |        23 |         24 |         25 |        26 |         27 |        28 |        29 |
|------------+----------+-----------+-----------+-----------+------------+-----------+------------+-----------+-----------+----------+----------+-----------+-----------+----------+-----------+-----------+------------+------------+-----------+-----------+-----------+------------+-----------+------------+------------+-----------+------------+-----------+-----------|
|   0.000405 |   0.0118 |   0.00932 |   0.00131 |   0.00281 |   5.88e-05 |   0.00276 |   8.39e-05 |   0.00576 |   0.00022 |   0.0122 |   0.0067 |   0.00277 |   0.00199 |   0.0131 |   0.00623 |   0.00141 |   0.000776 |   8.07e-05 |   0.00761 |   0.00124 |   0.00245 |   9.13e-05 |   0.00552 |   0.000462 |   0.000621 |   0.00436 |   0.000371 |   0.00762 |   0.00139 |
|   1.01     |   6.56   |   4.48    |   1.07    |   1.32    |   1        |   1.3     |   1        |   2.33    |   1       |   6.96   |   2.79   |   1.31    |   1.16    |   7.86   |   2.55    |   1.08    |   1.02     |   1        |   3.32    |   1.06    |   1.24    |   1        |   2.22    |   1.01     |   1.02     |   1.76    |   1.01     |   3.32    |   1.08    |
|   0.14     |   0.02   |   0.07    |   0.25    |   0.06    |   2.02     |   0.02    |   0.46     |   0.04    |   0.13    |   0.05   |   0.02   |   0.05    |   0.02    |   0.05   |   0.02    |   0.06    |   0.03     |   1.41     |   0.02    |   0.22    |   0.03    |   1.26     |   0.03    |   0.09     |   0.23     |   0.09    |   0.07     |   0.03    |   0.04    |
| nan        | nan      | nan       | nan       | nan       | nan        | nan       | nan        | nan       | nan       | nan      | nan      | nan       | nan       | nan      | nan       | nan       | nan        | nan        | nan       | nan       | nan       | nan        | nan       | nan        | nan        | nan       | nan        | nan       | nan       |
| nan        | nan      | nan       | nan       | nan       | nan        | nan       | nan        | nan       | nan       | nan      | nan      | nan       | nan       | nan      | nan       | nan       | nan        | nan        | nan       | nan       | nan       | nan        | nan       | nan        | nan        | nan       | nan        | nan       | nan       |
| nan        | nan      | nan       | nan       | nan       | nan        | nan       | nan        | nan       | nan       | nan      | nan      | nan       | nan       | nan      | nan       | nan       | nan        | nan        | nan       | nan       | nan       | nan        | nan       | nan        | nan        | nan       | nan        | nan       | nan       |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  50000
IMAGE SIZE: torch.Size([10, 3, 96, 96])
SAVING FOLDER FOR UNSUP:  STL10_CIFAR10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.90e-02	time: 00:09:22	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:3.706e-03/SW:1.252e-01/MR:6.367e+00/SR:3.700e+00/MeD:3.127e+00/MaD:1.006e+01/MW:0.666/MAW:0.334
|        0 |        1 |        2 |        3 |        4 |        5 |        6 |        7 |        8 |        9 |       10 |        11 |       12 |       13 |       14 |       15 |         16 |      17 |         18 |       19 |       20 |       21 |         22 |       23 |       24 |       25 |       26 |       27 |       28 |        29 |
|----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+-----------+----------+----------+----------+----------+------------+---------+------------+----------+----------+----------+------------+----------+----------+----------+----------+----------+----------+-----------|
|   0.0313 |   0.0245 |   0.0278 |   0.0183 |   0.0113 |   0.0282 |   0.0315 |   0.0284 |   0.0279 |   0.0295 |   0.0362 |   0.00727 |   0.0159 |   0.0337 |   0.0166 |   0.0218 |   0.000126 |   0.031 |   0.000394 |   0.0295 |   0.0107 |   0.0373 |   0.000354 |   0.0279 |   0.0318 |   0.0238 |   0.0191 |   0.0172 |   0.0265 |   0.00253 |
|  10.79   |   7      |   8.73   |   4.35   |   2.27   |   8.92   |  10.9    |   9.05   |   8.77   |   9.68   |  14.07   |   1.53    |   3.52   |  12.32   |   3.77   |   5.75   |   1        |  10.59  |   1        |   9.71   |   2.15   |  14.89   |   1        |   8.8    |  11.09   |   6.66   |   4.65   |   3.97   |   8.02   |   1.06    |
|   0.03   |   0.02   |   0.02   |   0      |   0      |   0.03   |   0.03   |   0.02   |   0.02   |   0.03   |   0.03   |   0       |   0      |   0.02   |   0      |   0.02   |   0.32     |   0     |   0.01     |   0.02   |   0      |   0.01   |   0.02     |   0.03   |   0.03   |   0.03   |   0      |   0      |   0.02   |   0.01    |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan        | nan     | nan        | nan      | nan      | nan      | nan        | nan      | nan      | nan      | nan      | nan      | nan      | nan       |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan        | nan     | nan        | nan      | nan      | nan      | nan        | nan      | nan      | nan      | nan      | nan      | nan      | nan       |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan        | nan     | nan        | nan      | nan      | nan      | nan        | nan      | nan      | nan      | nan      | nan      | nan      | nan       |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models

 ********** Hebbian Unsupervised learning of blocks [3] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  50000
IMAGE SIZE: torch.Size([10, 3, 96, 96])
SAVING FOLDER FOR UNSUP:  STL10_CIFAR10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 2.03e-02	time: 00:15:03	Acc_train 0.00	Acc_test 0.00	convergence: 1.20e+01	R1: 81	Info MB:0.000e+00/SB:0.000e+00/MW:5.564e-03/SW:1.172e-01/MR:1.295e+01/SR:4.738e+00/MeD:3.603e+00/MaD:1.195e+01/MW:0.569/MAW:0.431
|        0 |        1 |        2 |       3 |        4 |        5 |        6 |         7 |        8 |       9 |       10 |       11 |      12 |       13 |       14 |      15 |       16 |       17 |       18 |       19 |       20 |       21 |       22 |       23 |       24 |        25 |       26 |       27 |       28 |       29 |
|----------+----------+----------+---------+----------+----------+----------+-----------+----------+---------+----------+----------+---------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+-----------+----------+----------+----------+----------|
|   0.0351 |   0.0432 |   0.0351 |   0.034 |   0.0375 |   0.0332 |   0.0423 |   0.00916 |   0.0434 |   0.041 |   0.0356 |   0.0376 |   0.036 |   0.0308 |   0.0368 |   0.037 |   0.0292 |   0.0365 |   0.0375 |   0.0137 |   0.0407 |   0.0351 |   0.0421 |   0.0377 |   0.0369 |   0.00972 |   0.0152 |   0.0402 |   0.0315 |   0.0383 |
|  13.29   |  19.69   |  13.32   |  12.55  |  15.04   |  12.03   |  18.86   |   1.84    |  19.8    |  17.85  |  13.7    |  15.13   |  13.97  |  10.5    |  14.56   |  14.67  |   9.53   |  14.35   |  15.07   |   2.87   |  17.54   |  13.29   |  18.76   |  15.18   |  14.6    |   1.95    |   3.32   |  17.12   |  10.94   |  15.69   |
|   0.01   |   0.01   |   0.01   |   0     |   0.02   |   0.01   |   0.01   |   0       |   0.01   |   0.01  |   0.01   |   0.01   |   0.01  |   0.01   |   0.01   |   0.01  |   0      |   0.01   |   0      |   0      |   0.01   |   0.01   |   0.01   |   0      |   0.01   |   0.02    |   0      |   0.01   |   0.01   |   0.01   |
| nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan       | nan      | nan     | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan       | nan      | nan     | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan       | nan      | nan     | nan      | nan      | nan     | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models

 ********** Supervised learning of blocks [4] **********
SAVING FOLDER FOR SUP:  STL10_CIFAR10_CL
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  50000
IMAGE SIZE: torch.Size([64, 3, 96, 96])
Epoch: [1/50]	lr: 1.00e-03	time: 00:16:21	Loss_train 3.06100	Acc_train 56.78	/	Loss_test 0.15236	Acc_test 64.34
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models
Epoch: [10/50]	lr: 1.00e-03	time: 00:24:26	Loss_train 1.46576	Acc_train 77.54	/	Loss_test 0.17270	Acc_test 73.36
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models
Epoch: [20/50]	lr: 2.50e-04	time: 00:33:24	Loss_train 0.46147	Acc_train 90.28	/	Loss_test 0.11795	Acc_test 78.55
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models
Epoch: [30/50]	lr: 1.25e-04	time: 00:42:23	Loss_train 0.21693	Acc_train 94.08	/	Loss_test 0.11097	Acc_test 78.74
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models
Epoch: [40/50]	lr: 3.13e-05	time: 00:51:21	Loss_train 0.12516	Acc_train 95.85	/	Loss_test 0.10697	Acc_test 79.45
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models
Epoch: [50/50]	lr: 7.81e-06	time: 01:00:20	Loss_train 0.10389	Acc_train 96.33	/	Loss_test 0.10625	Acc_test 79.57
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models
RESULT:  {'train_loss': 0.10389330983161926, 'train_acc': 96.33319973945618, 'test_loss': 0.10625205188989639, 'test_acc': 79.56999969482422, 'convergence': 11.954227447509766, 'R1': 81, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 96}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 96}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't8': {'blocks': [4], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}
IN R1:  {'eval_1': {'test_loss': 1.7046663761138916, 'test_acc': 74.94999694824219, 'convergence': 12.583572387695312, 'R1': 43, 'dataset_sup': {'name': 'STL10', 'noise_std': 0, 'channels': 3, 'width': 96, 'height': 96, 'validation_split': 0.2, 'training_sample': 5000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 4, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': True, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 100, 'print_freq': 10, 'validation': False, 'continual_learning': False}, 'dataset_unsup': {'name': 'STL10', 'noise_std': 0, 'channels': 3, 'width': 96, 'height': 96, 'validation_split': 0.2, 'training_sample': 100000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 32, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'unlabeled', 'nb_epoch': 1, 'print_freq': 25, 'validation': False, 'continual_learning': False}}, 'R1': {'train_loss': 0.10389330983161926, 'train_acc': 96.33319973945618, 'test_loss': 0.10625205188989639, 'test_acc': 79.56999969482422, 'convergence': 11.954227447509766, 'R1': 81, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 96}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 96}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't8': {'blocks': [4], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}}
SEED:  0
block 0, size : 96 48 48
range = 2.886751345948129
block 1, size : 384 24 24
range = 0.8505172717997146
block 2, size : 1536 12 12
range = 0.4252586358998573
block 3, size : 6144 6 6
range = 0.21262931794992865
range = 0.036828478186799345
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.00032, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.00032, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.45, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.00032, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.21262931794992865, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 6144, 'kernel_size': 3, 'in_channels': 1536, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.00032, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.036828478186799345, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10, 'in_channels': 221184, 'old_channels': 6144, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 Model STL10_CIFAR10_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- AvgPool2d(kernel_size=4, stride=2, padding=1)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.44999998807907104reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.44999998807907104, bias=False, lr_bias=0.2222, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- AvgPool2d(kernel_size=4, stride=2, padding=1)

 ----- Architecture Block BatchNorm2dSK153661442(3, 3)0.25reflect, number 3 -----
- BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(1536, 6144, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 4 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=221184, out_features=10, bias=True)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  5000
IMAGE SIZE: torch.Size([32, 3, 96, 96])
SAVING FOLDER FOR UNSUP:  STL10_CIFAR10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.29e-01	time: 00:00:28	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:4.355e-03/SW:4.918e-01/MR:3.992e+00/SR:1.492e+00/MeD:1.172e+00/MaD:3.381e+00/MW:0.617/MAW:0.383
|       0 |       1 |       2 |       3 |      4 |       5 |       6 |       7 |       8 |      9 |         10 |      11 |      12 |      13 |      14 |      15 |      16 |      17 |      18 |      19 |      20 |        21 |       22 |      23 |      24 |         25 |      26 |      27 |        28 |      29 |
|---------+---------+---------+---------+--------+---------+---------+---------+---------+--------+------------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+-----------+----------+---------+---------+------------+---------+---------+-----------+---------|
|   0.111 |   0.104 |   0.149 |   0.167 |   0.16 |   0.195 |   0.148 |   0.116 |   0.151 |   0.15 |   0.000567 |   0.158 |   0.188 |   0.113 |   0.108 |   0.116 |   8e-07 |   0.173 |   0.107 |   0.146 |   0.151 |   0.00188 |   0.0778 |   0.149 |   0.182 |   1.95e-05 |   0.174 |   0.081 |   0.00169 |   0.178 |
|   2.93  |   2.69  |   4.45  |   5.34  |   5.01 |   6.97  |   4.44  |   3.09  |   4.55  |   4.53 |   1        |   4.91  |   6.51  |   3.01  |   2.82  |   3.11  |   1     |   5.65  |   2.79  |   4.35  |   4.56  |   1       |   1.95   |   4.48  |   6.15  |   1        |   5.72  |   2.03  |   1       |   5.93  |
|   0.35  |   0.42  |   0.59  |   0.64  |   0.37 |   0.51  |   0.4   |   0.48  |   0.44  |   0.39 |   2.9      |   0.35  |   0.3   |   0.64  |   0.6   |   0.59  |  23.21  |   0.6   |   0.63  |   0.34  |   0.4   |   0.84    |   0.34   |   0.37  |   0.76  |  27.08     |   0.48  |   0.45  |   0.84    |   0.51  |
| nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan    | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan       | nan      | nan     | nan     | nan        | nan     | nan     | nan       | nan     |
| nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan    | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan       | nan      | nan     | nan     | nan        | nan     | nan     | nan       | nan     |
| nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan    | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan       | nan      | nan     | nan     | nan        | nan     | nan     | nan       | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  5000
IMAGE SIZE: torch.Size([32, 3, 96, 96])
SAVING FOLDER FOR UNSUP:  STL10_CIFAR10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.29e-01	time: 00:00:57	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.443e-02/SW:9.276e-02/MR:2.394e+00/SR:1.374e+00/MeD:1.205e+00/MaD:3.644e+00/MW:0.542/MAW:0.458
|        0 |         1 |         2 |         3 |         4 |          5 |         6 |          7 |         8 |          9 |        10 |        11 |        12 |        13 |        14 |        15 |        16 |         17 |         18 |        19 |        20 |        21 |         22 |        23 |         24 |         25 |       26 |         27 |        28 |        29 |
|----------+-----------+-----------+-----------+-----------+------------+-----------+------------+-----------+------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+------------+------------+-----------+-----------+-----------+------------+-----------+------------+------------+----------+------------+-----------+-----------|
|   0.0004 |   0.00999 |   0.00851 |   0.00132 |   0.00281 |   5.89e-05 |   0.00277 |   8.03e-05 |   0.00575 |   0.000213 |   0.00885 |   0.00676 |   0.00278 |   0.00201 |   0.00978 |   0.00628 |   0.00141 |   0.000776 |   8.08e-05 |   0.00759 |   0.00124 |   0.00243 |   9.13e-05 |   0.00563 |   0.000463 |   0.000622 |   0.0044 |   0.000364 |   0.00774 |   0.00138 |
|   1.01   |   4.99    |   3.9     |   1.07    |   1.31    |   1        |   1.31    |   1        |   2.32    |   1        |   4.13    |   2.83    |   1.31    |   1.16    |   4.83    |   2.58    |   1.08    |   1.02     |   1        |   3.3     |   1.06    |   1.24    |   1        |   2.27    |   1.01     |   1.02     |   1.77   |   1.01     |   3.4     |   1.08    |
|   0.43   |   0.35    |   0.25    |   0.09    |   0.07    |   0.12     |   0.05    |   2.53     |   0.04    |   0.96     |   0.49    |   0.04    |   0.08    |   0.05    |   0.4     |   0.03    |   0.11    |   0.22     |   0.17     |   0.08    |   0.04    |   0.12    |   0.08     |   0.06    |   0.21     |   0.1      |   0.07   |   0.48     |   0.08    |   0.14    |
| nan      | nan       | nan       | nan       | nan       | nan        | nan       | nan        | nan       | nan        | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan        | nan        | nan       | nan       | nan       | nan        | nan       | nan        | nan        | nan      | nan        | nan       | nan       |
| nan      | nan       | nan       | nan       | nan       | nan        | nan       | nan        | nan       | nan        | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan        | nan        | nan       | nan       | nan       | nan        | nan       | nan        | nan        | nan      | nan        | nan       | nan       |
| nan      | nan       | nan       | nan       | nan       | nan        | nan       | nan        | nan       | nan        | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan        | nan        | nan       | nan       | nan       | nan        | nan       | nan        | nan        | nan      | nan        | nan       | nan       |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  5000
IMAGE SIZE: torch.Size([32, 3, 96, 96])
SAVING FOLDER FOR UNSUP:  STL10_CIFAR10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.90e-02	time: 00:01:27	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:3.741e-03/SW:1.119e-01/MR:5.777e+00/SR:3.158e+00/MeD:2.724e+00/MaD:7.317e+00/MW:0.619/MAW:0.381
|        0 |        1 |        2 |        3 |        4 |       5 |        6 |        7 |        8 |       9 |      10 |       11 |       12 |       13 |       14 |      15 |         16 |       17 |        18 |       19 |       20 |       21 |         22 |       23 |       24 |       25 |       26 |       27 |       28 |        29 |
|----------+----------+----------+----------+----------+---------+----------+----------+----------+---------+---------+----------+----------+----------+----------+---------+------------+----------+-----------+----------+----------+----------+------------+----------+----------+----------+----------+----------+----------+-----------|
|   0.0295 |   0.0201 |   0.0283 |   0.0184 |   0.0113 |   0.027 |   0.0306 |   0.0265 |   0.0277 |   0.023 |   0.031 |   0.0073 |   0.0159 |   0.0309 |   0.0167 |   0.022 |   0.000129 |   0.0292 |   0.00039 |   0.0294 |   0.0107 |   0.0313 |   0.000353 |   0.0268 |   0.0319 |   0.0245 |   0.0192 |   0.0173 |   0.0272 |   0.00255 |
|   9.7    |   5.02   |   8.99   |   4.37   |   2.28   |   8.3   |  10.39   |   8.01   |   8.66   |   6.29  |  10.59  |   1.53   |   3.53   |  10.56   |   3.77   |   5.84  |   1        |   9.51   |   1       |   9.63   |   2.15   |  10.77   |   1        |   8.21   |  11.16   |   6.99   |   4.68   |   3.98   |   8.4    |   1.06    |
|   0.04   |   0.05   |   0.01   |   0      |   0      |   0.03  |   0.03   |   0.04   |   0.03   |   0.06  |   0.07  |   0      |   0      |   0.05   |   0      |   0.01  |   0.23     |   0.04   |   0.13    |   0.03   |   0.01   |   0.03   |   0.15     |   0.02   |   0.03   |   0.01   |   0      |   0      |   0.01   |   0.01    |
| nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan     | nan     | nan      | nan      | nan      | nan      | nan     | nan        | nan      | nan       | nan      | nan      | nan      | nan        | nan      | nan      | nan      | nan      | nan      | nan      | nan       |
| nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan     | nan     | nan      | nan      | nan      | nan      | nan     | nan        | nan      | nan       | nan      | nan      | nan      | nan        | nan      | nan      | nan      | nan      | nan      | nan      | nan       |
| nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan     | nan     | nan      | nan      | nan      | nan      | nan     | nan        | nan      | nan       | nan      | nan      | nan      | nan        | nan      | nan      | nan      | nan      | nan      | nan      | nan       |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models

 ********** Hebbian Unsupervised learning of blocks [3] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  5000
IMAGE SIZE: torch.Size([32, 3, 96, 96])
SAVING FOLDER FOR UNSUP:  STL10_CIFAR10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.93e-02	time: 00:02:12	Acc_train 0.00	Acc_test 0.00	convergence: 1.16e+01	R1: 82	Info MB:0.000e+00/SB:0.000e+00/MW:5.537e-03/SW:1.139e-01/MR:1.262e+01/SR:4.536e+00/MeD:3.443e+00/MaD:1.162e+01/MW:0.533/MAW:0.467
|        0 |        1 |        2 |        3 |        4 |        5 |        6 |         7 |        8 |        9 |       10 |       11 |       12 |       13 |      14 |       15 |       16 |       17 |       18 |       19 |       20 |       21 |       22 |       23 |       24 |       25 |       26 |       27 |       28 |       29 |
|----------+----------+----------+----------+----------+----------+----------+-----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------|
|   0.0354 |   0.0443 |   0.0355 |   0.0344 |   0.0377 |   0.0335 |   0.0407 |   0.00926 |   0.0383 |   0.0388 |   0.0361 |   0.0383 |   0.0364 |   0.0309 |   0.037 |   0.0368 |   0.0293 |   0.0369 |   0.0369 |   0.0137 |   0.0403 |   0.0356 |   0.0431 |   0.0382 |   0.0354 |   0.0097 |   0.0152 |   0.0406 |   0.0317 |   0.0378 |
|  13.57   |  20.65   |  13.59   |  12.82   |  15.23   |  12.24   |  17.59   |   1.86    |  15.67   |  16.07   |  14.01   |  15.68   |  14.24   |  10.53   |  14.66  |  14.53   |   9.61   |  14.61   |  14.59   |   2.88   |  17.26   |  13.68   |  19.58   |  15.61   |  13.54   |   1.94   |   3.32   |  17.47   |  11.07   |  15.26   |
|   0      |   0.01   |   0      |   0      |   0.01   |   0.01   |   0.01   |   0.02    |   0.04   |   0.01   |   0      |   0      |   0.01   |   0      |   0     |   0      |   0      |   0      |   0.01   |   0      |   0.01   |   0.01   |   0.01   |   0.01   |   0.01   |   0.01   |   0      |   0.01   |   0      |   0.01   |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  5000
IMAGE SIZE: torch.Size([64, 3, 96, 96])
Accuracy of the network on the 1st dataset: 35.150 %
Test loss on the 1st dataset: 17.383

