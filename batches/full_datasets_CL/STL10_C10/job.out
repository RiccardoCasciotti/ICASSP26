BLOCKS:  {'b0': {'arch': 'CNN', 'preset': 'softkrotov-c96-k5-p2-s1-d1-b0-t1-lr0.08-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 0, 'batch_norm': False, 'pool': {'type': 'avg', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 0.7}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5}}, 'b1': {'arch': 'CNN', 'preset': 'softkrotov-c384-k3-p1-s1-d1-b0-t0.65-lr0.005-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 1, 'batch_norm': False, 'pool': {'type': 'max', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 0.7}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3}}, 'b2': {'arch': 'CNN', 'preset': 'softkrotov-c1536-k3-p1-s1-d1-b0-t0.45-lr0.01-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 2, 'batch_norm': False, 'pool': {'type': 'avg', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 1.4}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.45, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3}}, 'b3': {'arch': 'CNN', 'preset': 'softkrotov-c6144-k3-p1-s1-d1-b0-t0.25-lr0.01-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 3, 'batch_norm': False, 'pool': {'type': 'avg', 'kernel_size': 2, 'stride': 2, 'padding': 0}, 'activation': {'function': 'triangle', 'param': 1}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 6144, 'kernel_size': 3}}, 'b4': {'arch': 'MLP', 'preset': 'BP-c10', 'operation': 'flatten', 'num': 4, 'att_dropout': None, 'dropout': 0.5, 'layer': {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.25, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10}, 'pool': None, 'activation': None}}
CL:  True
{'name': 'STL10', 'noise_std': 0, 'channels': 3, 'width': 96, 'height': 96, 'validation_split': 0.2, 'training_sample': 5000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': True, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 100, 'print_freq': 10, 'validation': False, 'continual_learning': True}
CL:  False
{'name': 'STL10', 'noise_std': 0, 'channels': 3, 'width': 96, 'height': 96, 'validation_split': 0.2, 'training_sample': 5000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': True, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 100, 'print_freq': 10, 'validation': False, 'continual_learning': False}
CL:  False
{'name': 'STL10', 'noise_std': 0, 'channels': 3, 'width': 96, 'height': 96, 'validation_split': 0.2, 'training_sample': 100000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 32, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'unlabeled', 'nb_epoch': 1, 'print_freq': 25, 'validation': False, 'continual_learning': False}
SEED:  0
block 0, size : 96 48 48
range = 2.886751345948129
block 1, size : 384 24 24
range = 0.8505172717997146
block 2, size : 1536 12 12
range = 0.4252586358998573
block 3, size : 6144 6 6
range = 0.21262931794992865
range = 0.036828478186799345
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.00032, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.00032, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.45, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.00032, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.21262931794992865, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 6144, 'kernel_size': 3, 'in_channels': 1536, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.00032, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.036828478186799345, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10, 'in_channels': 221184, 'old_channels': 6144, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 Model STL10_CIFAR10_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- AvgPool2d(kernel_size=4, stride=2, padding=1)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.44999998807907104reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.44999998807907104, bias=False, lr_bias=0.2222, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- AvgPool2d(kernel_size=4, stride=2, padding=1)

 ----- Architecture Block BatchNorm2dSK153661442(3, 3)0.25reflect, number 3 -----
- BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(1536, 6144, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 4 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=221184, out_features=10, bias=True)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  5000
IMAGE SIZE: torch.Size([32, 3, 96, 96])
SAVING FOLDER FOR UNSUP:  STL10_CIFAR10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.29e-01	time: 00:00:29	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:5.232e-03/SW:5.085e-01/MR:4.050e+00/SR:1.738e+00/MeD:1.490e+00/MaD:3.610e+00/MW:0.615/MAW:0.385
|        0 |        1 |       2 |       3 |       4 |       5 |       6 |      7 |       8 |       9 |        10 |      11 |      12 |     13 |       14 |      15 |      16 |      17 |      18 |     19 |      20 |        21 |       22 |      23 |      24 |         25 |      26 |       27 |        28 |      29 |
|----------+----------+---------+---------+---------+---------+---------+--------+---------+---------+-----------+---------+---------+--------+----------+---------+---------+---------+---------+--------+---------+-----------+----------+---------+---------+------------+---------+----------+-----------+---------|
|   0.0977 |   0.0168 |   0.112 |   0.129 |   0.121 |   0.197 |   0.158 |   0.11 |   0.153 |   0.172 |   0.00063 |   0.117 |   0.194 |   0.1  |   0.0934 |   0.116 |   8e-07 |   0.181 |   0.106 |   0.11 |   0.166 |   0.00214 |   0.0547 |   0.166 |   0.169 |   1.95e-05 |   0.174 |   0.0797 |   0.00184 |   0.181 |
|   2.49   |   1.04   |   2.95  |   3.62  |   3.3   |   7.04  |   4.9   |   2.9  |   4.67  |   5.63  |   1       |   3.15  |   6.9   |   2.57 |   2.36   |   3.1   |   1     |   6.1   |   2.76  |   2.87 |   5.29  |   1       |   1.47   |   5.33  |   5.45  |   1        |   5.7   |   1.99   |   1       |   6.1   |
|   0.51   |   0.85   |   0.64  |   0.8   |   0.26  |   0.51  |   0.37  |   0.64 |   0.46  |   0.32  |   2.91    |   0.26  |   0.48  |   0.69 |   0.59   |   0.57  |  23.05  |   0.73  |   0.65  |   0.26 |   0.34  |   0.79    |   0.25   |   0.27  |   1.03  |  26.86     |   0.47  |   0.47   |   0.84    |   0.55  |
| nan      | nan      | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan       | nan     | nan     | nan    | nan      | nan     | nan     | nan     | nan     | nan    | nan     | nan       | nan      | nan     | nan     | nan        | nan     | nan      | nan       | nan     |
| nan      | nan      | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan       | nan     | nan     | nan    | nan      | nan     | nan     | nan     | nan     | nan    | nan     | nan       | nan      | nan     | nan     | nan        | nan     | nan      | nan       | nan     |
| nan      | nan      | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan       | nan     | nan     | nan    | nan      | nan     | nan     | nan     | nan     | nan    | nan     | nan       | nan      | nan     | nan     | nan        | nan     | nan      | nan       | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  5000
IMAGE SIZE: torch.Size([32, 3, 96, 96])
SAVING FOLDER FOR UNSUP:  STL10_CIFAR10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.29e-01	time: 00:00:58	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.409e-02/SW:9.350e-02/MR:2.378e+00/SR:1.440e+00/MeD:1.242e+00/MaD:3.822e+00/MW:0.538/MAW:0.462
|          0 |      1 |         2 |          3 |         4 |         5 |         6 |          7 |         8 |         9 |        10 |        11 |        12 |       13 |        14 |        15 |        16 |         17 |         18 |        19 |       20 |        21 |        22 |        23 |         24 |         25 |        26 |         27 |        28 |        29 |
|------------+--------+-----------+------------+-----------+-----------+-----------+------------+-----------+-----------+-----------+-----------+-----------+----------+-----------+-----------+-----------+------------+------------+-----------+----------+-----------+-----------+-----------+------------+------------+-----------+------------+-----------+-----------|
|   0.000435 |   0.01 |   0.00966 |   0.000371 |   0.00313 |   0.00396 |   0.00306 |   8.07e-05 |   0.00766 |   0.00025 |   0.00774 |   0.00676 |   0.00293 |   0.0024 |   0.00489 |   0.00621 |   0.00174 |   0.000854 |   4.77e-05 |   0.00914 |   0.0012 |   0.00252 |   0.00713 |   0.00575 |   0.000475 |   0.000483 |   0.00911 |   0.000404 |   0.00901 |   0.00146 |
|   1.01     |   5.03 |   4.73    |   1.01     |   1.39    |   1.63    |   1.38    |   1        |   3.35    |   1       |   3.39    |   2.83    |   1.34    |   1.23   |   1.96    |   2.54    |   1.12    |   1.03     |   1        |   4.34    |   1.06   |   1.25    |   3.04    |   2.32    |   1.01     |   1.01     |   4.32    |   1.01     |   4.25    |   1.09    |
|   0.38     |   0.21 |   0.26    |   0.14     |   0.06    |   0.04    |   0.04    |   2.28     |   0.06    |   0.75    |   0.21    |   0.03    |   0.03    |   0.06   |   0.05    |   0.03    |   0.09    |   0.12     |   0.22     |   0.13    |   0.09   |   0.05    |   0.06    |   0.04    |   0.12     |   0.16     |   0.17    |   0.27     |   0.12    |   0.09    |
| nan        | nan    | nan       | nan        | nan       | nan       | nan       | nan        | nan       | nan       | nan       | nan       | nan       | nan      | nan       | nan       | nan       | nan        | nan        | nan       | nan      | nan       | nan       | nan       | nan        | nan        | nan       | nan        | nan       | nan       |
| nan        | nan    | nan       | nan        | nan       | nan       | nan       | nan        | nan       | nan       | nan       | nan       | nan       | nan      | nan       | nan       | nan       | nan        | nan        | nan       | nan      | nan       | nan       | nan       | nan        | nan        | nan       | nan        | nan       | nan       |
| nan        | nan    | nan       | nan        | nan       | nan       | nan       | nan        | nan       | nan       | nan       | nan       | nan       | nan      | nan       | nan       | nan       | nan        | nan        | nan       | nan      | nan       | nan       | nan       | nan        | nan        | nan       | nan        | nan       | nan       |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  5000
IMAGE SIZE: torch.Size([32, 3, 96, 96])
SAVING FOLDER FOR UNSUP:  STL10_CIFAR10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.90e-02	time: 00:01:28	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:2.987e-03/SW:1.115e-01/MR:5.685e+00/SR:3.274e+00/MeD:2.865e+00/MaD:7.909e+00/MW:0.625/MAW:0.375
|        0 |        1 |        2 |        3 |        4 |       5 |        6 |        7 |        8 |        9 |       10 |        11 |       12 |       13 |       14 |       15 |       16 |       17 |        18 |       19 |       20 |       21 |         22 |       23 |       24 |       25 |       26 |       27 |       28 |        29 |
|----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+-----------+----------+----------+----------+----------+----------+----------+-----------+----------+----------+----------+------------+----------+----------+----------+----------+----------+----------+-----------|
|   0.0348 |   0.0263 |   0.0247 |   0.0193 |   0.0114 |   0.029 |   0.0258 |   0.0296 |   0.0281 |   0.0252 |   0.0332 |   0.00782 |   0.0168 |   0.0257 |   0.0177 |   0.0215 |   0.0179 |   0.0268 |   0.00041 |   0.0249 |   0.0116 |   0.0248 |   0.000333 |   0.0295 |   0.0273 |   0.0268 |   0.0198 |   0.0182 |   0.0278 |   0.00282 |
|  13.14   |   7.93   |   7.08   |   4.71   |   2.29   |   9.43  |   7.67   |   9.74   |   8.88   |   7.36   |  12.03   |   1.61    |   3.82   |   7.62   |   4.14   |   5.62   |   4.19   |   8.2    |   1       |   7.18   |   2.35   |   7.17   |   1        |   9.72   |   8.44   |   8.18   |   4.91   |   4.32   |   8.74   |   1.08    |
|   0.03   |   0.01   |   0      |   0      |   0      |   0.02  |   0      |   0.03   |   0.02   |   0.06   |   0.02   |   0       |   0      |   0.03   |   0      |   0      |   0      |   0.04   |   0.08    |   0.01   |   0      |   0.02   |   0.09     |   0.01   |   0.02   |   0.02   |   0      |   0      |   0.02   |   0.01    |
| nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan        | nan      | nan      | nan      | nan      | nan      | nan      | nan       |
| nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan        | nan      | nan      | nan      | nan      | nan      | nan      | nan       |
| nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan        | nan      | nan      | nan      | nan      | nan      | nan      | nan       |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models

 ********** Hebbian Unsupervised learning of blocks [3] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  5000
IMAGE SIZE: torch.Size([32, 3, 96, 96])
SAVING FOLDER FOR UNSUP:  STL10_CIFAR10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.88e-02	time: 00:02:07	Acc_train 0.00	Acc_test 0.00	convergence: 1.01e+01	R1: 119	Info MB:0.000e+00/SB:0.000e+00/MW:5.906e-03/SW:1.009e-01/MR:1.114e+01/SR:4.128e+00/MeD:3.165e+00/MaD:1.014e+01/MW:0.543/MAW:0.457
|        0 |        1 |        2 |       3 |        4 |        5 |        6 |         7 |        8 |        9 |       10 |       11 |        12 |      13 |       14 |       15 |       16 |       17 |      18 |       19 |       20 |       21 |       22 |       23 |       24 |        25 |       26 |       27 |       28 |        29 |
|----------+----------+----------+---------+----------+----------+----------+-----------+----------+----------+----------+----------+-----------+---------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+-----------+----------+----------+----------+-----------|
|   0.0324 |   0.0378 |   0.0362 |   0.032 |   0.0332 |   0.0293 |   0.0296 |   0.00964 |   0.0367 |   0.0354 |   0.0356 |   0.0312 |   0.00132 |   0.024 |   0.0182 |   0.0328 |   0.0317 |   0.0296 |   0.029 |   0.0143 |   0.0364 |   0.0339 |   0.0255 |   0.0415 |   0.0359 |   0.00218 |   0.0161 |   0.0381 |   0.0295 |   0.00188 |
|  11.51   |  15.29   |  14.1    |  11.27  |  12.01   |   9.61   |   9.75   |   1.93    |  14.45   |  13.54   |  13.66   |  10.75   |   1.02    |   6.75  |   4.31   |  11.74   |  11.02   |   9.78   |   9.42  |   3.04   |  14.22   |  12.48   |   7.51   |  18.26   |  13.87   |   1.05    |   3.61   |  15.49   |   9.71   |   1.04    |
|   0.02   |   0      |   0.01   |   0     |   0      |   0      |   0      |   0.01    |   0.01   |   0.01   |   0.01   |   0.01   |   0.04    |   0     |   0      |   0      |   0      |   0      |   0     |   0      |   0.02   |   0      |   0      |   0.03   |   0      |   0.03    |   0      |   0.03   |   0      |   0.03    |
| nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan       | nan     | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan       |
| nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan       | nan     | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan       |
| nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan       | nan     | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan       |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  5000
IMAGE SIZE: torch.Size([64, 3, 96, 96])
Accuracy of the network on the 1st dataset: 33.325 %
Test loss on the 1st dataset: 21.994
CL:  True
{'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True}
CL:  True
{'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
block 3, size : 6144 2 2
range = 0.21262931794992865
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.00032, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.00032, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.45, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.00032, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.21262931794992865, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 6144, 'kernel_size': 3, 'in_channels': 1536, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.00032, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.036828478186799345, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10, 'in_channels': 221184, 'old_channels': 6144, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 Model STL10_CIFAR10_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- AvgPool2d(kernel_size=4, stride=2, padding=1)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.44999998807907104reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.44999998807907104, bias=False, lr_bias=0.2222, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- AvgPool2d(kernel_size=4, stride=2, padding=1)

 ----- Architecture Block BatchNorm2dSK153661442(3, 3)0.25reflect, number 3 -----
- BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(1536, 6144, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 4 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=221184, out_features=10, bias=True)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  50000
IMAGE SIZE: torch.Size([10, 3, 96, 96])
SAVING FOLDER FOR UNSUP:  STL10_CIFAR10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.56e-01	time: 00:03:01	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:9.804e-03/SW:9.533e-01/MR:6.201e+00/SR:5.479e+00/MeD:4.517e+00/MaD:2.079e+01/MW:0.640/MAW:0.360
|        0 |        1 |        2 |       3 |       4 |       5 |       6 |       7 |       8 |       9 |         10 |       11 |      12 |      13 |      14 |      15 |        16 |      17 |      18 |       19 |      20 |        21 |       22 |      23 |      24 |         25 |      26 |      27 |        28 |      29 |
|----------+----------+----------+---------+---------+---------+---------+---------+---------+---------+------------+----------+---------+---------+---------+---------+-----------+---------+---------+----------+---------+-----------+----------+---------+---------+------------+---------+---------+-----------+---------|
|   0.0872 |   0.0234 |   0.0866 |   0.247 |   0.088 |   0.147 |   0.126 |   0.269 |   0.114 |   0.294 |   0.000506 |   0.0839 |   0.125 |   0.282 |   0.208 |   0.246 |   0.00028 |   0.145 |   0.115 |   0.0776 |   0.188 |   0.00413 |   0.0436 |   0.307 |   0.109 |   0.000225 |   0.125 |   0.102 |   0.00247 |   0.389 |
|   2.19   |   1.09   |   2.17   |  10.52  |   2.21  |   4.38  |   3.47  |  12.32  |   3.02  |  14.52  |   1        |   2.1    |   3.43  |  13.42  |   7.78  |  10.48  |   1       |   4.28  |   3.07  |   1.94   |   6.5   |   1       |   1.3    |  15.72  |   2.86  |   1        |   3.44  |   2.62  |   1       |  24.64  |
|   0.28   |   0.3    |   0.28   |   0.4   |   0.27  |   0.28  |   0.28  |   0.32  |   0.28  |   0.84  |   3.88     |   0.27   |   0.28  |   0.3   |   0.32  |   0.3   |  25.97    |   0.28  |   0.29  |   0.27   |   0.27  |   0.64    |   0.28   |   0.88  |   0.28  |  30.79     |   0.28  |   0.95  |   0.7     |   0.31  |
| nan      | nan      | nan      | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan      | nan     | nan     | nan     | nan     | nan       | nan     | nan     | nan      | nan     | nan       | nan      | nan     | nan     | nan        | nan     | nan     | nan       | nan     |
| nan      | nan      | nan      | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan      | nan     | nan     | nan     | nan     | nan       | nan     | nan     | nan      | nan     | nan       | nan      | nan     | nan     | nan        | nan     | nan     | nan       | nan     |
| nan      | nan      | nan      | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan      | nan     | nan     | nan     | nan     | nan       | nan     | nan     | nan      | nan     | nan       | nan      | nan     | nan     | nan        | nan     | nan     | nan       | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  50000
IMAGE SIZE: torch.Size([10, 3, 96, 96])
SAVING FOLDER FOR UNSUP:  STL10_CIFAR10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.56e-01	time: 00:06:02	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.499e-02/SW:1.116e-01/MR:2.590e+00/SR:2.063e+00/MeD:1.655e+00/MaD:7.677e+00/MW:0.738/MAW:0.262
|          0 |          1 |         2 |          3 |        4 |         5 |         6 |         7 |         8 |          9 |       10 |       11 |        12 |       13 |        14 |        15 |        16 |         17 |        18 |       19 |        20 |        21 |        22 |        23 |         24 |         25 |        26 |         27 |        28 |        29 |
|------------+------------+-----------+------------+----------+-----------+-----------+-----------+-----------+------------+----------+----------+-----------+----------+-----------+-----------+-----------+------------+-----------+----------+-----------+-----------+-----------+-----------+------------+------------+-----------+------------+-----------+-----------|
|   0.000462 |   0.000106 |   0.00342 |   0.000383 |   0.0033 |   0.00409 |   0.00324 |   8.5e-05 |   0.00775 |   0.000266 |   0.0102 |   0.0073 |   0.00303 |   0.0025 |   0.00523 |   0.00657 |   0.00184 |   0.000881 |   4.9e-05 |   0.0111 |   0.00135 |   0.00252 |   0.00841 |   0.00597 |   0.000485 |   0.000518 |   0.00516 |   0.000417 |   0.00034 |   0.00148 |
|   1.01     |   1        |   1.47    |   1.01     |   1.44   |   1.67    |   1.42    |   1       |   3.4     |   1        |   5.17   |   3.13   |   1.37    |   1.25   |   2.09    |   2.72    |   1.14    |   1.03     |   1       |   5.91   |   1.07    |   1.26    |   3.83    |   2.43    |   1.01     |   1.01     |   2.07    |   1.01     |   1       |   1.09    |
|   0.08     |   1.54     |   0.13    |   0.05     |   0.02   |   0.02    |   0.03    |   0.14    |   0.03    |   0.07     |   0.05   |   0.02   |   0.02    |   0.02   |   0.01    |   0.01    |   0.02    |   0.03     |   0.07    |   0.02   |   0.04    |   0.02    |   0.02    |   0.01    |   0.03     |   0.06     |   0.05    |   0.04     |   0.5     |   0.02    |
| nan        | nan        | nan       | nan        | nan      | nan       | nan       | nan       | nan       | nan        | nan      | nan      | nan       | nan      | nan       | nan       | nan       | nan        | nan       | nan      | nan       | nan       | nan       | nan       | nan        | nan        | nan       | nan        | nan       | nan       |
| nan        | nan        | nan       | nan        | nan      | nan       | nan       | nan       | nan       | nan        | nan      | nan      | nan       | nan      | nan       | nan       | nan       | nan        | nan       | nan      | nan       | nan       | nan       | nan       | nan        | nan        | nan       | nan        | nan       | nan       |
| nan        | nan        | nan       | nan        | nan      | nan       | nan       | nan       | nan       | nan        | nan      | nan      | nan       | nan      | nan       | nan       | nan       | nan        | nan       | nan      | nan       | nan       | nan       | nan       | nan        | nan        | nan       | nan        | nan       | nan       |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  50000
IMAGE SIZE: torch.Size([10, 3, 96, 96])
SAVING FOLDER FOR UNSUP:  STL10_CIFAR10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.90e-02	time: 00:09:20	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:2.652e-03/SW:1.166e-01/MR:5.712e+00/SR:3.795e+00/MeD:3.356e+00/MaD:1.178e+01/MW:0.707/MAW:0.293
|          0 |       1 |        2 |        3 |        4 |        5 |        6 |       7 |        8 |        9 |      10 |        11 |       12 |       13 |       14 |       15 |       16 |       17 |         18 |       19 |       20 |       21 |         22 |      23 |       24 |       25 |      26 |       27 |       28 |        29 |
|------------+---------+----------+----------+----------+----------+----------+---------+----------+----------+---------+-----------+----------+----------+----------+----------+----------+----------+------------+----------+----------+----------+------------+---------+----------+----------+---------+----------+----------+-----------|
|   0.000494 |   0.027 |   0.0266 |   0.0209 |   0.0115 |   0.0285 |   0.0321 |   0.028 |   0.0145 |   0.0254 |   0.033 |   0.00787 |   0.0172 |   0.0246 |   0.0179 |   0.0319 |   0.0191 |   0.0246 |   0.000421 |   0.0345 |   0.0122 |   0.0245 |   0.000341 |   0.027 |   0.0211 |   0.0274 |   0.021 |   0.0189 |   0.0272 |   0.00285 |
|   1        |   8.29  |   8.1    |   5.36   |   2.32   |   9.13   |  11.33   |   8.82  |   3.11   |   7.44   |  11.86  |   1.62    |   3.95   |   7.08   |   4.21   |  11.19   |   4.66   |   7.04   |   1        |  12.93   |   2.48   |   7.02   |   1        |   8.3   |   5.46   |   8.53   |   5.43  |   4.59   |   8.42   |   1.08    |
|   0.17     |   0.01  |   0.01   |   0      |   0      |   0.01   |   0.02   |   0.03  |   0.02   |   0.02   |   0.03  |   0       |   0      |   0.02   |   0      |   0      |   0      |   0.02   |   0.01     |   0      |   0      |   0.01   |   0.01     |   0.02  |   0.02   |   0.01   |   0     |   0      |   0.02   |   0       |
| nan        | nan     | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan       | nan      | nan      | nan      | nan      | nan      | nan      | nan        | nan      | nan      | nan      | nan        | nan     | nan      | nan      | nan     | nan      | nan      | nan       |
| nan        | nan     | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan       | nan      | nan      | nan      | nan      | nan      | nan      | nan        | nan      | nan      | nan      | nan        | nan     | nan      | nan      | nan     | nan      | nan      | nan       |
| nan        | nan     | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan     | nan       | nan      | nan      | nan      | nan      | nan      | nan      | nan        | nan      | nan      | nan      | nan        | nan     | nan      | nan      | nan     | nan      | nan      | nan       |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models

 ********** Hebbian Unsupervised learning of blocks [3] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  50000
IMAGE SIZE: torch.Size([10, 3, 96, 96])
SAVING FOLDER FOR UNSUP:  STL10_CIFAR10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.82e-02	time: 00:15:01	Acc_train 0.00	Acc_test 0.00	convergence: 1.06e+01	R1: 158	Info MB:0.000e+00/SB:0.000e+00/MW:6.634e-03/SW:1.071e-01/MR:1.163e+01/SR:4.886e+00/MeD:3.902e+00/MaD:1.149e+01/MW:0.628/MAW:0.372
|       0 |        1 |       2 |        3 |        4 |       5 |        6 |        7 |        8 |        9 |       10 |       11 |         12 |       13 |       14 |       15 |       16 |       17 |       18 |       19 |       20 |       21 |       22 |      23 |       24 |        25 |      26 |       27 |       28 |       29 |
|---------+----------+---------+----------+----------+---------+----------+----------+----------+----------+----------+----------+------------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+-----------+---------+----------+----------+----------|
|   0.039 |   0.0391 |   0.034 |   0.0346 |   0.0375 |   0.033 |   0.0315 |   0.0097 |   0.0397 |   0.0353 |   0.0387 |   0.0382 |   0.000684 |   0.0245 |   0.0193 |   0.0408 |   0.0344 |   0.0326 |   0.0314 |   0.0142 |   0.0305 |   0.0367 |   0.0262 |   0.037 |   0.0356 |   0.00231 |   0.016 |   0.0426 |   0.0321 |   0.0015 |
|  16.21  |  16.3    |  12.57  |  12.98   |  15.1    |  11.88  |  10.94   |   1.94   |  16.77   |  13.45   |  15.98   |  15.58   |   1        |   6.99   |   4.71   |  17.68   |  12.82   |  11.6    |  10.86   |   3.02   |  10.33   |  14.49   |   7.84   |  14.69  |  13.65   |   1.05    |   3.58  |  19.17   |  11.34   |   1.02   |
|   0     |   0      |   0.01  |   0      |   0      |   0     |   0      |   0      |   0.01   |   0      |   0.01   |   0      |   0.12     |   0      |   0      |   0      |   0      |   0      |   0      |   0      |   0.01   |   0.01   |   0      |   0.01  |   0.01   |   0.01    |   0     |   0.01   |   0      |   0.04   |
| nan     | nan      | nan     | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan        | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan       | nan     | nan      | nan      | nan      |
| nan     | nan      | nan     | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan        | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan       | nan     | nan      | nan      | nan      |
| nan     | nan      | nan     | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan        | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan       | nan     | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models

 ********** Supervised learning of blocks [4] **********
SAVING FOLDER FOR SUP:  STL10_CIFAR10_CL
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  50000
IMAGE SIZE: torch.Size([64, 3, 96, 96])
Epoch: [1/50]	lr: 1.00e-03	time: 00:16:16	Loss_train 2.52943	Acc_train 72.45	/	Loss_test 0.24311	Acc_test 67.27
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models
Epoch: [10/50]	lr: 1.00e-03	time: 00:24:22	Loss_train 1.48210	Acc_train 82.52	/	Loss_test 0.24682	Acc_test 72.53
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models
Epoch: [20/50]	lr: 2.50e-04	time: 00:33:21	Loss_train 0.75202	Acc_train 88.94	/	Loss_test 0.18517	Acc_test 76.41
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models
Epoch: [30/50]	lr: 1.25e-04	time: 00:42:19	Loss_train 0.50542	Acc_train 91.25	/	Loss_test 0.16975	Acc_test 76.99
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models
Epoch: [40/50]	lr: 3.13e-05	time: 00:51:17	Loss_train 0.43929	Acc_train 92.04	/	Loss_test 0.15999	Acc_test 77.77
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models
Epoch: [50/50]	lr: 7.81e-06	time: 01:00:27	Loss_train 0.41420	Acc_train 92.32	/	Loss_test 0.15938	Acc_test 77.91
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models
RESULT:  {'train_loss': 0.41420429944992065, 'train_acc': 92.32079982757568, 'test_loss': 0.1593753844499588, 'test_acc': 77.91000366210938, 'convergence': 10.629302024841309, 'R1': 158, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 96}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 96}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't8': {'blocks': [4], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}
IN R1:  {'eval_1': {'test_loss': 21.993986129760742, 'test_acc': 33.32500076293945, 'convergence': 10.142229080200195, 'R1': 119, 'dataset_sup': {'name': 'STL10', 'noise_std': 0, 'channels': 3, 'width': 96, 'height': 96, 'validation_split': 0.2, 'training_sample': 5000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 4, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': True, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 100, 'print_freq': 10, 'validation': False, 'continual_learning': False}, 'dataset_unsup': {'name': 'STL10', 'noise_std': 0, 'channels': 3, 'width': 96, 'height': 96, 'validation_split': 0.2, 'training_sample': 100000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 32, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'unlabeled', 'nb_epoch': 1, 'print_freq': 25, 'validation': False, 'continual_learning': False}}, 'R1': {'train_loss': 0.41420429944992065, 'train_acc': 92.32079982757568, 'test_loss': 0.1593753844499588, 'test_acc': 77.91000366210938, 'convergence': 10.629302024841309, 'R1': 158, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 96}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 96}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't6': {'blocks': [3], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 10, 'print_freq': 10}, 't8': {'blocks': [4], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 64, 'print_freq': 10}}}}
SEED:  0
block 0, size : 96 48 48
range = 2.886751345948129
block 1, size : 384 24 24
range = 0.8505172717997146
block 2, size : 1536 12 12
range = 0.4252586358998573
block 3, size : 6144 6 6
range = 0.21262931794992865
range = 0.036828478186799345
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.00032, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.00032, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.45, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.00032, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.21262931794992865, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 6144, 'kernel_size': 3, 'in_channels': 1536, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.00032, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.036828478186799345, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10, 'in_channels': 221184, 'old_channels': 6144, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 Model STL10_CIFAR10_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- AvgPool2d(kernel_size=4, stride=2, padding=1)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.44999998807907104reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.44999998807907104, bias=False, lr_bias=0.2222, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- AvgPool2d(kernel_size=4, stride=2, padding=1)

 ----- Architecture Block BatchNorm2dSK153661442(3, 3)0.25reflect, number 3 -----
- BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(1536, 6144, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 4 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=221184, out_features=10, bias=True)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  5000
IMAGE SIZE: torch.Size([32, 3, 96, 96])
SAVING FOLDER FOR UNSUP:  STL10_CIFAR10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.34e-01	time: 00:00:29	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:4.523e-03/SW:5.611e-01/MR:4.361e+00/SR:2.153e+00/MeD:1.717e+00/MaD:6.130e+00/MW:0.617/MAW:0.383
|       0 |        1 |       2 |      3 |       4 |       5 |       6 |       7 |       8 |       9 |         10 |      11 |      12 |      13 |      14 |      15 |         16 |      17 |     18 |      19 |      20 |        21 |       22 |      23 |      24 |         25 |      26 |       27 |        28 |      29 |
|---------+----------+---------+--------+---------+---------+---------+---------+---------+---------+------------+---------+---------+---------+---------+---------+------------+---------+--------+---------+---------+-----------+----------+---------+---------+------------+---------+----------+-----------+---------|
|   0.127 |   0.0303 |   0.197 |   0.14 |   0.195 |   0.207 |   0.179 |   0.117 |   0.167 |   0.147 |   0.000713 |   0.145 |   0.214 |   0.105 |   0.114 |   0.123 |   0.000103 |   0.186 |   0.12 |   0.102 |   0.151 |   0.00247 |   0.0464 |   0.157 |   0.184 |   7.81e-05 |   0.231 |   0.0818 |   0.00162 |   0.197 |
|   3.53  |   1.14   |   7.09  |   4.05 |   6.93  |   7.67  |   5.99  |   3.14  |   5.38  |   4.37  |   1        |   4.27  |   8.16  |   2.72  |   3.03  |   3.36  |   1        |   6.42  |   3.26 |   2.61  |   4.55  |   1       |   1.34   |   4.83  |   6.27  |   1        |   9.34  |   2.05   |   1       |   7.05  |
|   0.4   |   0.29   |   0.3   |   0.64 |   0.34  |   0.32  |   0.3   |   0.55  |   0.29  |   0.6   |   3.33     |   0.27  |   0.3   |   0.57  |   0.52  |   0.56  |  23.95     |   0.38  |   0.46 |   0.27  |   0.47  |   0.87    |   0.26   |   0.6   |   0.36  |  27.95     |   0.28  |   0.52   |   0.99    |   0.49  |
| nan     | nan      | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan    | nan     | nan     | nan       | nan      | nan     | nan     | nan        | nan     | nan      | nan       | nan     |
| nan     | nan      | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan    | nan     | nan     | nan       | nan      | nan     | nan     | nan        | nan     | nan      | nan       | nan     |
| nan     | nan      | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan    | nan     | nan     | nan       | nan      | nan     | nan     | nan        | nan     | nan      | nan       | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  5000
IMAGE SIZE: torch.Size([32, 3, 96, 96])
SAVING FOLDER FOR UNSUP:  STL10_CIFAR10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.34e-01	time: 00:00:58	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.445e-02/SW:8.818e-02/MR:2.233e+00/SR:1.385e+00/MeD:1.213e+00/MaD:3.465e+00/MW:0.555/MAW:0.445
|          0 |          1 |         2 |          3 |         4 |         5 |         6 |          7 |         8 |         9 |        10 |        11 |        12 |        13 |        14 |       15 |        16 |         17 |        18 |        19 |        20 |        21 |        22 |        23 |         24 |         25 |        26 |         27 |        28 |        29 |
|------------+------------+-----------+------------+-----------+-----------+-----------+------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+----------+-----------+------------+-----------+-----------+-----------+-----------+-----------+-----------+------------+------------+-----------+------------+-----------+-----------|
|   0.000459 |   0.000106 |   0.00345 |   0.000384 |   0.00331 |   0.00409 |   0.00325 |   8.28e-05 |   0.00779 |   0.00026 |   0.00895 |   0.00736 |   0.00303 |   0.00251 |   0.00526 |   0.0066 |   0.00185 |   0.000883 |   4.9e-05 |   0.00978 |   0.00135 |   0.00253 |   0.00848 |   0.00599 |   0.000486 |   0.000519 |   0.00519 |   0.000415 |   0.00034 |   0.00148 |
|   1.01     |   1        |   1.48    |   1.01     |   1.44    |   1.67    |   1.42    |   1        |   3.43    |   1       |   4.2     |   3.17    |   1.37    |   1.25    |   2.11    |   2.74   |   1.14    |   1.03     |   1       |   4.83    |   1.07    |   1.26    |   3.88    |   2.44    |   1.01     |   1.01     |   2.08    |   1.01     |   1       |   1.09    |
|   0.41     |   0.18     |   0.06    |   0.09     |   0.04    |   0.03    |   0.04    |   2.22     |   0.07    |   0.95    |   0.29    |   0.04    |   0.03    |   0.04    |   0.03    |   0.03   |   0.04    |   0.1      |   0.13    |   0.36    |   0.02    |   0.07    |   0.08    |   0.03    |   0.08     |   0.06     |   0.04    |   0.31     |   0.16    |   0.08    |
| nan        | nan        | nan       | nan        | nan       | nan       | nan       | nan        | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan      | nan       | nan        | nan       | nan       | nan       | nan       | nan       | nan       | nan        | nan        | nan       | nan        | nan       | nan       |
| nan        | nan        | nan       | nan        | nan       | nan       | nan       | nan        | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan      | nan       | nan        | nan       | nan       | nan       | nan       | nan       | nan       | nan        | nan        | nan       | nan        | nan       | nan       |
| nan        | nan        | nan       | nan        | nan       | nan       | nan       | nan        | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan      | nan       | nan        | nan       | nan       | nan       | nan       | nan       | nan       | nan        | nan        | nan       | nan        | nan       | nan       |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  5000
IMAGE SIZE: torch.Size([32, 3, 96, 96])
SAVING FOLDER FOR UNSUP:  STL10_CIFAR10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.90e-02	time: 00:01:28	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:2.713e-03/SW:1.074e-01/MR:5.290e+00/SR:3.448e+00/MeD:3.090e+00/MaD:8.539e+00/MW:0.649/MAW:0.351
|          0 |        1 |        2 |        3 |        4 |       5 |       6 |        7 |        8 |        9 |       10 |        11 |       12 |      13 |       14 |       15 |       16 |       17 |         18 |       19 |       20 |       21 |         22 |       23 |       24 |       25 |       26 |      27 |       28 |        29 |
|------------+----------+----------+----------+----------+---------+---------+----------+----------+----------+----------+-----------+----------+---------+----------+----------+----------+----------+------------+----------+----------+----------+------------+----------+----------+----------+----------+---------+----------+-----------|
|   0.000495 |   0.0265 |   0.0263 |   0.0209 |   0.0115 |   0.028 |   0.031 |   0.0282 |   0.0147 |   0.0251 |   0.0338 |   0.00788 |   0.0172 |   0.025 |   0.0179 |   0.0326 |   0.0191 |   0.0251 |   0.000422 |   0.0339 |   0.0122 |   0.0246 |   0.000342 |   0.0269 |   0.0216 |   0.0279 |   0.0211 |   0.019 |   0.0277 |   0.00285 |
|   1        |   8.03   |   7.93   |   5.37   |   2.32   |   8.85  |  10.6   |   8.93   |   3.17   |   7.28   |  12.4    |   1.62    |   3.96   |   7.25  |   4.22   |  11.61   |   4.67   |   7.3    |   1        |  12.47   |   2.49   |   7.03   |   1        |   8.23   |   5.66   |   8.77   |   5.45   |   4.59  |   8.67   |   1.08    |
|   0.02     |   0.02   |   0.03   |   0      |   0      |   0.04  |   0.04  |   0.04   |   0.01   |   0.03   |   0.03   |   0       |   0      |   0.03  |   0      |   0.02   |   0      |   0.02   |   0.03     |   0.09   |   0      |   0.01   |   0.03     |   0.02   |   0.02   |   0.02   |   0      |   0     |   0.01   |   0       |
| nan        | nan      | nan      | nan      | nan      | nan     | nan     | nan      | nan      | nan      | nan      | nan       | nan      | nan     | nan      | nan      | nan      | nan      | nan        | nan      | nan      | nan      | nan        | nan      | nan      | nan      | nan      | nan     | nan      | nan       |
| nan        | nan      | nan      | nan      | nan      | nan     | nan     | nan      | nan      | nan      | nan      | nan       | nan      | nan     | nan      | nan      | nan      | nan      | nan        | nan      | nan      | nan      | nan        | nan      | nan      | nan      | nan      | nan     | nan      | nan       |
| nan        | nan      | nan      | nan      | nan      | nan     | nan     | nan      | nan      | nan      | nan      | nan       | nan      | nan     | nan      | nan      | nan      | nan      | nan        | nan      | nan      | nan      | nan        | nan      | nan      | nan      | nan      | nan     | nan      | nan       |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models

 ********** Hebbian Unsupervised learning of blocks [3] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  5000
IMAGE SIZE: torch.Size([32, 3, 96, 96])
SAVING FOLDER FOR UNSUP:  STL10_CIFAR10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.73e-02	time: 00:02:07	Acc_train 0.00	Acc_test 0.00	convergence: 1.05e+01	R1: 160	Info MB:0.000e+00/SB:0.000e+00/MW:6.615e-03/SW:1.058e-01/MR:1.148e+01/SR:4.856e+00/MeD:3.898e+00/MaD:1.109e+01/MW:0.566/MAW:0.434
|        0 |      1 |        2 |        3 |        4 |        5 |        6 |         7 |        8 |        9 |       10 |       11 |         12 |       13 |       14 |       15 |       16 |       17 |       18 |       19 |       20 |       21 |       22 |       23 |       24 |        25 |      26 |      27 |       28 |       29 |
|----------+--------+----------+----------+----------+----------+----------+-----------+----------+----------+----------+----------+------------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+-----------+---------+---------+----------+----------|
|   0.0373 |   0.04 |   0.0341 |   0.0347 |   0.0363 |   0.0331 |   0.0317 |   0.00973 |   0.0407 |   0.0352 |   0.0379 |   0.0391 |   0.000687 |   0.0245 |   0.0193 |   0.0396 |   0.0348 |   0.0328 |   0.0315 |   0.0142 |   0.0307 |   0.0379 |   0.0262 |   0.0379 |   0.0363 |   0.00231 |   0.016 |   0.042 |   0.0322 |   0.0015 |
|  14.94   |  16.97 |  12.61   |  13.07   |  14.14   |  11.96   |  11.03   |   1.95    |  17.53   |  13.37   |  15.36   |  16.31   |   1        |   7      |   4.72   |  16.7    |  13.13   |  11.74   |  10.94   |   3.02   |  10.41   |  15.38   |   7.85   |  15.34   |  14.14   |   1.05    |   3.57  |  18.64  |  11.36   |   1.02   |
|   0.02   |   0    |   0      |   0      |   0.01   |   0      |   0      |   0       |   0      |   0      |   0.01   |   0.01   |   0.05     |   0      |   0      |   0.01   |   0      |   0      |   0      |   0      |   0      |   0.01   |   0      |   0      |   0      |   0.01    |   0     |   0.02  |   0      |   0.02   |
| nan      | nan    | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan        | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan     | nan     | nan      | nan      |
| nan      | nan    | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan        | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan     | nan     | nan      | nan      |
| nan      | nan    | nan      | nan      | nan      | nan      | nan      | nan       | nan      | nan      | nan      | nan      | nan        | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan       | nan     | nan     | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/STL10_CIFAR10_CL/models
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  5000
IMAGE SIZE: torch.Size([64, 3, 96, 96])
Accuracy of the network on the 1st dataset: 28.763 %
Test loss on the 1st dataset: 27.158

