BLOCKS:  {'b0': {'arch': 'CNN', 'preset': 'softkrotov-c96-k5-p2-s1-d1-b0-t1-lr0.08-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 0, 'batch_norm': False, 'pool': {'type': 'max', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 0.7}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5}}, 'b1': {'arch': 'CNN', 'preset': 'softkrotov-c384-k3-p1-s1-d1-b0-t0.65-lr0.005-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 1, 'batch_norm': False, 'pool': {'type': 'max', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 1.4}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3}}, 'b2': {'arch': 'CNN', 'preset': 'softkrotov-c1536-k3-p1-s1-d1-b0-t0.25-lr0.01-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 2, 'batch_norm': False, 'pool': {'type': 'avg', 'kernel_size': 2, 'stride': 2, 'padding': 0}, 'activation': {'function': 'triangle', 'param': 1.0}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3}}, 'b3': {'arch': 'MLP', 'preset': 'BP-c10', 'operation': 'flatten', 'num': 3, 'att_dropout': None, 'dropout': 0.5, 'layer': {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.25, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10}, 'pool': None, 'activation': None}}
CL:  True
{'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True}
CL:  False
{'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': False}
CL:  False
{'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': False}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.11048543456039805, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10, 'in_channels': 24576, 'old_channels': 1536, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 Model CIFAR10_STL10_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=10, bias=True)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  50000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  CIFAR10_STL10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.53e-01	time: 00:00:20	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.493e-02/SW:6.274e-01/MR:5.106e+00/SR:1.871e+00/MeD:1.413e+00/MaD:4.106e+00/MW:0.608/MAW:0.392
|       0 |       1 |          2 |       3 |       4 |        5 |       6 |       7 |         8 |       9 |         10 |     11 |      12 |      13 |      14 |      15 |      16 |     17 |      18 |      19 |      20 |      21 |      22 |      23 |         24 |      25 |      26 |     27 |      28 |      29 |
|---------+---------+------------+---------+---------+----------+---------+---------+-----------+---------+------------+--------+---------+---------+---------+---------+---------+--------+---------+---------+---------+---------+---------+---------+------------+---------+---------+--------+---------+---------|
|   0.216 |   0.179 |   4.78e-05 |   0.186 |   0.202 |   0.0884 |   0.138 |   0.191 |   0.00131 |   0.206 |   0.000185 |   0.17 |   0.164 |   0.156 |   0.155 |   0.163 |   0.189 |   0.2  |   0.184 |   0.162 |   0.151 |   0.204 |   0.145 |   0.174 |   0.000219 |   0.152 |   0.119 |   0.12 |   0.177 |   0.189 |
|   8.26  |   6.01  |   1        |   6.43  |   7.37  |   2.22   |   3.99  |   6.72  |   1       |   7.64  |   1        |   5.5  |   5.18  |   4.81  |   4.74  |   5.15  |   6.57  |   7.23 |   6.28  |   5.1   |   4.56  |   7.51  |   4.29  |   5.74  |   1        |   4.63  |   3.23  |   3.23 |   5.88  |   6.6   |
|   0.39  |   0.52  |  21.02     |   0.48  |   0.49  |   0.53   |   0.45  |   0.34  |   1.65    |   0.35  |   2.54     |   0.32 |   0.34  |   0.31  |   0.31  |   0.5   |   0.52  |   0.5  |   0.5   |   0.49  |   0.35  |   0.52  |   0.49  |   0.48  |   1.86     |   0.49  |   0.28  |   0.45 |   0.51  |   0.49  |
| nan     | nan     | nan        | nan     | nan     | nan      | nan     | nan     | nan       | nan     | nan        | nan    | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan    | nan     | nan     |
| nan     | nan     | nan        | nan     | nan     | nan      | nan     | nan     | nan       | nan     | nan        | nan    | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan    | nan     | nan     |
| nan     | nan     | nan        | nan     | nan     | nan      | nan     | nan     | nan       | nan     | nan        | nan    | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan        | nan     | nan     | nan    | nan     | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/CIFAR10_STL10_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  50000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  CIFAR10_STL10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.53e-01	time: 00:00:37	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:5.125e-03/SW:1.291e-01/MR:3.571e+00/SR:1.295e+00/MeD:1.015e+00/MaD:4.426e+00/MW:0.614/MAW:0.386
|         0 |         1 |        2 |         3 |         4 |         5 |         6 |          7 |        8 |         9 |        10 |        11 |       12 |        13 |        14 |        15 |       16 |        17 |        18 |        19 |        20 |        21 |        22 |        23 |        24 |        25 |        26 |        27 |        28 |       29 |
|-----------+-----------+----------+-----------+-----------+-----------+-----------+------------+----------+-----------+-----------+-----------+----------+-----------+-----------+-----------+----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+----------|
|   0.00842 |   0.00544 |   0.0094 |   0.00857 |   0.00919 |   0.00756 |   0.00823 |   0.000265 |   0.0043 |   0.00846 |   0.00766 |   0.00942 |   0.0104 |   0.00993 |   0.00873 |   0.00331 |   0.0055 |   0.00853 |   0.00863 |   0.00831 |   0.00949 |   0.00843 |   0.00103 |   0.00804 |   0.00803 |   0.00939 |   0.00812 |   0.00873 |   0.00998 |   0.0115 |
|   3.84    |   2.18    |   4.53   |   3.94    |   4.38    |   3.28    |   3.71    |   1        |   1.74   |   3.86    |   3.35    |   4.55    |   5.32   |   4.94    |   4.05    |   1.44    |   2.21   |   3.91    |   3.98    |   3.76    |   4.6     |   3.84    |   1.04    |   3.58    |   3.58    |   4.53    |   3.64    |   4.05    |   4.99    |   6.26   |
|   0.16    |   0.06    |   0.11   |   0.11    |   0.16    |   0.11    |   0.17    |   0.72     |   0.06   |   0.1     |   0.12    |   0.15    |   0.16   |   0.15    |   0.1     |   0.07    |   0.04   |   0.12    |   0.12    |   0.12    |   0.16    |   0.17    |   0.19    |   0.11    |   0.11    |   0.16    |   0.13    |   0.19    |   0.13    |   0.18   |
| nan       | nan       | nan      | nan       | nan       | nan       | nan       | nan        | nan      | nan       | nan       | nan       | nan      | nan       | nan       | nan       | nan      | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan      |
| nan       | nan       | nan      | nan       | nan       | nan       | nan       | nan        | nan      | nan       | nan       | nan       | nan      | nan       | nan       | nan       | nan      | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan      |
| nan       | nan       | nan      | nan       | nan       | nan       | nan       | nan        | nan      | nan       | nan       | nan       | nan      | nan       | nan       | nan       | nan      | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/CIFAR10_STL10_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  50000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  CIFAR10_STL10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 3.80e-02	time: 00:01:00	Acc_train 0.00	Acc_test 0.00	convergence: 1.45e+01	R1: 1	Info MB:0.000e+00/SB:0.000e+00/MW:1.729e-02/SW:2.655e-01/MR:1.553e+01/SR:1.885e+00/MeD:1.496e+00/MaD:1.453e+01/MW:0.455/MAW:0.545
|        0 |        1 |        2 |        3 |        4 |        5 |        6 |        7 |        8 |      9 |       10 |       11 |       12 |       13 |       14 |       15 |       16 |       17 |      18 |       19 |       20 |       21 |       22 |       23 |       24 |      25 |       26 |       27 |       28 |       29 |
|----------+----------+----------+----------+----------+----------+----------+----------+----------+--------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------|
|   0.0419 |   0.0381 |   0.0395 |   0.0424 |   0.0417 |   0.0392 |   0.0314 |   0.0378 |   0.0324 |   0.04 |   0.0335 |   0.0338 |   0.0364 |   0.0353 |   0.0379 |   0.0347 |   0.0394 |   0.0411 |   0.039 |   0.0351 |   0.0401 |   0.0409 |   0.0346 |   0.0374 |   0.0405 |   0.036 |   0.0399 |   0.0397 |   0.0406 |   0.0387 |
|  18.54   |  15.5    |  16.59   |  19      |  18.39   |  16.34   |  10.85   |  15.33   |  11.48   |  17.03 |  12.24   |  12.42   |  14.25   |  13.49   |  15.35   |  13.07   |  16.54   |  17.86   |  16.17  |  13.29   |  17.08   |  17.73   |  12.97   |  15.02   |  17.42   |  13.95  |  16.95   |  16.73   |  17.49   |  15.96   |
|   0.08   |   0.06   |   0.08   |   0.06   |   0.06   |   0.07   |   0.03   |   0.05   |   0.05   |   0.06 |   0.04   |   0.03   |   0.05   |   0.05   |   0.04   |   0.04   |   0.08   |   0.06   |   0.07  |   0.03   |   0.1    |   0.06   |   0.08   |   0.09   |   0.07   |   0.06  |   0.06   |   0.06   |   0.06   |   0.04   |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan    | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan    | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan    | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/CIFAR10_STL10_CL/models
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  50000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Accuracy of the network on the 1st dataset: 68.680 %
Test loss on the 1st dataset: 0.023
CL:  True
{'name': 'STL10', 'noise_std': 0, 'channels': 3, 'width': 96, 'height': 96, 'validation_split': 0.2, 'training_sample': 5000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 32, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True}
CL:  True
{'name': 'STL10', 'noise_std': 0, 'channels': 3, 'width': 96, 'height': 96, 'validation_split': 0.2, 'training_sample': 5000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 32, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 1, 'validation': False, 'continual_learning': True}
SEED:  0
block 0, size : 96 48 48
range = 2.886751345948129
block 1, size : 384 24 24
range = 0.8505172717997146
block 2, size : 1536 12 12
range = 0.4252586358998573
range = 0.036828478186799345
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.11048543456039805, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10, 'in_channels': 24576, 'old_channels': 1536, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 Model CIFAR10_STL10_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=10, bias=True)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  5000
IMAGE SIZE: torch.Size([32, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  CIFAR10_STL10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.01e-01	time: 00:00:21	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:8.864e-03/SW:3.620e-01/MR:2.902e+00/SR:1.194e+00/MeD:8.970e-01/MaD:3.175e+00/MW:0.574/MAW:0.426
|       0 |       1 |          2 |       3 |       4 |         5 |        6 |       7 |         8 |       9 |         10 |      11 |     12 |      13 |      14 |       15 |      16 |      17 |      18 |      19 |      20 |      21 |       22 |      23 |         24 |       25 |       26 |       27 |      28 |      29 |
|---------+---------+------------+---------+---------+-----------+----------+---------+-----------+---------+------------+---------+--------+---------+---------+----------+---------+---------+---------+---------+---------+---------+----------+---------+------------+----------+----------+----------+---------+---------|
|   0.168 |   0.105 |   0.000189 |   0.108 |   0.115 |   0.00943 |   0.0799 |   0.159 |   0.00151 |   0.132 |   0.000395 |   0.115 |   0.14 |   0.144 |   0.144 |   0.0972 |   0.115 |   0.118 |   0.115 |   0.135 |   0.143 |   0.112 |   0.0866 |   0.103 |   0.000378 |   0.0995 |   0.0931 |   0.0555 |   0.113 |   0.112 |
|   5.39  |   2.72  |   1        |   2.81  |   3.07  |   1.01    |   2      |   4.93  |   1       |   3.7   |   1        |   3.05  |   4.07 |   4.26  |   4.22  |   2.48   |   3.07  |   3.19  |   3.05  |   3.84  |   4.21  |   2.95  |   2.17   |   2.67  |   1        |   2.55   |   2.35   |   1.48   |   2.99  |   2.98  |
|   0.39  |   0.63  |  18.82     |   0.6   |   0.62  |   0.79    |   0.45   |   0.34  |   1.33    |   0.33  |   2.8      |   0.3   |   0.35 |   0.31  |   0.32  |   0.6    |   0.67  |   0.64  |   0.63  |   0.43  |   0.35  |   0.64  |   0.52   |   0.59  |   2.01     |   0.61   |   0.42   |   0.56   |   0.58  |   0.67  |
| nan     | nan     | nan        | nan     | nan     | nan       | nan      | nan     | nan       | nan     | nan        | nan     | nan    | nan     | nan     | nan      | nan     | nan     | nan     | nan     | nan     | nan     | nan      | nan     | nan        | nan      | nan      | nan      | nan     | nan     |
| nan     | nan     | nan        | nan     | nan     | nan       | nan      | nan     | nan       | nan     | nan        | nan     | nan    | nan     | nan     | nan      | nan     | nan     | nan     | nan     | nan     | nan     | nan      | nan     | nan        | nan      | nan      | nan      | nan     | nan     |
| nan     | nan     | nan        | nan     | nan     | nan       | nan      | nan     | nan       | nan     | nan        | nan     | nan    | nan     | nan     | nan      | nan     | nan     | nan     | nan     | nan     | nan     | nan      | nan     | nan        | nan      | nan      | nan      | nan     | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/CIFAR10_STL10_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  5000
IMAGE SIZE: torch.Size([32, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  CIFAR10_STL10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.01e-01	time: 00:00:42	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:4.889e-03/SW:1.300e-01/MR:3.592e+00/SR:1.315e+00/MeD:1.035e+00/MaD:3.789e+00/MW:0.618/MAW:0.382
|        0 |         1 |         2 |         3 |         4 |        5 |         6 |          7 |         8 |         9 |        10 |        11 |       12 |       13 |        14 |       15 |        16 |        17 |        18 |        19 |        20 |        21 |        22 |        23 |        24 |        25 |        26 |        27 |       28 |       29 |
|----------+-----------+-----------+-----------+-----------+----------+-----------+------------+-----------+-----------+-----------+-----------+----------+----------+-----------+----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+----------+----------|
|   0.0087 |   0.00544 |   0.00942 |   0.00848 |   0.00935 |   0.0077 |   0.00839 |   0.000249 |   0.00432 |   0.00856 |   0.00776 |   0.00955 |   0.0105 |   0.0101 |   0.00892 |   0.0033 |   0.00549 |   0.00848 |   0.00882 |   0.00847 |   0.00974 |   0.00791 |   0.00094 |   0.00827 |   0.00796 |   0.00932 |   0.00813 |   0.00905 |   0.0101 |   0.0114 |
|   4.03   |   2.18    |   4.55    |   3.88    |   4.5     |   3.37   |   3.82    |   1        |   1.75    |   3.93    |   3.41    |   4.65    |   5.44   |   5.08   |   4.18    |   1.44   |   2.21    |   3.87    |   4.11    |   3.87    |   4.8     |   3.5     |   1.04    |   3.74    |   3.54    |   4.47    |   3.65    |   4.27    |   5.05   |   6.19   |
|   0.07   |   0.04    |   0.12    |   0.1     |   0.11    |   0.06   |   0.09    |   1.09     |   0.02    |   0.1     |   0.08    |   0.18    |   0.13   |   0.09   |   0.09    |   0.07   |   0.07    |   0.1     |   0.07    |   0.08    |   0.11    |   0.14    |   0.33    |   0.08    |   0.1     |   0.18    |   0.1     |   0.13    |   0.1    |   0.17   |
| nan      | nan       | nan       | nan       | nan       | nan      | nan       | nan        | nan       | nan       | nan       | nan       | nan      | nan      | nan       | nan      | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan      | nan      |
| nan      | nan       | nan       | nan       | nan       | nan      | nan       | nan        | nan       | nan       | nan       | nan       | nan      | nan      | nan       | nan      | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan      | nan      |
| nan      | nan       | nan       | nan       | nan       | nan      | nan       | nan        | nan       | nan       | nan       | nan       | nan      | nan      | nan       | nan      | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/CIFAR10_STL10_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  5000
IMAGE SIZE: torch.Size([32, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  CIFAR10_STL10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 3.80e-02	time: 00:01:04	Acc_train 0.00	Acc_test 0.00	convergence: 1.45e+01	R1: 1	Info MB:0.000e+00/SB:0.000e+00/MW:1.773e-02/SW:2.653e-01/MR:1.552e+01/SR:1.905e+00/MeD:1.492e+00/MaD:1.452e+01/MW:0.455/MAW:0.545
|        0 |        1 |        2 |        3 |       4 |        5 |        6 |        7 |       8 |        9 |       10 |       11 |       12 |       13 |       14 |       15 |       16 |       17 |       18 |       19 |       20 |       21 |       22 |       23 |       24 |       25 |       26 |      27 |       28 |       29 |
|----------+----------+----------+----------+---------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------|
|   0.0427 |   0.0383 |   0.0394 |   0.0414 |   0.041 |   0.0403 |   0.0311 |   0.0355 |   0.032 |   0.0415 |   0.0339 |   0.0342 |   0.0365 |   0.0366 |   0.0368 |   0.0352 |   0.0392 |   0.0422 |   0.0377 |   0.0356 |   0.0385 |   0.0424 |   0.0347 |   0.0386 |   0.0419 |   0.0367 |   0.0404 |   0.039 |   0.0392 |   0.0383 |
|  19.2    |  15.66   |  16.52   |  18.16   |  17.82  |  17.21   |  10.65   |  13.6    |  11.22  |  18.18   |  12.51   |  12.72   |  14.32   |  14.36   |  14.55   |  13.42   |  16.33   |  18.77   |  15.19   |  13.67   |  15.81   |  18.94   |  13.07   |  15.87   |  18.55   |  14.44   |  17.29   |  16.25  |  16.38   |  15.67   |
|   0.09   |   0.07   |   0.08   |   0.07   |   0.08  |   0.04   |   0.02   |   0.04   |   0.04  |   0.05   |   0.02   |   0.03   |   0.05   |   0.05   |   0.05   |   0.03   |   0.08   |   0.08   |   0.08   |   0.02   |   0.1    |   0.05   |   0.04   |   0.06   |   0.06   |   0.02   |   0.06   |   0.06  |   0.06   |   0.04   |
| nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      |
| nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      |
| nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/CIFAR10_STL10_CL/models

 ********** Supervised learning of blocks [3] **********
SAVING FOLDER FOR SUP:  CIFAR10_STL10_CL
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  5000
IMAGE SIZE: torch.Size([32, 3, 32, 32])
Epoch: [1/50]	lr: 1.00e-03	time: 00:01:25	Loss_train 2.58302	Acc_train 42.14	/	Loss_test 1.53965	Acc_test 53.78
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/CIFAR10_STL10_CL/models
Epoch: [10/50]	lr: 1.00e-03	time: 00:01:30	Loss_train 0.81689	Acc_train 70.83	/	Loss_test 1.27142	Acc_test 63.90
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/CIFAR10_STL10_CL/models
Epoch: [20/50]	lr: 2.50e-04	time: 00:01:35	Loss_train 0.22493	Acc_train 87.07	/	Loss_test 1.18580	Acc_test 65.91
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/CIFAR10_STL10_CL/models
Epoch: [30/50]	lr: 1.25e-04	time: 00:01:40	Loss_train 0.12798	Acc_train 91.35	/	Loss_test 1.19517	Acc_test 66.57
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/CIFAR10_STL10_CL/models
Epoch: [40/50]	lr: 3.13e-05	time: 00:01:45	Loss_train 0.09607	Acc_train 92.83	/	Loss_test 1.16056	Acc_test 66.49
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/CIFAR10_STL10_CL/models
Epoch: [50/50]	lr: 7.81e-06	time: 00:01:50	Loss_train 0.08219	Acc_train 93.54	/	Loss_test 1.15870	Acc_test 66.62
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/CIFAR10_STL10_CL/models
RESULT:  {'train_loss': 0.08219373971223831, 'train_acc': 93.54199767112732, 'test_loss': 1.1587011814117432, 'test_acc': 66.625, 'convergence': 14.516597747802734, 'R1': 1, 'dataset_sup': {'name': 'STL10', 'noise_std': 0, 'channels': 3, 'width': 96, 'height': 96, 'validation_split': 0.2, 'training_sample': 5000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 32, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32}, 'dataset_unsup': {'name': 'STL10', 'noise_std': 0, 'channels': 3, 'width': 96, 'height': 96, 'validation_split': 0.2, 'training_sample': 5000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 32, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 1, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 32, 'print_freq': 1}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 32, 'print_freq': 1}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 32, 'print_freq': 1}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 32, 'print_freq': 10}}}
IN R1:  {'eval_1': {'test_loss': 0.022565355524420738, 'test_acc': 68.68000030517578, 'convergence': 14.527555465698242, 'R1': 1, 'dataset_sup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 64, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': False}, 'dataset_unsup': {'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': False}}, 'R1': {'train_loss': 0.08219373971223831, 'train_acc': 93.54199767112732, 'test_loss': 1.1587011814117432, 'test_acc': 66.625, 'convergence': 14.516597747802734, 'R1': 1, 'dataset_sup': {'name': 'STL10', 'noise_std': 0, 'channels': 3, 'width': 96, 'height': 96, 'validation_split': 0.2, 'training_sample': 5000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 32, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 50, 'print_freq': 10, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32}, 'dataset_unsup': {'name': 'STL10', 'noise_std': 0, 'channels': 3, 'width': 96, 'height': 96, 'validation_split': 0.2, 'training_sample': 5000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 32, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 1, 'validation': False, 'continual_learning': True, 'old_dataset_size': 32}, 'train_config': {'t0': {'blocks': [0], 'mode': 'unsupervised', 'lr': 0.08, 'nb_epoch': 1, 'batch_size': 32, 'print_freq': 1}, 't2': {'blocks': [1], 'mode': 'unsupervised', 'lr': 0.005, 'nb_epoch': 1, 'batch_size': 32, 'print_freq': 1}, 't4': {'blocks': [2], 'mode': 'unsupervised', 'lr': 0.01, 'nb_epoch': 1, 'batch_size': 32, 'print_freq': 1}, 't6': {'blocks': [3], 'mode': 'supervised', 'lr': 0.001, 'nb_epoch': 50, 'batch_size': 32, 'print_freq': 10}}}}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CONFIG: {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.11048543456039805, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10, 'in_channels': 24576, 'old_channels': 1536, 'lr_scheduler': {'decay': 'cste', 'lr': 0.1}}

 Model CIFAR10_STL10_CL loaded successfuly with best perf



 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=10, bias=True)

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  50000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  CIFAR10_STL10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.54e-01	time: 00:00:16	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.450e-02/SW:6.581e-01/MR:5.264e+00/SR:2.199e+00/MeD:1.712e+00/MaD:5.223e+00/MW:0.611/MAW:0.389
|       0 |       1 |          2 |       3 |       4 |        5 |       6 |       7 |         8 |       9 |         10 |      11 |      12 |      13 |      14 |      15 |      16 |      17 |      18 |      19 |      20 |      21 |     22 |      23 |         24 |      25 |      26 |      27 |      28 |      29 |
|---------+---------+------------+---------+---------+----------+---------+---------+-----------+---------+------------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+--------+---------+------------+---------+---------+---------+---------+---------|
|   0.213 |   0.173 |   4.78e-05 |   0.189 |   0.205 |   0.0266 |   0.133 |   0.202 |   0.00129 |   0.204 |   0.000185 |   0.176 |   0.172 |   0.151 |   0.148 |   0.154 |   0.194 |   0.204 |   0.178 |   0.188 |   0.176 |   0.203 |   0.24 |   0.185 |   0.000205 |   0.152 |   0.122 |   0.102 |   0.164 |   0.189 |
|   8.08  |   5.69  |   1        |   6.6   |   7.54  |   1.11   |   3.77  |   7.38  |   1       |   7.51  |   1        |   5.83  |   5.62  |   4.58  |   4.44  |   4.73  |   6.9   |   7.51  |   5.95  |   6.54  |   5.83  |   7.41  |   9.97 |   6.36  |   1        |   4.61  |   3.33  |   2.63  |   5.21  |   6.61  |
|   0.36  |   0.52  |  21.43     |   0.5   |   0.51  |   0.28   |   0.44  |   0.32  |   1.72    |   0.31  |   2.67     |   0.31  |   0.35  |   0.31  |   0.31  |   0.49  |   0.52  |   0.52  |   0.52  |   0.37  |   0.36  |   0.51  |   0.48 |   0.49  |   2.05     |   0.51  |   0.37  |   0.43  |   0.42  |   0.51  |
| nan     | nan     | nan        | nan     | nan     | nan      | nan     | nan     | nan       | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan        | nan     | nan     | nan     | nan     | nan     |
| nan     | nan     | nan        | nan     | nan     | nan      | nan     | nan     | nan       | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan        | nan     | nan     | nan     | nan     | nan     |
| nan     | nan     | nan        | nan     | nan     | nan      | nan     | nan     | nan       | nan     | nan        | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan        | nan     | nan     | nan     | nan     | nan     |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/CIFAR10_STL10_CL/models

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  50000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  CIFAR10_STL10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 1.54e-01	time: 00:00:33	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:4.774e-03/SW:1.221e-01/MR:3.369e+00/SR:1.245e+00/MeD:9.815e-01/MaD:4.699e+00/MW:0.638/MAW:0.362
|         0 |         1 |         2 |         3 |         4 |        5 |         6 |          7 |         8 |         9 |        10 |       11 |       12 |        13 |        14 |        15 |        16 |        17 |        18 |        19 |        20 |        21 |         22 |        23 |        24 |        25 |        26 |       27 |        28 |        29 |
|-----------+-----------+-----------+-----------+-----------+----------+-----------+------------+-----------+-----------+-----------+----------+----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+------------+-----------+-----------+-----------+-----------+----------+-----------+-----------|
|   0.00833 |   0.00554 |   0.00915 |   0.00751 |   0.00883 |   0.0092 |   0.00845 |   0.000147 |   0.00457 |   0.00837 |   0.00755 |   0.0101 |   0.0102 |   0.00802 |   0.00834 |   0.00227 |   0.00653 |   0.00844 |   0.00868 |   0.00933 |   0.00852 |   0.00801 |   0.000265 |   0.00813 |   0.00824 |   0.00907 |   0.00807 |   0.0114 |   0.00927 |   0.00957 |
|   3.78    |   2.23    |   4.35    |   3.26    |   4.12    |   4.38   |   3.86    |   1        |   1.83    |   3.8     |   3.28    |   5.07   |   5.2    |   3.57    |   3.78    |   1.21    |   2.71    |   3.85    |   4.02    |   4.48    |   3.9     |   3.57    |   1        |   3.64    |   3.71    |   4.29    |   3.6     |   6.16   |   4.43    |   4.67    |
|   0.13    |   0.03    |   0.1     |   0.1     |   0.15    |   0.08   |   0.09    |   0.83     |   0.02    |   0.1     |   0.09    |   0.13   |   0.16   |   0.08    |   0.1     |   0.08    |   0.02    |   0.11    |   0.09    |   0.09    |   0.12    |   0.1     |   0.46     |   0.1     |   0.07    |   0.13    |   0.11    |   0.18   |   0.1     |   0.16    |
| nan       | nan       | nan       | nan       | nan       | nan      | nan       | nan        | nan       | nan       | nan       | nan      | nan      | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan        | nan       | nan       | nan       | nan       | nan      | nan       | nan       |
| nan       | nan       | nan       | nan       | nan       | nan      | nan       | nan        | nan       | nan       | nan       | nan      | nan      | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan        | nan       | nan       | nan       | nan       | nan      | nan       | nan       |
| nan       | nan       | nan       | nan       | nan       | nan      | nan       | nan        | nan       | nan       | nan       | nan      | nan      | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan       | nan        | nan       | nan       | nan       | nan       | nan      | nan       | nan       |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/CIFAR10_STL10_CL/models

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  50000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  CIFAR10_STL10_CL
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 3.69e-02	time: 00:00:57	Acc_train 0.00	Acc_test 0.00	convergence: 1.37e+01	R1: 1	Info MB:0.000e+00/SB:0.000e+00/MW:2.198e-02/SW:2.501e-01/MR:1.466e+01/SR:1.747e+00/MeD:1.389e+00/MaD:1.366e+01/MW:0.472/MAW:0.528
|        0 |        1 |        2 |        3 |        4 |       5 |        6 |        7 |        8 |        9 |       10 |      11 |       12 |       13 |       14 |       15 |      16 |       17 |       18 |       19 |       20 |       21 |       22 |       23 |       24 |       25 |       26 |       27 |       28 |       29 |
|----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------|
|   0.0379 |   0.0372 |   0.0367 |   0.0406 |   0.0397 |   0.039 |   0.0321 |   0.0378 |   0.0326 |   0.0397 |   0.0325 |   0.035 |   0.0381 |   0.0344 |   0.0359 |   0.0344 |   0.039 |   0.0391 |   0.0354 |   0.0356 |   0.0355 |   0.0395 |   0.0344 |   0.0372 |   0.0399 |   0.0312 |   0.0385 |   0.0375 |   0.0388 |   0.0358 |
|  15.38   |  14.83   |  14.5    |  17.44   |  16.75   |  16.21  |  11.31   |  15.27   |  11.61   |  16.75   |  11.59   |  13.26  |  15.48   |  12.85   |  13.89   |  12.83   |  16.17  |  16.29   |  13.5    |  13.68   |  13.62   |  16.6    |  12.86   |  14.82   |  16.94   |  10.73   |  15.79   |  15.08   |  16.07   |  13.8    |
|   0.07   |   0.05   |   0.07   |   0.06   |   0.06   |   0.05  |   0.02   |   0.04   |   0.02   |   0.05   |   0.03   |   0.04  |   0.05   |   0.05   |   0.03   |   0.04   |   0.07  |   0.07   |   0.05   |   0.03   |   0.06   |   0.07   |   0.05   |   0.07   |   0.07   |   0.03   |   0.05   |   0.05   |   0.06   |   0.05   |
| nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/g100_work/EIRI_E_POLIMI/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/CIFAR10_STL10_CL/models
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  50000
IMAGE SIZE: torch.Size([64, 3, 32, 32])
Accuracy of the network on the 1st dataset: 32.630 %
Test loss on the 1st dataset: 0.136

