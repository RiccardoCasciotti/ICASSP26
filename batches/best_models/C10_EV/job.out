--------------- /leonardo/prod/opt/modulefiles/deeplrn/libraries ---------------
cineca-ai/3.0.0  cineca-ai/4.0.0  cineca-ai/4.1.1(default)  
cineca-ai/3.0.1  cineca-ai/4.1.0  cineca-ai/4.3.0           

Key:
(symbolic-version)  
BLOCKS:  {'b0': {'arch': 'CNN', 'preset': 'softkrotov-c96-k5-p2-s1-d1-b0-t1-lr0.08-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 0, 'batch_norm': False, 'pool': {'type': 'max', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 0.7}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5}}, 'b1': {'arch': 'CNN', 'preset': 'softkrotov-c384-k3-p1-s1-d1-b0-t0.65-lr0.005-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 1, 'batch_norm': False, 'pool': {'type': 'max', 'kernel_size': 4, 'stride': 2, 'padding': 1}, 'activation': {'function': 'triangle', 'param': 1.4}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3}}, 'b2': {'arch': 'CNN', 'preset': 'softkrotov-c1536-k3-p1-s1-d1-b0-t0.25-lr0.01-lp0.5-e0', 'operation': 'batchnorm2d', 'num': 2, 'batch_norm': False, 'pool': {'type': 'avg', 'kernel_size': 2, 'stride': 2, 'padding': 0}, 'activation': {'function': 'triangle', 'param': 1.0}, 'resume': None, 'layer': {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'positive', 'weight_init_range': 2, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3}}, 'b3': {'arch': 'MLP', 'preset': 'BP-c10', 'operation': 'flatten', 'num': 3, 'att_dropout': None, 'dropout': 0.5, 'layer': {'arch': 'MLP', 'lr': 0.05, 'adaptive': True, 'lr_sup': 0.001, 'speed': 0.4, 'lr_div': 100, 'lebesgue_p': 2, 't_invert': 10, 'beta': 0.01, 'power': 4.5, 'ranking_param': 3, 'delta': 0.1, 'hebbian': False, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'lr_bias': 600, 'softness': 'soft', 'soft_activation_fn': 'exp', 'plasticity': 'SoftHebb', 'metric_mode': 'unsupervised', 'weight_init': 'positive', 'weight_init_range': 0.25, 'weight_init_offset': 0, 'weight_decay': 0, 'radius': 10, 'power_lr': 0.2, 'out_channels': 10}, 'pool': None, 'activation': None}}
CL:  False
{'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': False}
CL:  False
{'name': 'CIFAR10', 'noise_std': 0, 'channels': 3, 'width': 32, 'height': 32, 'validation_split': 0.2, 'training_sample': 50000, 'testing_sample': 10000, 'out_channels': 10, 'num_workers': 0, 'seed': 0, 'shuffle': True, 'batch_size': 10, 'augmentation': False, 'zca_whitened': False, 'training_class': 'all', 'split': 'train', 'nb_epoch': 1, 'print_freq': 10, 'validation': False, 'continual_learning': False}
SEED:  0
block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
range = 0.11048543456039805
The device used will be: 
True
cuda:0
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.08, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 1.0, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 2, 'weight_init': 'normal', 'weight_init_range': 2.886751345948129, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 96, 'kernel_size': 5, 'in_channels': 3, 'lr_scheduler': {'lr': 0.08, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.005, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.65, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.8505172717997146, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 384, 'kernel_size': 3, 'in_channels': 96, 'lr_scheduler': {'lr': 0.005, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}
CNN LAYER CONFIG:  {'arch': 'CNN', 'nb_train': None, 'lr': 0.01, 'adaptive': True, 'lr_sup': 0.001, 'speed': 7, 'lr_div': 96, 'lebesgue_p': 2, 'padding_mode': 'reflect', 'pre_triangle': False, 'ranking_param': 3, 'delta': 2, 't_invert': 0.25, 'groups': 1, 'stride': 1, 'dilation': 1, 'beta': 1, 'power': 4.5, 'padding': 1, 'weight_init': 'normal', 'weight_init_range': 0.4252586358998573, 'weight_init_offset': 0, 'mask_thsd': 0, 'radius': 25, 'power_lr': 0.5, 'weight_decay': 0, 'soft_activation_fn': 'exp', 'hebbian': True, 'resume': None, 'add_bias': False, 'normalize_inp': False, 'lr_decay': 'linear', 'seed': 0, 'softness': 'softkrotov', 'out_channels': 1536, 'kernel_size': 3, 'in_channels': 384, 'lr_scheduler': {'lr': 0.01, 'adaptive': True, 'nb_epochs': 1, 'ratio': 0.0002, 'speed': 7, 'div': 96, 'decay': 'linear', 'power_lr': 0.5}}

 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 3 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24576, out_features=10, bias=True)
[Sequential(
  (0): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=0.7)
  )
  (1): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=1.4)
  )
  (2): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (activation): Triangle(power=1.0)
  )
  (3): BasicBlock(
    (operations): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
    )
    (layer): Linear(in_features=24576, out_features=10, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
)]
LAYER NAME:  Sequential(
  (0): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=0.7)
  )
  (1): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
    (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
    (activation): Triangle(power=1.4)
  )
  (2): BasicBlock(
    (operations): Sequential(
      (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
    )
    (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    (activation): Triangle(power=1.0)
  )
  (3): BasicBlock(
    (operations): Sequential(
      (0): Flatten(start_dim=1, end_dim=-1)
    )
    (layer): Linear(in_features=24576, out_features=10, bias=True)
    (dropout): Dropout(p=0.5, inplace=False)
  )
)
LAYER CHILDREN:  [BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
  (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
  (activation): Triangle(power=0.7)
), BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
  (pool): MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
  (activation): Triangle(power=1.4)
), BasicBlock(
  (operations): Sequential(
    (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
  )
  (layer): HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (activation): Triangle(power=1.0)
), BasicBlock(
  (operations): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
  )
  (layer): Linear(in_features=24576, out_features=10, bias=True)
  (dropout): Dropout(p=0.5, inplace=False)
)]
subsubl NAME:  Sequential(
  (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
subsubl NAME:  Triangle(power=0.7)
subsubl NAME:  Sequential(
  (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)
subsubl NAME:  Triangle(power=1.4)
subsubl NAME:  Sequential(
  (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
subsubl NAME:  HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
subsubl NAME:  AvgPool2d(kernel_size=2, stride=2, padding=0)
subsubl NAME:  Triangle(power=1.0)
subsubl NAME:  Sequential(
  (0): Flatten(start_dim=1, end_dim=-1)
)
subsubl NAME:  Linear(in_features=24576, out_features=10, bias=True)
subsubl NAME:  Dropout(p=0.5, inplace=False)
MODEL PARAMETERS: 
torch.Size([10, 24576]) tensor([[ 0.0047, -0.0050,  0.0012,  ...,  0.0017,  0.0033,  0.0019],
        [-0.0021, -0.0006,  0.0044,  ..., -0.0026, -0.0023, -0.0007],
        [-0.0041,  0.0025, -0.0033,  ...,  0.0022, -0.0049,  0.0021],
        ...,
        [ 0.0029,  0.0008,  0.0023,  ...,  0.0007, -0.0021, -0.0063],
        [-0.0057, -0.0047,  0.0036,  ..., -0.0025, -0.0011,  0.0029],
        [-0.0046,  0.0051, -0.0040,  ...,  0.0028,  0.0012,  0.0015]],
       device='cuda:0')
torch.Size([10]) tensor([ 0.0046, -0.0054, -0.0008, -0.0015, -0.0060, -0.0058,  0.0034,  0.0053,
         0.0048,  0.0006], device='cuda:0')
############################################
BLOCKS:  [0]

 ********** Hebbian Unsupervised learning of blocks [0] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  50000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_EV
DEPTH:  3
LAYER_NUM:  0
FINAL_SUM:  [39, 90, 54, 22, 92, 13, 11, 34, 77, 95]
acts len:  3
acts keys:  ['conv0', 'conv1', 'conv2']
acts:  {'conv0': [39, 90, 54, 22, 92, 13, 11, 34, 77, 95, 40, 30, 35, 55, 53, 9, 48, 42, 68, 51, 49], 'conv1': [98, 330, 204, 359, 259, 63, 294, 61, 225, 247, 147, 300, 64, 158, 78, 19, 66, 243, 49, 266, 175], 'conv2': [1005, 1284, 626, 1189, 870, 660, 650, 1113, 540, 1323, 205, 1261, 588, 1505, 674, 269, 914, 1132, 924, 61, 320]}
final_sum len:  96
delta_weights INFO:
NUM OF TRACKED COV LAYERS:  1
NUM OF TRACKED WEIGHTS CHANGES PER LAYER:  50
avg_deltas size:  3
num of averages for 0 layer:  torch.Size([96])
################################################
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.10e-04	time: 00:00:20	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:-3.016e-03/SW:1.154e-01/MR:1.000e+00/SR:6.281e-05/MeD:2.483e-05/MaD:4.326e-04/MW:nan/MAW:nan
|        0 |         1 |          2 |         3 |          4 |        5 |          6 |        7 |        8 |         9 |        10 |        11 |         12 |         13 |        14 |       15 |       16 |         17 |       18 |       19 |        20 |        21 |         22 |         23 |        24 |         25 |        26 |         27 |         28 |         29 |
|----------+-----------+------------+-----------+------------+----------+------------+----------+----------+-----------+-----------+-----------+------------+------------+-----------+----------+----------+------------+----------+----------+-----------+-----------+------------+------------+-----------+------------+-----------+------------+------------+------------|
|   0.0004 |   0.00041 |   0.000183 |   0.00041 |   0.000398 |   0.0004 |   0.000411 |   0.0004 |   0.0004 |   0.00041 |   0.00041 |   0.00041 |   0.000156 |   0.000233 |   0.00041 |   0.0004 |   0.0004 |   0.000209 |   0.0004 |   0.0004 |   0.00041 |   0.00041 |   0.000201 |   0.000169 |   0.00041 |   0.000409 |   0.00127 |   0.000394 |   0.000237 |   0.000166 |
|   1      |   1       |   1        |   1       |   1        |   1      |   1        |   1      |   1      |   1       |   1       |   1       |   1        |   1        |   1       |   1      |   1      |   1        |   1      |   1      |   1       |   1       |   1        |   1        |   1       |   1        |   1       |   1        |   1        |   1        |
|   1.07   |   1.13    |   0.82     |   1.13    |   1.1      |   1.11   |   1.16     |   0.98   |   1.1    |   1.14    |   1.16    |   1.13    |   0.7      |   0.63     |   1.18    |   1.04   |   1.12   |   0.64     |   1.09   |   1.09   |   1.15    |   1.17    |   0.78     |   0.64     |   1.15    |   1.18     |   0.86    |   0.94     |   0.72     |   0.68     |
| nan      | nan       | nan        | nan       | nan        | nan      | nan        | nan      | nan      | nan       | nan       | nan       | nan        | nan        | nan       | nan      | nan      | nan        | nan      | nan      | nan       | nan       | nan        | nan        | nan       | nan        | nan       | nan        | nan        | nan        |
| nan      | nan       | nan        | nan       | nan        | nan      | nan        | nan      | nan      | nan       | nan       | nan       | nan        | nan        | nan       | nan      | nan      | nan        | nan      | nan      | nan       | nan       | nan        | nan        | nan       | nan        | nan       | nan        | nan        | nan        |
| nan      | nan       | nan        | nan       | nan        | nan      | nan        | nan      | nan      | nan       | nan       | nan       | nan        | nan        | nan       | nan      | nan      | nan        | nan      | nan      | nan       | nan       | nan        | nan        | nan       | nan        | nan       | nan        | nan        | nan        |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_EV/models
BLOCKS:  [1]

 ********** Hebbian Unsupervised learning of blocks [1] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  50000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_EV
DEPTH:  3
ACTIVATIONS SHAPE:  tensor([[-144.7463, -164.1826, -170.6552, -165.8360, -171.6860,  -98.8105,
          -69.9948,  -94.2353,  -81.9315,  -70.5613,  -95.1561,  -98.6266,
         -138.6414, -142.8972, -113.6033, -108.0002],
        [-125.4527, -144.6747, -149.9587, -116.2034, -115.8295,  -71.3409,
         -109.7882, -113.9070,  -75.4764,  -56.7065,  -56.4269,  -20.8719,
           -8.5843,  -26.7399,  -41.5631,  -27.7621],
        [ -94.9613, -132.3235, -179.8316, -186.0997, -135.6681,  -74.3323,
         -127.0247, -164.2996, -122.9321,  -93.4155, -103.4809,  -61.9303,
          -38.7172,  -24.6935,  -33.3153,  -35.6752],
        [ -87.0426, -111.2890, -135.4553, -114.3071, -108.4847, -114.2569,
         -182.9778, -201.4232, -209.7965, -184.6611, -226.0657, -122.3059,
          -87.6897,  -65.9296,  -81.0352,  -86.3969],
        [-118.4273, -132.4436, -141.3311, -127.0044, -158.6511, -152.9802,
         -212.6960, -242.9937, -291.5842, -221.4699, -247.4520, -190.1591,
         -129.0750,  -90.7541,  -96.5140, -105.7964],
        [-101.7599, -121.9443, -159.4674, -156.9613, -158.7805, -144.7799,
         -218.2742, -198.5383, -265.5289, -259.1312, -223.8340, -205.9765,
         -165.4517, -112.0988, -135.3300, -142.9993],
        [-115.6605, -118.0014, -143.2811, -136.0782,  -93.1650, -161.8499,
         -312.1577, -223.5982, -226.8532, -244.3076, -161.9444, -128.6799,
         -131.5214, -154.1946, -182.0884, -185.8899],
        [ -88.2267,  -81.2043,  -77.3818, -122.6409,  -48.1538,  -78.7588,
         -155.3056, -163.9609, -190.0415, -215.0437, -206.9857, -137.0806,
         -122.5872, -164.0031, -213.4178, -197.4284],
        [ -63.0582,  -94.5168,  -82.8507,  -51.2692,  -35.5877, -143.0476,
         -173.2426, -196.0004, -168.5702, -186.8643, -133.8944,  -46.2146,
          -48.6822,  -68.1838,  -87.4795,  -86.6131],
        [-108.3927,  -97.1092,  -95.4451, -101.8993, -100.9482, -149.5121,
         -213.6934, -231.1312, -181.5242, -162.5480, -112.4757,  -38.7810,
           -6.6005,   14.0191,  -43.8329,  -41.0408],
        [-155.5128, -158.9617, -180.5444, -187.7840, -141.2433, -143.7778,
         -190.1827, -209.4236, -154.0248, -148.6887,  -88.3254,  -30.8972,
          -39.1947,  -28.1050,  -65.7555,  -58.7058],
        [-166.8200, -150.9940, -182.4382, -181.8640, -201.5531, -226.8566,
         -202.3190, -198.1513, -140.2415,  -28.8883,   27.0476,   42.4984,
           41.8307,   34.4146,  -13.8832,  -13.7806],
        [-177.3938, -197.1325, -206.0973, -231.6811, -246.6565, -212.9891,
         -204.4126, -202.3168, -199.0678,  -94.9807,  -32.0263,   25.0753,
           45.1430,   16.1711,   15.3923,    5.3547],
        [ -72.0514,  -97.7466, -108.8890, -115.3073, -119.1567, -104.7499,
         -114.4479, -152.9732, -208.4654, -136.6840,  -66.5127,  -31.6958,
          -51.9294,  -38.7943,   -6.3183,    9.7416],
        [ -40.5599,  -62.4902,  -50.5930,  -35.2022,  -18.0684,  -81.8100,
         -107.8261, -127.7980,  -95.3543,  -59.7937,  -74.4098,  -48.9800,
          -63.3313,  -66.6634,  -48.7671,  -10.1101],
        [-114.5555, -111.9642, -120.6209, -141.2015, -120.3779, -118.6399,
         -137.4497, -205.7229, -192.3569, -104.5974,  -76.5822,  -30.0662,
          -77.2153,  -89.3147,  -57.7545,  -47.2308]], device='cuda:0')
LAYER_NUM:  1
FINAL_SUM:  [213, 261, 91, 232, 157, 7, 46, 290, 300, 266]
acts len:  3
acts keys:  ['conv0', 'conv1', 'conv2']
acts:  {'conv0': [39, 90, 54, 22, 92, 13, 11, 34, 77, 95, 40, 30, 35, 55, 53, 9, 48, 42, 68, 51, 49], 'conv1': [213, 261, 91, 232, 157, 7, 46, 290, 300, 266, 160, 273, 42, 43, 161, 119, 311, 10, 360, 204, 255], 'conv2': [1005, 1284, 626, 1189, 870, 660, 650, 1113, 540, 1323, 205, 1261, 588, 1505, 674, 269, 914, 1132, 924, 61, 320]}
final_sum len:  384
delta_weights INFO:
NUM OF TRACKED COV LAYERS:  1
NUM OF TRACKED WEIGHTS CHANGES PER LAYER:  50
avg_deltas size:  3
num of averages for 1 layer:  torch.Size([96])
################################################
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 4.10e-04	time: 00:00:32	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:-9.113e-04/SW:3.401e-02/MR:1.000e+00/SR:1.850e-04/MeD:5.776e-05/MaD:3.209e-03/MW:nan/MAW:nan
|          0 |          1 |          2 |          3 |          4 |          5 |          6 |          7 |          8 |          9 |         10 |         11 |         12 |         13 |         14 |         15 |         16 |         17 |         18 |         19 |         20 |         21 |         22 |         23 |         24 |         25 |         26 |         27 |        28 |        29 |
|------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+-----------+-----------|
|   4.42e-05 |   5.43e-05 |   1.09e-05 |   3.85e-05 |   1.68e-05 |   5.46e-06 |   6.91e-06 |   3.53e-05 |   2.39e-05 |   8.28e-06 |   3.36e-05 |   5.02e-05 |   4.63e-05 |   6.22e-06 |   1.34e-05 |   2.36e-05 |   4.88e-06 |   7.12e-06 |   3.21e-05 |   3.45e-06 |   2.25e-05 |   1.13e-05 |   1.16e-05 |   7.53e-06 |   2.71e-05 |   2.67e-05 |   5.18e-06 |   2.49e-05 |   3.9e-05 |   1.9e-05 |
|   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1       |   1       |
|   0.15     |   0.11     |   0.33     |   0.14     |   0.39     |   0.33     |   0.33     |   0.14     |   0.16     |   0.31     |   0.13     |   0.15     |   0.15     |   0.49     |   0.28     |   0.24     |   0.46     |   0.47     |   0.13     |   0.42     |   0.2      |   0.35     |   0.38     |   0.41     |   0.26     |   0.26     |   0.47     |   0.17     |   0.15    |   0.29    |
| nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan       | nan       |
| nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan       | nan       |
| nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan       | nan       |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_EV/models
BLOCKS:  [2]

 ********** Hebbian Unsupervised learning of blocks [2] **********
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  50000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
SAVING FOLDER FOR UNSUP:  C10_EV
DEPTH:  3
ACTIVATIONS SHAPE:  tensor([[-1.0131e+01, -1.1217e+01, -1.2785e+01, -1.1470e+01, -4.1307e+00,
          4.2503e+00,  1.1925e+01,  1.6133e+01,  2.0950e+01,  2.4672e+01,
          2.7467e+01,  2.6524e+01,  2.5852e+01,  2.6658e+01,  2.9224e+01,
          3.1832e+01],
        [-2.5293e+00, -6.2143e+00, -1.0845e+01, -1.2255e+01, -3.0994e+00,
          6.0767e+00,  1.1862e+01,  1.2447e+01,  1.5437e+01,  2.0310e+01,
          2.4698e+01,  2.6498e+01,  3.0854e+01,  3.6495e+01,  4.0956e+01,
          4.3907e+01],
        [ 4.0631e+00, -1.9220e+00, -9.8346e+00, -1.4017e+01, -6.3971e+00,
         -1.1953e-01,  1.8751e+00, -7.0974e-01,  6.0700e-01,  5.2712e+00,
          1.0123e+01,  1.5204e+01,  2.2410e+01,  2.9509e+01,  3.2316e+01,
          3.4254e+01],
        [ 4.9145e+00, -1.6826e-01, -4.7285e+00, -6.2121e+00,  1.8421e+00,
          2.7449e+00, -1.9924e+00, -1.1241e+01, -1.4842e+01, -1.3695e+01,
         -1.0087e+01, -1.3385e+00,  9.3531e+00,  1.7893e+01,  1.8983e+01,
          1.9405e+01],
        [ 1.1470e+00, -1.6021e+00, -4.2620e+00, -4.5219e+00, -4.6162e-02,
         -4.8543e+00, -1.3083e+01, -2.4661e+01, -2.9298e+01, -3.1467e+01,
         -2.9142e+01, -1.9932e+01, -8.1222e+00,  2.5382e+00,  6.3231e+00,
          8.0107e+00],
        [ 1.7277e+00, -2.2860e+00, -5.9532e+00, -6.9037e+00, -3.8448e+00,
         -1.0531e+01, -2.0154e+01, -3.1904e+01, -3.6249e+01, -3.9769e+01,
         -3.6446e+01, -2.6467e+01, -1.1874e+01, -8.2152e-01,  3.5386e+00,
          4.2345e+00],
        [ 2.0732e+00, -3.0989e+00, -5.4453e+00, -5.1650e+00, -1.0891e+00,
         -5.7200e+00, -1.7873e+01, -2.7756e+01, -3.2997e+01, -3.5211e+01,
         -3.3598e+01, -2.5387e+01, -1.2680e+01, -4.4922e+00, -4.2233e+00,
         -5.3178e+00],
        [ 7.6016e+00,  5.3754e+00,  4.9800e+00,  7.1614e+00,  1.0397e+01,
          7.9837e+00, -3.5325e+00, -1.4277e+01, -2.4422e+01, -3.2000e+01,
         -3.3198e+01, -2.3814e+01, -1.0083e+01, -2.9821e+00, -4.7667e+00,
         -6.9705e+00],
        [ 4.8225e+00,  6.5706e+00,  8.4380e+00,  1.4982e+01,  1.6508e+01,
          1.1421e+01, -4.9671e+00, -2.0597e+01, -3.4956e+01, -4.2445e+01,
         -3.7587e+01, -1.8224e+01,  2.1109e+00,  1.2763e+01,  1.2944e+01,
          1.2322e+01],
        [-9.9394e+00, -6.8751e+00, -2.0156e+00,  4.2909e+00,  4.8870e+00,
         -1.4470e+00, -1.8100e+01, -3.2162e+01, -4.5084e+01, -4.8482e+01,
         -3.9746e+01, -1.7513e+01,  7.2913e+00,  2.1193e+01,  2.4847e+01,
          2.5812e+01],
        [-2.2801e+01, -2.0734e+01, -1.6609e+01, -1.1914e+01, -1.0595e+01,
         -1.6544e+01, -2.9025e+01, -3.8346e+01, -4.3333e+01, -3.8070e+01,
         -2.3514e+01,  7.1026e-01,  2.3232e+01,  3.5029e+01,  3.6577e+01,
          3.7002e+01],
        [-2.9265e+01, -2.9077e+01, -2.8290e+01, -2.6732e+01, -2.7920e+01,
         -3.4152e+01, -4.0473e+01, -4.3166e+01, -4.0487e+01, -2.6535e+01,
         -2.3318e+00,  2.7397e+01,  4.6672e+01,  5.5653e+01,  5.5569e+01,
          5.5859e+01],
        [-1.8189e+01, -1.9510e+01, -2.2514e+01, -2.4253e+01, -2.8320e+01,
         -3.1275e+01, -3.3293e+01, -3.2513e+01, -3.1666e+01, -1.9464e+01,
          3.0750e+00,  3.1628e+01,  5.0651e+01,  6.2363e+01,  6.8305e+01,
          7.0700e+01],
        [ 2.8687e+00,  2.1781e+00,  6.1555e-01,  1.2291e+00, -1.5777e+00,
         -4.4282e+00, -1.1723e+01, -1.8547e+01, -2.3766e+01, -1.5583e+01,
          2.4857e+00,  2.5422e+01,  4.2087e+01,  5.5268e+01,  6.6687e+01,
          7.0586e+01],
        [ 1.1070e+01,  1.1019e+01,  1.0971e+01,  1.2546e+01,  1.1227e+01,
          7.7299e+00, -2.8100e+00, -1.3963e+01, -1.9263e+01, -1.1963e+01,
          4.5836e+00,  2.1926e+01,  3.4992e+01,  4.4493e+01,  5.5470e+01,
          5.8974e+01],
        [ 9.5041e+00,  9.4208e+00,  1.0378e+01,  1.2314e+01,  1.1123e+01,
          8.9926e+00, -1.3438e-01, -1.0265e+01, -1.8850e+01, -1.4457e+01,
          2.1625e-01,  1.8581e+01,  3.2738e+01,  4.3776e+01,  5.6398e+01,
          6.0754e+01]], device='cuda:0')
LAYER_NUM:  2
FINAL_SUM:  [868, 1185, 293, 1121, 829, 318, 92, 1129, 1380, 1464]
acts len:  3
acts keys:  ['conv0', 'conv1', 'conv2']
acts:  {'conv0': [39, 90, 54, 22, 92, 13, 11, 34, 77, 95, 40, 30, 35, 55, 53, 9, 48, 42, 68, 51, 49], 'conv1': [213, 261, 91, 232, 157, 7, 46, 290, 300, 266, 160, 273, 42, 43, 161, 119, 311, 10, 360, 204, 255], 'conv2': [868, 1185, 293, 1121, 829, 318, 92, 1129, 1380, 1464, 699, 321, 337, 606, 249, 27, 601, 797, 82, 471, 747]}
final_sum len:  1536
delta_weights INFO:
NUM OF TRACKED COV LAYERS:  1
NUM OF TRACKED WEIGHTS CHANGES PER LAYER:  50
avg_deltas size:  3
num of averages for 2 layer:  torch.Size([96])
################################################
INSIDE EVALUATE UNSUP
INSIDE EVALUATE UNSUP RETURNED 0,0
Epoch: [1/1]	lr: 5.16e-05	time: 00:00:46	Acc_train 0.00	Acc_test 0.00	convergence: 3.40e-05	R1: 1536	Info MB:0.000e+00/SB:0.000e+00/MW:5.111e-04/SW:1.700e-02/MR:1.000e+00/SR:4.878e-05/MeD:2.667e-05/MaD:7.964e-04/MW:nan/MAW:nan
|          0 |          1 |         2 |          3 |          4 |          5 |          6 |          7 |          8 |          9 |         10 |         11 |         12 |         13 |         14 |         15 |         16 |         17 |         18 |         19 |         20 |         21 |         22 |         23 |         24 |         25 |         26 |         27 |         28 |         29 |
|------------+------------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------|
|   4.06e-05 |   4.88e-05 |   3.7e-05 |   2.83e-05 |   3.95e-05 |   4.67e-05 |   6.02e-05 |   4.62e-05 |   4.06e-05 |   4.17e-05 |   2.87e-05 |   3.37e-05 |   2.97e-05 |   2.91e-05 |   4.54e-05 |   6.89e-05 |   3.07e-05 |   3.44e-05 |   4.73e-05 |   6.72e-05 |   2.85e-05 |   5.57e-05 |   4.75e-05 |   2.83e-05 |   5.11e-05 |   2.67e-05 |   4.11e-05 |   5.24e-05 |   3.42e-05 |   4.53e-05 |
|   1        |   1        |   1       |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |   1        |
|   0.07     |   0.04     |   0.11    |   0.08     |   0.06     |   0.07     |   0.05     |   0.06     |   0.07     |   0.07     |   0.09     |   0.11     |   0.09     |   0.11     |   0.06     |   0.03     |   0.1      |   0.09     |   0.06     |   0.04     |   0.1      |   0.05     |   0.08     |   0.08     |   0.04     |   0.12     |   0.07     |   0.04     |   0.09     |   0.05     |
| nan        | nan        | nan       | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        |
| nan        | nan        | nan       | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        |
| nan        | nan        | nan       | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        | nan        |

STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_EV/models
BLOCKS:  [3]

 ********** Supervised learning of blocks [3] **********
SAVING FOLDER FOR SUP:  C10_EV
SEED:  0
BEFORE RESIZING
Files already downloaded and verified
AFTER RESIZING
Files already downloaded and verified
INDICES:  50000
IMAGE SIZE: torch.Size([10, 3, 32, 32])
Epoch: [1/1]	lr: 1.00e-03	time: 00:00:57	Loss_train 27.58162	Acc_train 22.88	/	Loss_test 0.24698	Acc_test 25.91
STORING PATH IS NONEEEEEE
SAVING THE MODEL
/leonardo_work/try24_antoniet/rcasciot/neuromodAI/SoftHebb-main/Training/results/hebb/result/network/C10_EV/models

